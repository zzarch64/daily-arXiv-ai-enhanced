{"id": "2509.19790", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.19790", "abs": "https://arxiv.org/abs/2509.19790", "authors": ["Anthony Faure-Gignoux", "Kevin Delmas", "Adrien Gauffriau", "Claire Pagetti"], "title": "Open-source Stand-Alone Versatile Tensor Accelerator", "comment": null, "summary": "Machine Learning (ML) applications demand significant computational\nresources, posing challenges for safety-critical domains like aeronautics. The\nVersatile Tensor Accelerator (VTA) is a promising FPGA-based solution, but its\nadoption was hindered by its dependency on the TVM compiler and by other code\nnon-compliant with certification requirements. This paper presents an\nopen-source, standalone Python compiler pipeline for the VTA, developed from\nscratch and designed with certification requirements, modularity, and\nextensibility in mind. The compiler's effectiveness is demonstrated by\ncompiling and executing LeNet-5 Convolutional Neural Network (CNN) using the\nVTA simulators, and preliminary results indicate a strong potential for scaling\nits capabilities to larger CNN architectures. All contributions are publicly\navailable.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u7528\u4e8eVTA\u7684\u5f00\u6e90\u72ec\u7acbPython\u7f16\u8bd1\u5668\u7ba1\u9053\uff0c\u89e3\u51b3\u4e86VTA\u4f9d\u8d56TVM\u7f16\u8bd1\u5668\u4e14\u4e0d\u7b26\u5408\u8ba4\u8bc1\u8981\u6c42\u7684\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728VTA\u6a21\u62df\u5668\u4e0a\u7f16\u8bd1\u548c\u6267\u884cLeNet-5 CNN\u7684\u6709\u6548\u6027\u3002", "motivation": "\u673a\u5668\u5b66\u4e60\u5e94\u7528\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\uff0c\u5728\u822a\u7a7a\u7b49\u5b89\u5168\u5173\u952e\u9886\u57df\u9762\u4e34\u6311\u6218\u3002VTA\u662f\u57fa\u4e8eFPGA\u7684\u6709\u524d\u666f\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u5176\u4f9d\u8d56TVM\u7f16\u8bd1\u5668\u4e14\u4ee3\u7801\u4e0d\u7b26\u5408\u8ba4\u8bc1\u8981\u6c42\uff0c\u963b\u788d\u4e86\u5176\u5e94\u7528\u3002", "method": "\u4ece\u5934\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90\u3001\u72ec\u7acb\u7684Python\u7f16\u8bd1\u5668\u7ba1\u9053\uff0c\u8bbe\u8ba1\u65f6\u8003\u8651\u4e86\u8ba4\u8bc1\u8981\u6c42\u3001\u6a21\u5757\u5316\u548c\u53ef\u6269\u5c55\u6027\u3002\u4f7f\u7528VTA\u6a21\u62df\u5668\u7f16\u8bd1\u548c\u6267\u884cLeNet-5\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u6765\u9a8c\u8bc1\u7f16\u8bd1\u5668\u6548\u679c\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u7f16\u8bd1\u5668\u5177\u6709\u6269\u5c55\u5230\u66f4\u5927CNN\u67b6\u6784\u7684\u5f3a\u5927\u6f5c\u529b\u3002\u6240\u6709\u8d21\u732e\u90fd\u5df2\u516c\u5f00\u53ef\u7528\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u7b26\u5408\u8ba4\u8bc1\u8981\u6c42\u7684VTA\u7f16\u8bd1\u5668\uff0c\u4e3a\u5b89\u5168\u5173\u952e\u9886\u57df\u7684ML\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684FPGA\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19873", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.19873", "abs": "https://arxiv.org/abs/2509.19873", "authors": ["Linfeng Zhong", "Songqiang Xu", "Huifeng Wen", "Tong Xie", "Qingyu Guo", "Yuan Wang", "Meng Li"], "title": "SpecMamba: Accelerating Mamba Inference on FPGA with Speculative Decoding", "comment": "Accepted by ICCAD'25", "summary": "The growing demand for efficient long-sequence modeling on edge devices has\npropelled widespread adoption of State Space Models (SSMs) like Mamba, due to\ntheir superior computational efficiency and scalability. As its autoregressive\ngeneration process remains memory-bound, speculative decoding has been proposed\nthat incorporates draft model generation and target model verification.\nHowever, directly applying speculative decoding to SSMs faces three key\nchallenges: (1) hidden state backtracking difficulties, (2) tree-based parallel\nverification incompatibility, and (3) hardware workload mismatch. To address\nthese challenges, we propose SpecMamba, the first FPGA-based accelerator for\nMamba with speculative decoding, which features system, algorithm, and hardware\nco-design. At the system level, we present a memory-aware hybrid backtracking\nstrategy to coordinate both models. At the algorithm level, we propose\nfirst-in-first-out (FIFO)-based tree verification with tiling to minimize\nmemory access. At the hardware level, we customize a dataflow that computes\nlinear layers in parallel and SSM layers in series to enable maximal\noverlapping. Implemented on AMD FPGA platforms (VHK158 and VCK190), SpecMamba\nachieves a 2.27x speedup over GPU baselines and a 2.85x improvement compared to\nprior FPGA solutions, while demonstrating 5.41x and 1.26x higher energy\nefficiency, respectively.", "AI": {"tldr": "SpecMamba\u662f\u9996\u4e2a\u57fa\u4e8eFPGA\u7684Mamba\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u52a0\u901f\u5668\uff0c\u91c7\u7528\u63a8\u6d4b\u89e3\u7801\u6280\u672f\uff0c\u901a\u8fc7\u7cfb\u7edf\u3001\u7b97\u6cd5\u548c\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u89e3\u51b3SSM\u5728\u63a8\u6d4b\u89e3\u7801\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u6311\u6218\uff0c\u76f8\u6bd4GPU\u57fa\u7ebf\u5b9e\u73b02.27\u500d\u52a0\u901f\u548c5.41\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u8fb9\u7f18\u8bbe\u5907\u5bf9\u957f\u5e8f\u5217\u5efa\u6a21\u7684\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0cMamba\u7b49\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u56e0\u5176\u8ba1\u7b97\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u800c\u5e7f\u6cdb\u5e94\u7528\u3002\u4f46\u5176\u81ea\u56de\u5f52\u751f\u6210\u8fc7\u7a0b\u4ecd\u53d7\u5185\u5b58\u9650\u5236\uff0c\u63a8\u6d4b\u89e3\u7801\u6280\u672f\u9762\u4e34\u9690\u85cf\u72b6\u6001\u56de\u6eaf\u56f0\u96be\u3001\u6811\u5f62\u5e76\u884c\u9a8c\u8bc1\u4e0d\u517c\u5bb9\u548c\u786c\u4ef6\u5de5\u4f5c\u8d1f\u8f7d\u4e0d\u5339\u914d\u4e09\u5927\u6311\u6218\u3002", "method": "\u63d0\u51faSpecMamba\u4e09\u5c42\u6b21\u8bbe\u8ba1\uff1a\u7cfb\u7edf\u5c42\u91c7\u7528\u5185\u5b58\u611f\u77e5\u6df7\u5408\u56de\u6eaf\u7b56\u7565\u534f\u8c03\u53cc\u6a21\u578b\uff1b\u7b97\u6cd5\u5c42\u63d0\u51fa\u57fa\u4e8eFIFO\u7684\u6811\u5f62\u9a8c\u8bc1\u4e0e\u5206\u5757\u6280\u672f\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\uff1b\u786c\u4ef6\u5c42\u5b9a\u5236\u6570\u636e\u6d41\uff0c\u5e76\u884c\u8ba1\u7b97\u7ebf\u6027\u5c42\u3001\u4e32\u884c\u8ba1\u7b97SSM\u5c42\u4ee5\u5b9e\u73b0\u6700\u5927\u91cd\u53e0\u3002", "result": "\u5728AMD FPGA\u5e73\u53f0\uff08VHK158\u548cVCK190\uff09\u4e0a\u5b9e\u73b0\uff0c\u76f8\u6bd4GPU\u57fa\u7ebf\u83b7\u5f972.27\u500d\u52a0\u901f\uff0c\u76f8\u6bd4\u73b0\u6709FPGA\u65b9\u6848\u63d0\u53472.85\u500d\uff0c\u80fd\u6548\u5206\u522b\u63d0\u9ad85.41\u500d\u548c1.26\u500d\u3002", "conclusion": "SpecMamba\u6210\u529f\u89e3\u51b3\u4e86SSM\u63a8\u6d4b\u89e3\u7801\u7684\u5173\u952e\u6280\u672f\u6311\u6218\uff0c\u901a\u8fc7\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u548c\u80fd\u6548\u4f18\u5316\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u7684\u957f\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.19959", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.19959", "abs": "https://arxiv.org/abs/2509.19959", "authors": ["Antoine Plin", "Fr\u00e9d\u00e9ric Fauberteau", "Nga Nguyen"], "title": "OpenGL GPU-Based Rowhammer Attack (Work in Progress)", "comment": "Presented at HS3 2025 Workshop", "summary": "Rowhammer attacks have emerged as a significant threat to modern DRAM-based\nmemory systems, leveraging frequent memory accesses to induce bit flips in\nadjacent memory cells. This work-in-progress paper presents an adaptive,\nmany-sided Rowhammer attack utilizing GPU compute shaders to systematically\nachieve high-frequency memory access patterns. Our approach employs statistical\ndistributions to optimize row targeting and avoid current mitigations. The\nmethodology involves initializing memory with known patterns, iteratively\nhammering victim rows, monitoring for induced errors, and dynamically adjusting\nparameters to maximize success rates. The proposed attack exploits the parallel\nprocessing capabilities of GPUs to accelerate hammering operations, thereby\nincreasing the probability of successful bit flips within a constrained\ntimeframe. By leveraging OpenGL compute shaders, our implementation achieves\nhighly efficient row hammering with minimal software overhead. Experimental\nresults on a Raspberry Pi 4 demonstrate that the GPU-based approach attains a\nhigh rate of bit flips compared to traditional CPU-based hammering, confirming\nits effectiveness in compromising DRAM integrity. Our findings align with\nexisting research on microarchitectural attacks in heterogeneous systems that\nhighlight the susceptibility of GPUs to security vulnerabilities. This study\ncontributes to the understanding of GPU-assisted fault-injection attacks and\nunderscores the need for improved mitigation strategies in future memory\narchitectures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGPU\u8ba1\u7b97\u7740\u8272\u5668\u7684\u81ea\u9002\u5e94\u591a\u9762Rowhammer\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u8ba1\u5206\u5e03\u4f18\u5316\u884c\u76ee\u6807\u9009\u62e9\u5e76\u89c4\u907f\u73b0\u6709\u7f13\u89e3\u63aa\u65bd\uff0c\u5728\u6811\u8393\u6d3e4\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edfCPU\u653b\u51fb\u66f4\u9ad8\u7684\u6bd4\u7279\u7ffb\u8f6c\u7387\u3002", "motivation": "Rowhammer\u653b\u51fb\u5df2\u6210\u4e3a\u73b0\u4ee3DRAM\u5185\u5b58\u7cfb\u7edf\u7684\u91cd\u5927\u5a01\u80c1\uff0c\u5229\u7528\u9891\u7e41\u5185\u5b58\u8bbf\u95ee\u8bf1\u5bfc\u76f8\u90bb\u5185\u5b58\u5355\u5143\u6bd4\u7279\u7ffb\u8f6c\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22GPU\u5e76\u884c\u5904\u7406\u80fd\u529b\u5728\u52a0\u901fRowhammer\u653b\u51fb\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "method": "\u91c7\u7528OpenGL\u8ba1\u7b97\u7740\u8272\u5668\u5b9e\u73b0\u9ad8\u6548\u884c\u9524\u51fb\uff0c\u65b9\u6cd5\u5305\u62ec\uff1a\u521d\u59cb\u5316\u5df2\u77e5\u6a21\u5f0f\u5185\u5b58\u3001\u8fed\u4ee3\u9524\u51fb\u53d7\u5bb3\u884c\u3001\u76d1\u63a7\u8bf1\u5bfc\u9519\u8bef\u3001\u52a8\u6001\u8c03\u6574\u53c2\u6570\u4ee5\u6700\u5927\u5316\u6210\u529f\u7387\u3002\u5229\u7528GPU\u5e76\u884c\u5904\u7406\u80fd\u529b\u52a0\u901f\u9524\u51fb\u64cd\u4f5c\u3002", "result": "\u5728\u6811\u8393\u6d3e4\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u57fa\u4e8eGPU\u7684\u65b9\u6cd5\u76f8\u6bd4\u4f20\u7edfCPU\u9524\u51fb\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u6bd4\u7279\u7ffb\u8f6c\u7387\uff0c\u8bc1\u5b9e\u4e86\u5176\u5728\u7834\u574fDRAM\u5b8c\u6574\u6027\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u6709\u52a9\u4e8e\u7406\u89e3GPU\u8f85\u52a9\u7684\u6545\u969c\u6ce8\u5165\u653b\u51fb\uff0c\u5e76\u5f3a\u8c03\u4e86\u672a\u6765\u5185\u5b58\u67b6\u6784\u4e2d\u9700\u8981\u6539\u8fdb\u7f13\u89e3\u7b56\u7565\u7684\u5fc5\u8981\u6027\uff0c\u4e0e\u5f02\u6784\u7cfb\u7edf\u4e2d\u5fae\u67b6\u6784\u653b\u51fb\u7684\u73b0\u6709\u7814\u7a76\u7ed3\u679c\u4e00\u81f4\u3002"}}
{"id": "2509.20182", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.20182", "abs": "https://arxiv.org/abs/2509.20182", "authors": ["Amulya Bhattaram", "Janani Ramamoorthy", "Ranit Gupta", "Diana Marculescu", "Dimitrios Stamoulis"], "title": "Automated Multi-Agent Workflows for RTL Design", "comment": "Accepted: ML for Systems Workshop NeurIPS 2025", "summary": "The rise of agentic AI workflows unlocks novel opportunities for computer\nsystems design and optimization. However, for specialized domains such as\nprogram synthesis, the relative scarcity of HDL and proprietary EDA resources\nonline compared to more common programming tasks introduces challenges, often\nnecessitating task-specific fine-tuning, high inference costs, and\nmanually-crafted agent orchestration. In this work, we present VeriMaAS, a\nmulti-agent framework designed to automatically compose agentic workflows for\nRTL code generation. Our key insight is to integrate formal verification\nfeedback from HDL tools directly into workflow generation, reducing the cost of\ngradient-based updates or prolonged reasoning traces. Our method improves\nsynthesis performance by 5-7% for pass@k over fine-tuned baselines, while\nrequiring only a few hundred training examples, representing an\norder-of-magnitude reduction in supervision cost.", "AI": {"tldr": "VeriMaAS\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u96c6\u6210\u5f62\u5f0f\u9a8c\u8bc1\u53cd\u9988\u6765\u81ea\u52a8\u751f\u6210RTL\u4ee3\u7801\u751f\u6210\u7684\u5de5\u4f5c\u6d41\uff0c\u5728\u5c11\u91cf\u8bad\u7ec3\u6837\u672c\u4e0b\u5b9e\u73b05-7%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u9488\u5bf9\u7a0b\u5e8f\u5408\u6210\u7b49\u4e13\u4e1a\u9886\u57df\uff0cHDL\u548cEDA\u8d44\u6e90\u7684\u7a00\u7f3a\u6027\u5e26\u6765\u4e86\u6311\u6218\uff0c\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u7684\u5fae\u8c03\u3001\u9ad8\u63a8\u7406\u6210\u672c\u548c\u624b\u52a8\u7f16\u6392\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u3002", "method": "\u63d0\u51faVeriMaAS\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u5c06HDL\u5de5\u5177\u7684\u5f62\u5f0f\u9a8c\u8bc1\u53cd\u9988\u76f4\u63a5\u96c6\u6210\u5230\u5de5\u4f5c\u6d41\u751f\u6210\u4e2d\uff0c\u51cf\u5c11\u57fa\u4e8e\u68af\u5ea6\u7684\u66f4\u65b0\u6216\u957f\u65f6\u95f4\u63a8\u7406\u8f68\u8ff9\u7684\u6210\u672c\u3002", "result": "\u5728pass@k\u6307\u6807\u4e0a\u6bd4\u5fae\u8c03\u57fa\u7ebf\u63d0\u9ad8\u4e865-7%\uff0c\u4ec5\u9700\u51e0\u767e\u4e2a\u8bad\u7ec3\u6837\u672c\uff0c\u76d1\u7763\u6210\u672c\u964d\u4f4e\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u5f62\u5f0f\u9a8c\u8bc1\u53cd\u9988\u7684\u96c6\u6210\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4e13\u4e1a\u9886\u57df\u667a\u80fd\u4f53\u5de5\u4f5c\u6d41\u751f\u6210\u7684\u6311\u6218\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u76d1\u7763\u6210\u672c\u5e76\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
