<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [3D Stack In-Sensor-Computing (3DS-ISC): Accelerating Time-Surface Construction for Neuromorphic Event Cameras](https://arxiv.org/abs/2512.20073)
*Hongyang Shang,Shuai Dong,Ye Ke,Arindam Basu*

Main category: cs.AR

TL;DR: 提出3D堆叠传感器内计算架构，用于高效事件视觉处理，通过泄漏DRAM特性实现时间表面归一化，相比2D架构大幅降低功耗、延迟和面积


<details>
  <summary>Details</summary>
Motivation: 传统事件视觉处理面临内存墙问题，需要频繁在传感器和处理器间传输数据，导致高功耗和延迟。需要一种集成感知、存储和计算的架构来克服这些限制

Method: 提出3D堆叠传感器内计算架构，利用DRAM泄漏特性实现指数衰减时间归一化，使用定制金属-氧化物-金属电容存储电荷，低泄漏开关延长电荷存储时间

Result: 相比2D架构，功耗降低69倍，延迟降低2.2倍，面积减少1.9倍。相比16位SRAM存储时间戳，功耗降低三个数量级。在多个数据集上达到SOTA性能

Conclusion: 3D-ISC架构为实时、资源高效的事件处理奠定基础，未来可集成更先进计算电路扩展应用范围

Abstract: This work proposes a 3D Stack In-Sensor-Computing (3DS-ISC) architecture for efficient event-based vision processing. A real-time normalization method using an exponential decay function is introduced to construct the time-surface, reducing hardware usage while preserving temporal information. The circuit design utilizes the leakage characterization of Dynamic Random Access Memory(DRAM) for timestamp normalization. Custom interdigitated metal-oxide-metal capacitor (MOMCAP) is used to store the charge and low leakage switch (LL switch) is used to extend the effective charge storage time. The 3DS-ISC architecture integrates sensing, memory, and computation to overcome the memory wall problem, reducing power, latency, and reducing area by 69x, 2.2x and 1.9x, respectively, compared with its 2D counterpart. Moreover, compared to works using a 16-bit SRAM to store timestamps, the ISC analog array can reduce power consumption by three orders of magnitude. In real computer vision (CV) tasks, we applied the spatial-temporal correlation filter (STCF) for denoise, and 3D-ISC achieved almost equivalent accuracy compared to the digital implementation using high precision timestamps. As for the image classification, time-surface constructed by 3D-ISC is used as the input of GoogleNet, achieving 99% on N-MNIST, 85% on N-Caltech101, 78% on CIFAR10-DVS, and 97% on DVS128 Gesture, comparable with state-of-the-art results on each dataset. Additionally, the 3D-ISC method is also applied to image reconstruction using the DAVIS240C dataset, achieving the highest average SSIM (0.62) among three methods. This work establishes a foundation for real-time, resource-efficient event-based processing and points to future integration of advanced computational circuits for broader applications.

</details>


### [2] [Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling](https://arxiv.org/abs/2512.20198)
*Huizheng Wang,Taiquan Wei,Hongbin Wang,Zichuan Wang,Xinru Tang,Zhiheng Yue,Shaojun Wei,Yang Hu,Shouyi Yin*

Main category: cs.AR

TL;DR: STAR是一种针对大语言模型长序列并行处理的跨阶段协同稀疏加速算法-硬件协同设计，通过预测稀疏性、分布式排序和协调分块策略，显著提升计算和内存效率。


<details>
  <summary>Details</summary>
Motivation: 现有动态稀疏加速器在长序列并行处理场景下表现不佳，因为它们采用阶段隔离优化，忽略了跨阶段协同的机会。重新审视端到端稀疏加速流程，发现跨阶段协调可以大幅减少冗余计算和内存访问。

Method: 提出STAR跨阶段协同设计：1) 基于前导零的稀疏预测，使用对数域仅加法操作最小化预测开销；2) 分布式排序和排序更新FlashAttention机制；3) 协调分块策略实现细粒度阶段交互；4) 专用STAR加速器架构；5) 多核空间架构部署优化数据流和执行编排。

Result: STAR加速器相比A100实现9.2倍加速和71.2倍能效提升，超越现有最先进加速器16.1倍能效和27.1倍面积效率。空间架构版本相比基线设计实现20.1倍吞吐量提升。

Conclusion: 跨阶段协同设计是解决大语言模型长序列并行处理中稀疏加速挑战的有效方法，STAR通过算法-硬件协同设计显著提升了Transformer推理的计算和内存效率。

Abstract: Large language models (LLMs) rely on self-attention for contextual understanding, demanding high-throughput inference and large-scale token parallelism (LTPP). Existing dynamic sparsity accelerators falter under LTPP scenarios due to stage-isolated optimizations. Revisiting the end-to-end sparsity acceleration flow, we identify an overlooked opportunity: cross-stage coordination can substantially reduce redundant computation and memory access. We propose STAR, a cross-stage compute- and memory-efficient algorithm-hardware co-design tailored for Transformer inference under LTPP. STAR introduces a leading-zero-based sparsity prediction using log-domain add-only operations to minimize prediction overhead. It further employs distributed sorting and a sorted updating FlashAttention mechanism, guided by a coordinated tiling strategy that enables fine-grained stage interaction for improved memory efficiency and latency. These optimizations are supported by a dedicated STAR accelerator architecture, achieving up to 9.2$\times$ speedup and 71.2$\times$ energy efficiency over A100, and surpassing SOTA accelerators by up to 16.1$\times$ energy and 27.1$\times$ area efficiency gains. Further, we deploy STAR onto a multi-core spatial architecture, optimizing dataflow and execution orchestration for ultra-long sequence processing. Architectural evaluation shows that, compared to the baseline design, Spatial-STAR achieves a 20.1$\times$ throughput improvement.

</details>


### [3] [Nebula: Enable City-Scale 3D Gaussian Splatting in Virtual Reality via Collaborative Rendering and Accelerated Stereo Rasterization](https://arxiv.org/abs/2512.20495)
*He Zhu,Zheng Liu,Xingyang Li,Anbang Wu,Jieru Zhao,Fangxin Liu,Yiming Gan,Jingwen Leng,Yu Feng*

Main category: cs.AR

TL;DR: Nebula是一个用于大规模3D高斯泼溅协同渲染的加速框架，通过流式传输中间结果而非视频，大幅降低云客户端通信带宽，并提升VR渲染性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅架构设计忽略了可扩展性，对大规模场景脆弱；同时VR带宽需求使得云端无法高效传输高保真流畅内容。

Method: 1) 流式传输LoD搜索后的中间结果而非视频；2) 云端引入时间感知的LoD搜索，利用帧间时间一致性减少不规则内存访问；3) 客户端提出新颖的立体光栅化，让双眼共享计算；4) 最小硬件增强。

Result: 相比有损视频流，Nebula实现了2.7倍的运动到光子延迟加速，并减少了1925%的带宽需求。

Conclusion: Nebula通过创新的协同渲染框架，有效解决了大规模3D高斯泼溅的扩展性和VR带宽瓶颈问题，为高质量VR内容传输提供了可行方案。

Abstract: 3D Gaussian splatting (3DGS) has drawn significant attention in the architectural community recently. However, current architectural designs often overlook the 3DGS scalability, making them fragile for extremely large-scale 3DGS. Meanwhile, the VR bandwidth requirement makes it impossible to deliver high-fidelity and smooth VR content from the cloud.
  We present Nebula, a coherent acceleration framework for large-scale 3DGS collaborative rendering. Instead of streaming videos, Nebula streams intermediate results after the LoD search, reducing 1925% data communication between the cloud and the client. To further enhance the motion-to-photon experience, we introduce a temporal-aware LoD search in the cloud that tames the irregular memory access and reduces redundant data access by exploiting temporal coherence across frames. On the client side, we propose a novel stereo rasterization that enables two eyes to share most computations during the stereo rendering with bit-accurate quality. With minimal hardware augmentations, Nebula achieves 2.7$\times$ motion-to-photon speedup and reduces 1925% bandwidth over lossy video streaming.

</details>


### [4] [Composing Mini Oscilloscope on Embedded Systems](https://arxiv.org/abs/2512.20571)
*Brennan Romero,D. G. Perera*

Main category: cs.AR

TL;DR: 使用Nuvoton NUC-140嵌入式平台实现基本示波器功能，包括自动/边沿触发/单次模式、波形缩放和探头校准，达到商用示波器90%常用功能


<details>
  <summary>Details</summary>
Motivation: 利用低成本嵌入式平台(NUC-140)复现常规示波器的基本功能，为电子调试提供经济实用的替代方案

Method: 设计定制子板连接NUC-140平台，集成两个BNC探头接口、九键键盘和校准信号，利用开发板LCD显示波形，实现多种触发模式和缩放功能

Result: 系统成功实现90%商用示波器常用功能，包括自动/边沿触发/单次模式、垂直水平缩放、探头校准，成为有效的调试工具

Conclusion: 基于NUC-140的示波器系统是经济实用的调试工具，复现了大部分商用示波器核心功能，验证了低成本嵌入式平台实现专业仪器的可行性

Abstract: In this paper, our goal is to reproduce the basic functionalities of a regular oscilloscope, using the Nuvoton NUC-140 embedded systems development platform as the front-end and display method. A custom-built daughter board connects the NUC-140 to a variety of peripherals, including two BNC scope-probe connections, an external nine-button keypad, and a calibration signal. The LCD of the NUC-140 development board serves as the waveform display. From the experimental results, it is demonstrated that our proposed system became a very competent debugging tool. It implements 90% of the features we typically use on original oscilloscopes, including: automatic, edge-triggered, and single modes; waveform visualization using vertical and horizontal scaling; probe calibration.

</details>
