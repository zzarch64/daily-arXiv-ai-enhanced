{"id": "2602.11357", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.11357", "abs": "https://arxiv.org/abs/2602.11357", "authors": ["Xiaoling Yi", "Ryan Antonio", "Yunhao Deng", "Fanchen Kong", "Joren Dumoulin", "Jun Yin", "Marian Verhelst"], "title": "A 16 nm 1.60TOPS/W High Utilization DNN Accelerator with 3D Spatial Data Reuse and Efficient Shared Memory Access", "comment": "Accepted at ISCAS 2026 (2026 IEEE International Symposium on Circuits and Systems)", "summary": "Achieving high compute utilization across a wide range of AI workloads is crucial for the efficiency of versatile DNN accelerators. This paper presents the Voltra chip and its utilization-optimised DNN accelerator architecture, which leverages 3-Dimensional (3D) spatial data reuse along with efficient and flexible shared memory access. The 3D spatial dataflow enables balanced spatial data reuse across three dimensions, improving spatial utilization by up to 2.0x compared to a conventional 2D design. Inside the shared memory access architecture, Voltra incorporates flexible data streamers that enable mixed-grained hardware data pre-fetching and dynamic memory allocation, further improving the temporal utilization by 2.12-2.94x and achieving 1.15-2.36x total latency speedup compared with the non-prefetching and separated memory architecture, respectively. Fabricated in 16nm technology, our chip achieves 1.60 TOPS/W peak system energy efficiency and 1.25 TOPS/mm2 system area efficiency, which is competitive with state-of-the-art solutions while achieving high utilization across diverse workloads.", "AI": {"tldr": "Voltra\u82af\u7247\u91c7\u75283D\u7a7a\u95f4\u6570\u636e\u6d41\u548c\u7075\u6d3b\u5171\u4eab\u5185\u5b58\u67b6\u6784\uff0c\u63d0\u5347DNN\u52a0\u901f\u5668\u8ba1\u7b97\u5229\u7528\u7387\uff0c\u76f8\u6bd4\u4f20\u7edf2D\u8bbe\u8ba1\u7a7a\u95f4\u5229\u7528\u7387\u63d0\u53472\u500d\uff0c\u7cfb\u7edf\u80fd\u6548\u8fbe1.60 TOPS/W\u3002", "motivation": "\u63d0\u9ad8AI\u5de5\u4f5c\u8d1f\u8f7d\u7684\u8ba1\u7b97\u5229\u7528\u7387\u5bf9\u4e8e\u901a\u7528DNN\u52a0\u901f\u5668\u7684\u6548\u7387\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u89e3\u51b3\u4f20\u7edf\u67b6\u6784\u5728\u7a7a\u95f4\u6570\u636e\u91cd\u7528\u548c\u5185\u5b58\u8bbf\u95ee\u6548\u7387\u65b9\u9762\u7684\u9650\u5236\u3002", "method": "\u63d0\u51faVoltra\u82af\u7247\u67b6\u6784\uff0c\u91c7\u75283D\u7a7a\u95f4\u6570\u636e\u6d41\u5b9e\u73b0\u4e09\u7ef4\u5e73\u8861\u6570\u636e\u91cd\u7528\uff0c\u7ed3\u5408\u7075\u6d3b\u6570\u636e\u6d41\u5904\u7406\u5668\u652f\u6301\u6df7\u5408\u7c92\u5ea6\u786c\u4ef6\u9884\u53d6\u548c\u52a8\u6001\u5185\u5b58\u5206\u914d\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf2D\u8bbe\u8ba1\u7a7a\u95f4\u5229\u7528\u7387\u63d0\u53472.0\u500d\uff0c\u65f6\u95f4\u5229\u7528\u7387\u63d0\u53472.12-2.94\u500d\uff0c\u603b\u5ef6\u8fdf\u52a0\u901f1.15-2.36\u500d\uff0c16nm\u5de5\u827a\u4e0b\u7cfb\u7edf\u80fd\u65481.60 TOPS/W\uff0c\u9762\u79ef\u6548\u73871.25 TOPS/mm\u00b2\u3002", "conclusion": "Voltra\u82af\u7247\u901a\u8fc7\u521b\u65b0\u76843D\u7a7a\u95f4\u6570\u636e\u6d41\u548c\u7075\u6d3b\u5185\u5b58\u67b6\u6784\uff0c\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u65b9\u6848\u7ade\u4e89\u529b\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u8de8\u591a\u6837\u5316\u5de5\u4f5c\u8d1f\u8f7d\u7684\u9ad8\u8ba1\u7b97\u5229\u7528\u7387\u3002"}}
{"id": "2602.11461", "categories": ["cs.AR", "cs.AI", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.11461", "abs": "https://arxiv.org/abs/2602.11461", "authors": ["Yilun Huang", "Asal Mehradfar", "Salman Avestimehr", "Hamidreza Aghasi"], "title": "EM-Aware Physical Synthesis: Neural Inductor Modeling and Intelligent Placement & Routing for RF Circuits", "comment": "Accepted at the 2026 IEEE International Symposium on Circuits and Systems (ISCAS 2026)", "summary": "This paper presents an ML-driven framework for automated RF physical synthesis that transforms circuit netlists into manufacturable GDSII layouts. While recent ML approaches demonstrate success in topology selection and parameter optimization, they fail to produce manufacturable layouts due to oversimplified component models and lack of routing capabilities. Our framework addresses these limitations through three key innovations: (1) a neural network framework trained on 18,210 inductor geometries with frequency sweeps from 1-100 GHz, generating 7.5 million training samples, that predicts inductor Q-factor with less than 2% error and enables fast gradient-based layout optimization with a 93.77% success rate in producing high-Q layouts; (2) an intelligent P-Cell optimizer that reduces layout area while maintaining design-rule-check (DRC) compliance; and (3) a complete placement and routing engine with frequency-dependent EM spacing rules and DRC-aware synthesis. The neural inductor model demonstrates superior accuracy across 1-100 GHz, enabling EM-accurate component synthesis with real-time inference. The framework successfully generates DRC-aware GDSII layouts for RF circuits, representing a significant step toward automated RF physical design.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5c04\u9891\u7269\u7406\u5408\u6210\u6846\u67b6\uff0c\u53ef\u5c06\u7535\u8def\u7f51\u8868\u8f6c\u6362\u4e3a\u53ef\u5236\u9020\u7684GDSII\u7248\u56fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709ML\u65b9\u6cd5\u65e0\u6cd5\u751f\u6210\u53ef\u5236\u9020\u7248\u56fe\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5c04\u9891\u7535\u8def\u8bbe\u8ba1\u4e2d\u867d\u5728\u62d3\u6251\u9009\u62e9\u548c\u53c2\u6570\u4f18\u5316\u65b9\u9762\u53d6\u5f97\u6210\u529f\uff0c\u4f46\u65e0\u6cd5\u751f\u6210\u53ef\u5236\u9020\u7684\u7248\u56fe\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7ec4\u4ef6\u6a21\u578b\u8fc7\u4e8e\u7b80\u5316\u4e14\u7f3a\u4e4f\u5e03\u7ebf\u80fd\u529b\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u5173\u952e\u6280\u672f\uff1a1\uff09\u57fa\u4e8e18,210\u4e2a\u7535\u611f\u51e0\u4f55\u7ed3\u6784\u7684\u795e\u7ecf\u7f51\u7edc\u6846\u67b6\uff0c\u9884\u6d4bQ\u56e0\u5b50\u8bef\u5dee\u5c0f\u4e8e2%\uff1b2\uff09\u667a\u80fdP-Cell\u4f18\u5316\u5668\u51cf\u5c11\u7248\u56fe\u9762\u79ef\u5e76\u4fdd\u6301DRC\u5408\u89c4\uff1b3\uff09\u5b8c\u6574\u7684\u5e03\u5c40\u5e03\u7ebf\u5f15\u64ce\uff0c\u652f\u6301\u9891\u7387\u76f8\u5173\u7684\u7535\u78c1\u95f4\u8ddd\u89c4\u5219\u548cDRC\u611f\u77e5\u5408\u6210\u3002", "result": "\u795e\u7ecf\u7f51\u7edc\u7535\u611f\u6a21\u578b\u57281-100 GHz\u8303\u56f4\u5185\u8868\u73b0\u51fa\u5353\u8d8a\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u5b9e\u65f6\u7535\u78c1\u7cbe\u786e\u7ec4\u4ef6\u5408\u6210\uff1b\u6846\u67b6\u6210\u529f\u751f\u6210DRC\u611f\u77e5\u7684GDSII\u7248\u56fe\uff0c\u9ad8Q\u5e03\u5c40\u6210\u529f\u7387\u8fbe93.77%\u3002", "conclusion": "\u8be5\u6846\u67b6\u4ee3\u8868\u4e86\u5411\u81ea\u52a8\u5316\u5c04\u9891\u7269\u7406\u8bbe\u8ba1\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u80fd\u591f\u751f\u6210\u53ef\u5236\u9020\u7684\u5c04\u9891\u7535\u8def\u7248\u56fe\uff0c\u89e3\u51b3\u4e86\u73b0\u6709ML\u65b9\u6cd5\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2602.11521", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2602.11521", "abs": "https://arxiv.org/abs/2602.11521", "authors": ["Lian Liu", "Shixin Zhao", "Yutian Zhou", "Yintao He", "Mengdi Wang", "Yinhe Han", "Ying Wang"], "title": "PAM: Processing Across Memory Hierarchy for Efficient KV-centric LLM Serving System", "comment": "15 pages, 13 figures", "summary": "The widespread adoption of Large Language Models (LLMs) has exponentially increased the demand for efficient serving systems. With growing requests and context lengths, key-value (KV)-related operations, including attention computation and KV cache storage, have emerged as critical bottlenecks. They require massive memory bandwidth and capacity. Unfortunately, existing LLM serving systems, optimized for compute-bound workloads, fail to handle these memory-intensive operations effectively. Even with Processing-In-Memory (PIM) technology, current single-level memory designs cannot simultaneously satisfy the bandwidth and capacity requirements.\n  To address these challenges, we propose Processing Across Memory (PAM), a KV-centric LLM serving system that coordinates heterogeneous PIM-enabled memory devices within a hierarchical architecture. PAM introduces a novel computing paradigm to balance high memory bandwidth with scalable capacity. First, PAM exploits the inherent context locality in KV access patterns to intelligently distribute KV tokens across the memory hierarchy. Second, to further exploit context locality, it introduces the PAMattention algorithm, enabling fine-grained parallel attention computation across heterogeneous PIM devices. Finally, PAM incorporates an intra-device KV mapping, inter-device KV migration interface, and an inter-device online KV scheduling algorithm to dynamically balance computational workloads. By addressing both bandwidth and capacity demands simultaneously, PAM significantly enhances the efficiency and scalability of LLM serving systems, paving the way for cost-effective, high-performance solutions in the era of large-scale AI.", "AI": {"tldr": "PAM\uff1a\u4e00\u79cd\u57fa\u4e8e\u5f02\u6784\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u7684KV\u4e2d\u5fc3\u5316LLM\u670d\u52a1\u7cfb\u7edf\uff0c\u901a\u8fc7\u534f\u8c03PIM\u5185\u5b58\u8bbe\u5907\u89e3\u51b3KV\u76f8\u5173\u64cd\u4f5c\u7684\u5185\u5b58\u5e26\u5bbd\u548c\u5bb9\u91cf\u74f6\u9888\u95ee\u9898\u3002", "motivation": "\u968f\u7740LLM\u7684\u5e7f\u6cdb\u5e94\u7528\uff0cKV\u76f8\u5173\u64cd\u4f5c\uff08\u6ce8\u610f\u529b\u8ba1\u7b97\u548cKV\u7f13\u5b58\u5b58\u50a8\uff09\u5df2\u6210\u4e3a\u5173\u952e\u74f6\u9888\uff0c\u9700\u8981\u5927\u91cf\u5185\u5b58\u5e26\u5bbd\u548c\u5bb9\u91cf\u3002\u73b0\u6709LLM\u670d\u52a1\u7cfb\u7edf\u9488\u5bf9\u8ba1\u7b97\u5bc6\u96c6\u578b\u8d1f\u8f7d\u4f18\u5316\uff0c\u65e0\u6cd5\u6709\u6548\u5904\u7406\u8fd9\u4e9b\u5185\u5b58\u5bc6\u96c6\u578b\u64cd\u4f5c\uff0c\u5373\u4f7f\u4f7f\u7528PIM\u6280\u672f\uff0c\u5355\u7ea7\u5185\u5b58\u8bbe\u8ba1\u4e5f\u65e0\u6cd5\u540c\u65f6\u6ee1\u8db3\u5e26\u5bbd\u548c\u5bb9\u91cf\u9700\u6c42\u3002", "method": "1. \u5229\u7528KV\u8bbf\u95ee\u6a21\u5f0f\u4e2d\u7684\u4e0a\u4e0b\u6587\u5c40\u90e8\u6027\uff0c\u5728\u5185\u5b58\u5c42\u6b21\u7ed3\u6784\u4e2d\u667a\u80fd\u5206\u914dKV\u4ee4\u724c\uff1b2. \u63d0\u51faPAMattention\u7b97\u6cd5\uff0c\u5728\u5f02\u6784PIM\u8bbe\u5907\u95f4\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u5e76\u884c\u6ce8\u610f\u529b\u8ba1\u7b97\uff1b3. \u5305\u542b\u8bbe\u5907\u5185KV\u6620\u5c04\u3001\u8bbe\u5907\u95f4KV\u8fc1\u79fb\u63a5\u53e3\u548c\u5728\u7ebfKV\u8c03\u5ea6\u7b97\u6cd5\uff0c\u52a8\u6001\u5e73\u8861\u8ba1\u7b97\u8d1f\u8f7d\u3002", "result": "PAM\u901a\u8fc7\u540c\u65f6\u6ee1\u8db3\u5e26\u5bbd\u548c\u5bb9\u91cf\u9700\u6c42\uff0c\u663e\u8457\u63d0\u5347\u4e86LLM\u670d\u52a1\u7cfb\u7edf\u7684\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5927\u89c4\u6a21AI\u65f6\u4ee3\u63d0\u4f9b\u4e86\u7ecf\u6d4e\u9ad8\u6548\u7684\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "PAM\u7cfb\u7edf\u901a\u8fc7\u534f\u8c03\u5f02\u6784PIM\u5185\u5b58\u8bbe\u5907\u7684\u5c42\u6b21\u67b6\u6784\uff0c\u89e3\u51b3\u4e86LLM\u670d\u52a1\u4e2dKV\u76f8\u5173\u64cd\u4f5c\u7684\u5185\u5b58\u74f6\u9888\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21AI\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u670d\u52a1\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11580", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.11580", "abs": "https://arxiv.org/abs/2602.11580", "authors": ["Hao Zhen", "Qingxuan Kang", "Yungang Bao", "Trevor E. Carlson"], "title": "Benchmarking for Single Feature Attribution with Microarchitecture Cliffs", "comment": "12 pages, 14 figures, 4 tables", "summary": "Architectural simulators play a critical role in early microarchitectural exploration due to their flexibility and high productivity. However, their effectiveness is often constrained by fidelity: simulators may deviate from the behavior of the final RTL, leading to unreliable performance estimates. Consequently, model calibration, which aligns simulator behavior with the RTL as the ground-truth microarchitecture, becomes essential for achieving accurate performance modeling.\n  To facilitate model calibration accuracy, we propose Microarchitecture Cliffs, a benchmark generation methodology designed to expose mismatches in microarchitectural behavior between the simulator and RTL. After identifying the key architectural components that require calibration, the Cliff methodology enables precise attribution of microarchitectural differences to a single microarchitectural feature through a set of benchmarks. In addition, we develop a set of automated tools to improve the efficiency of the Cliff workflow.\n  We apply the Cliff methodology to calibrate the XiangShan version of gem5 (XS-GEM5) against the XiangShan open-source CPU (XS-RTL). We reduce the performance error of XS-GEM5 from 59.2% to just 1.4% on the Cliff benchmarks. Meanwhile, the calibration guided by Cliffs effectively reduces the relative error of a representative tightly coupled microarchitectural feature by 48.03%. It also substantially lowers the absolute performance error, with reductions of 15.1% and 21.0% on SPECint2017 and SPECfp2017, respectively.", "AI": {"tldr": "\u63d0\u51faMicroarchitecture Cliffs\u57fa\u51c6\u751f\u6210\u65b9\u6cd5\uff0c\u7528\u4e8e\u66b4\u9732\u6a21\u62df\u5668\u4e0eRTL\u4e4b\u95f4\u7684\u5fae\u67b6\u6784\u884c\u4e3a\u5dee\u5f02\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u6821\u51c6\u5c06XS-GEM5\u6a21\u62df\u5668\u7684\u6027\u80fd\u8bef\u5dee\u4ece59.2%\u964d\u4f4e\u52301.4%\u3002", "motivation": "\u67b6\u6784\u6a21\u62df\u5668\u5728\u65e9\u671f\u5fae\u67b6\u6784\u63a2\u7d22\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5176\u6709\u6548\u6027\u5e38\u53d7\u9650\u4e8e\u4fdd\u771f\u5ea6\u95ee\u9898\uff1a\u6a21\u62df\u5668\u53ef\u80fd\u4e0e\u6700\u7ec8RTL\u7684\u884c\u4e3a\u5b58\u5728\u504f\u5dee\uff0c\u5bfc\u81f4\u6027\u80fd\u4f30\u8ba1\u4e0d\u53ef\u9760\u3002\u56e0\u6b64\uff0c\u9700\u8981\u6a21\u578b\u6821\u51c6\u6765\u5bf9\u9f50\u6a21\u62df\u5668\u4e0eRTL\u7684\u884c\u4e3a\u3002", "method": "\u63d0\u51faCliff\u57fa\u51c6\u751f\u6210\u65b9\u6cd5\uff1a1)\u8bc6\u522b\u9700\u8981\u6821\u51c6\u7684\u5173\u952e\u67b6\u6784\u7ec4\u4ef6\uff1b2)\u901a\u8fc7\u4e00\u7ec4\u57fa\u51c6\u7cbe\u786e\u5f52\u56e0\u5fae\u67b6\u6784\u5dee\u5f02\u5230\u5355\u4e2a\u5fae\u67b6\u6784\u7279\u6027\uff1b3)\u5f00\u53d1\u81ea\u52a8\u5316\u5de5\u5177\u63d0\u5347Cliff\u5de5\u4f5c\u6d41\u7a0b\u6548\u7387\u3002\u5e94\u7528\u4e8eXS-GEM5\u6a21\u62df\u5668\u4e0eXS-RTL CPU\u7684\u6821\u51c6\u3002", "result": "1) \u5728Cliff\u57fa\u51c6\u4e0a\uff0cXS-GEM5\u6027\u80fd\u8bef\u5dee\u4ece59.2%\u964d\u81f31.4%\uff1b2) \u4ee3\u8868\u6027\u7d27\u5bc6\u8026\u5408\u5fae\u67b6\u6784\u7279\u6027\u7684\u76f8\u5bf9\u8bef\u5dee\u964d\u4f4e48.03%\uff1b3) SPECint2017\u548cSPECfp2017\u7684\u7edd\u5bf9\u6027\u80fd\u8bef\u5dee\u5206\u522b\u964d\u4f4e15.1%\u548c21.0%\u3002", "conclusion": "Microarchitecture Cliffs\u65b9\u6cd5\u80fd\u6709\u6548\u66b4\u9732\u6a21\u62df\u5668\u4e0eRTL\u4e4b\u95f4\u7684\u5fae\u67b6\u6784\u884c\u4e3a\u5dee\u5f02\uff0c\u901a\u8fc7\u9488\u5bf9\u6027\u6821\u51c6\u663e\u8457\u63d0\u5347\u6a21\u62df\u5668\u4fdd\u771f\u5ea6\uff0c\u4e3a\u67b6\u6784\u6a21\u62df\u5668\u7684\u51c6\u786e\u6027\u80fd\u5efa\u6a21\u63d0\u4f9b\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.11614", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.11614", "abs": "https://arxiv.org/abs/2602.11614", "authors": ["Yousuf Choudhary", "Tosiron Adegbija"], "title": "Device-Circuit Co-Design of Variation-Resilient Read and Write Drivers for Antiferromagnetic Tunnel Junction (AFMTJ) Memories", "comment": "International VLSI Symposium on Technology, Systems and Applications (VLSI-TSA) 2026", "summary": "Antiferromagnetic Tunnel Junctions (AFMTJs) offer picosecond switching and high integration density for in-memory computing, but their ultrafast dynamics and low tunnel magnetoresistance (TMR) make state-of-the-art MRAM interfaces unreliable. This work develops a device-circuit co-designed read/write interface optimized for AFMTJ behavior. Using a calibrated SPICE AFMTJ model as a baseline, we identify the limitations of conventional drivers and propose an asymmetric pulse driver (PD) for deterministic picosecond switching and a self-timed sense amplifier (STSA) with dynamic trip-point tuning for low-TMR sensing. Our experiments using SPICE and Monte Carlo evaluations demonstrate that the proposed circuits preserve AFMTJ latency and energy benefits while achieving robust read/write yield under realistic PVT and 3D integration parasitics, outperforming standard MRAM front-ends under the same conditions.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u9488\u5bf9\u53cd\u94c1\u78c1\u96a7\u9053\u7ed3\uff08AFMTJ\uff09\u4f18\u5316\u7684\u5668\u4ef6-\u7535\u8def\u534f\u540c\u8bbe\u8ba1\u8bfb\u5199\u63a5\u53e3\uff0c\u89e3\u51b3\u4e86AFMTJ\u8d85\u5feb\u52a8\u6001\u548c\u4f4e\u96a7\u7a7f\u78c1\u963b\uff08TMR\uff09\u5e26\u6765\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002", "motivation": "AFMTJ\u5177\u6709\u76ae\u79d2\u7ea7\u5f00\u5173\u901f\u5ea6\u548c\u9ad8\u5ea6\u96c6\u6210\u5bc6\u5ea6\uff0c\u9002\u7528\u4e8e\u5185\u5b58\u8ba1\u7b97\uff0c\u4f46\u5176\u8d85\u5feb\u52a8\u6001\u548c\u4f4eTMR\u4f7f\u5f97\u73b0\u6709MRAM\u63a5\u53e3\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u4e13\u95e8\u4f18\u5316\u7684\u8bfb\u5199\u63a5\u53e3\u3002", "method": "\u4f7f\u7528\u6821\u51c6\u7684SPICE AFMTJ\u6a21\u578b\u4f5c\u4e3a\u57fa\u51c6\uff0c\u5206\u6790\u4f20\u7edf\u9a71\u52a8\u5668\u7684\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u4e0d\u5bf9\u79f0\u8109\u51b2\u9a71\u52a8\u5668\uff08PD\uff09\u5b9e\u73b0\u786e\u5b9a\u6027\u76ae\u79d2\u5f00\u5173\uff0c\u4ee5\u53ca\u5177\u6709\u52a8\u6001\u89e6\u53d1\u70b9\u8c03\u8c10\u7684\u81ea\u5b9a\u65f6\u611f\u6d4b\u653e\u5927\u5668\uff08STSA\uff09\u7528\u4e8e\u4f4eTMR\u68c0\u6d4b\u3002", "result": "SPICE\u548c\u8499\u7279\u5361\u6d1b\u8bc4\u4f30\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7535\u8def\u5728\u4fdd\u6301AFMTJ\u5ef6\u8fdf\u548c\u80fd\u91cf\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5728\u73b0\u5b9e\u7684PVT\u548c3D\u96c6\u6210\u5bc4\u751f\u53c2\u6570\u4e0b\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u8bfb\u5199\u826f\u7387\uff0c\u4f18\u4e8e\u76f8\u540c\u6761\u4ef6\u4e0b\u7684\u6807\u51c6MRAM\u524d\u7aef\u3002", "conclusion": "\u901a\u8fc7\u5668\u4ef6-\u7535\u8def\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u5f00\u53d1\u7684\u4e13\u7528\u8bfb\u5199\u63a5\u53e3\u6210\u529f\u89e3\u51b3\u4e86AFMTJ\u7684\u53ef\u9760\u6027\u95ee\u9898\uff0c\u4e3aAFMTJ\u5728\u5185\u5b58\u8ba1\u7b97\u5e94\u7528\u4e2d\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.11966", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.11966", "abs": "https://arxiv.org/abs/2602.11966", "authors": ["Jiahong Bi", "Lars Sch\u00fctze", "Jeronimo Castrillon"], "title": "MING: An Automated CNN-to-Edge MLIR HLS framework", "comment": null, "summary": "Driven by the increasing demand for low-latency and real-time processing, machine learning applications are steadily migrating toward edge computing platforms, where Field-Programmable Gate Arrays (FPGAs) are widely adopted for their energy efficiency compared to CPUs and GPUs. To generate high-performance and low-power FPGA designs, several frameworks built upon High Level Synthesis (HLS) vendor tools have been proposed, among which MLIR-based frameworks are gaining significant traction due to their extensibility and ease of use. However, existing state-of-the-art frameworks often overlook the stringent resource constraints of edge devices. To address this limitation, we propose MING, an Multi-Level Intermediate Representation (MLIR)-based framework that abstracts and automates the HLS design process. Within this framework, we adopt a streaming architecture with carefully managed buffers, specifically designed to handle resource constraints while ensuring low-latency. In comparison with recent frameworks, our approach achieves on average 15x speedup for standard Convolutional Neural Network (CNN) kernels with up to four layers, and up to 200x for single-layer kernels. For kernels with larger input sizes, MING is capable of generating efficient designs that respect hardware resource constraints, whereas state-of-the-art frameworks struggle to meet.", "AI": {"tldr": "MING\u662f\u4e00\u4e2a\u57fa\u4e8eMLIR\u7684FPGA HLS\u6846\u67b6\uff0c\u4e13\u95e8\u9488\u5bf9\u8fb9\u7f18\u8bbe\u5907\u7684\u8d44\u6e90\u7ea6\u675f\u8fdb\u884c\u4f18\u5316\uff0c\u91c7\u7528\u6d41\u5f0f\u67b6\u6784\u548c\u7f13\u51b2\u533a\u7ba1\u7406\uff0c\u76f8\u6bd4\u73b0\u6709\u6846\u67b6\u5728CNN\u5185\u6838\u4e0a\u5b9e\u73b015-200\u500d\u52a0\u901f\u3002", "motivation": "\u968f\u7740\u673a\u5668\u5b66\u4e60\u5e94\u7528\u5411\u8fb9\u7f18\u8ba1\u7b97\u8fc1\u79fb\uff0cFPGA\u56e0\u5176\u80fd\u6548\u4f18\u52bf\u88ab\u5e7f\u6cdb\u91c7\u7528\u3002\u73b0\u6709\u57fa\u4e8eMLIR\u7684HLS\u6846\u67b6\u867d\u7136\u6613\u4e8e\u4f7f\u7528\uff0c\u4f46\u5f80\u5f80\u5ffd\u89c6\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e25\u683c\u7684\u8d44\u6e90\u7ea6\u675f\uff0c\u9700\u8981\u4e13\u95e8\u9488\u5bf9\u8d44\u6e90\u53d7\u9650\u73af\u5883\u7684\u8bbe\u8ba1\u65b9\u6848\u3002", "method": "\u63d0\u51faMING\u6846\u67b6\uff0c\u57fa\u4e8eMLIR\u62bd\u8c61\u548c\u81ea\u52a8\u5316HLS\u8bbe\u8ba1\u6d41\u7a0b\u3002\u91c7\u7528\u6d41\u5f0f\u67b6\u6784\u914d\u5408\u7cbe\u5fc3\u7ba1\u7406\u7684\u7f13\u51b2\u533a\uff0c\u4e13\u95e8\u9488\u5bf9\u8d44\u6e90\u7ea6\u675f\u8fdb\u884c\u8bbe\u8ba1\uff0c\u540c\u65f6\u786e\u4fdd\u4f4e\u5ef6\u8fdf\u5904\u7406\u3002", "result": "\u4e0e\u73b0\u6709\u6846\u67b6\u76f8\u6bd4\uff0cMING\u5728\u6807\u51c6CNN\u5185\u6838\uff08\u6700\u591a\u56db\u5c42\uff09\u4e0a\u5e73\u5747\u5b9e\u73b015\u500d\u52a0\u901f\uff0c\u5355\u5c42\u5185\u6838\u6700\u9ad8\u53ef\u8fbe200\u500d\u52a0\u901f\u3002\u5bf9\u4e8e\u5927\u8f93\u5165\u5c3a\u5bf8\u7684\u5185\u6838\uff0cMING\u80fd\u591f\u751f\u6210\u7b26\u5408\u786c\u4ef6\u8d44\u6e90\u7ea6\u675f\u7684\u9ad8\u6548\u8bbe\u8ba1\uff0c\u800c\u73b0\u6709\u6846\u67b6\u96be\u4ee5\u6ee1\u8db3\u8fd9\u4e9b\u7ea6\u675f\u3002", "conclusion": "MING\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u8fb9\u7f18\u8bbe\u5907\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684FPGA\u8bbe\u8ba1\u6311\u6218\uff0c\u901a\u8fc7MLIR-based\u6d41\u5f0f\u67b6\u6784\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u3002"}}
