<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Choreographer: A Full-System Framework for Fine-Grained Tasks in Cache Hierarchies](https://arxiv.org/abs/2510.26944)
*Hoa Nguyen,Pongstorn Maidee,Jason Lowe-Power,Alireza Kaviani*

Main category: cs.AR

TL;DR: Choreographer是一个用于细粒度加速器系统级评估的仿真框架，能够准确捕捉硬件和软件开销，通过两个案例研究展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有框架无法全面捕捉核心-加速器和缓存-加速器交互中的所有硬件和软件开销，需要开发一个能够进行整体系统级评估的仿真框架。

Method: 开发了基于gem5的硬件栈，包含AMBA CHI网状网络和完整的Linux软件栈，提供C++ API和模块化配置选项，以及详细的缓存模型。

Result: 图分析工作负载的数据感知预取器实现了1.08-1.88倍加速，快速排序加速器实现了2倍以上加速，且地址转换开销最小。

Conclusion: Choreographer能够有效建模复杂的硬件-软件交互，在小任务卸载场景中优化性能。

Abstract: In this paper, we introduce Choreographer, a simulation framework that
enables a holistic system-level evaluation of fine-grained accelerators
designed for latency-sensitive tasks. Unlike existing frameworks, Choreographer
captures all hardware and software overheads in core-accelerator and
cache-accelerator interactions, integrating a detailed gem5-based hardware
stack featuring an AMBA coherent hub interface (CHI) mesh network and a
complete Linux-based software stack. To facilitate rapid prototyping, it offers
a C++ application programming interface and modular configuration options. Our
detailed cache model provides accurate insights into performance variations
caused by cache configurations, which are not captured by other frameworks. The
framework is demonstrated through two case studies: a data-aware prefetcher for
graph analytics workloads, and a quicksort accelerator. Our evaluation shows
that the prefetcher achieves speedups between 1.08x and 1.88x by reducing
memory access latency, while the quicksort accelerator delivers more than 2x
speedup with minimal address translation overhead. These findings underscore
the ability of Choreographer to model complex hardware-software interactions
and optimize performance in small task offloading scenarios.

</details>


### [2] [Practical Timing Closure in FPGA and ASIC Designs: Methods, Challenges, and Case Studies](https://arxiv.org/abs/2510.26985)
*Mostafa Darvishi*

Main category: cs.AR

TL;DR: 本文深入分析了FPGA和ASIC中的时序收敛挑战与约束，通过比较Xilinx Kintex UltraScale+ FPGA和7nm ASIC的案例研究，展示了两种技术的时序分析和性能权衡。


<details>
  <summary>Details</summary>
Motivation: 研究FPGA和ASIC时序收敛的核心挑战和约束，理解两种技术架构差异对时序行为的影响，为高性能设计提供技术选型参考。

Method: 分析核心时序原理、架构差异和设计方法学，通过XCKU040 FPGA与7nm ASIC的案例研究进行实际时序分析和性能比较。

Result: 实验结果显示ASIC在时序性能上更优（建立时间45ps，保持时间35ps），而现代FPGA仍具有竞争力（建立时间180ps，保持时间120ps）。

Conclusion: 现代FPGA在时序性能方面仍然具有竞争力，验证了其适用于高性能设计的可行性，尽管ASIC在绝对时序性能上表现更优。

Abstract: This paper presents an in-depth analysis of timing closure challenges and
constraints in Field Programmable Gate Arrays (FPGAs) and Application Specific
Integrated Circuits (ASICs). We examine core timing principles, architectural
distinctions, and design methodologies influencing timing behavior in both
technologies. A case study comparing the Xilinx Kintex UltraScale+ FPGA
(XCKU040) with a 7nm ASIC highlights practical timing analysis and performance
trade-offs. Experimental results show ASICs achieve superior timing of 45ps
setup and 35ps hold, while modern FPGAs remain competitive with 180ps setup and
120ps hold times, validating their suitability for high-performance designs.

</details>


### [3] [Descriptor-Based Object-Aware Memory Systems: A Comprehensive Review](https://arxiv.org/abs/2510.27070)
*Dong Tong*

Main category: cs.AR

TL;DR: 该论文系统调查了基于描述符的对象感知内存系统架构范式，通过将描述符提升为一级架构抽象，使硬件能够动态获取和执行软件定义对象的丰富语义。


<details>
  <summary>Details</summary>
Motivation: 现代计算系统的安全性和效率因缺乏在硬件/软件接口间传播高级程序语义（如对象身份、边界和生命周期）的原生架构机制而受到根本性损害。

Method: 建立内存对象和描述符的基础概念，引入描述符寻址模式的新分类法，提供结构化框架来分析和比较不同实现，并以CentroID模型作为案例研究。

Result: 统一分析揭示了该范式如何整体解决内存保护、管理和处理的相互关联挑战，展示了混合标记指针编码和描述符处理机制如何体现实用高效的对象感知设计路径。

Conclusion: 明确的对象语义跨层通信为下一代缓存层次、统一虚拟内存甚至128位架构提供了基础研究方向。

Abstract: The security and efficiency of modern computing systems are fundamentally
undermined by the absence of a native architectural mechanism to propagate
high-level program semantics, such as object identity, bounds, and lifetime,
across the hardware/software interface. This paper presents a comprehensive
survey of the architectural paradigm designed to bridge this semantic gap:
descriptor-based, object-aware memory systems. By elevating the descriptor to a
first-class architectural abstraction, this paradigm enables hardware to
dynamically acquire and enforce the rich semantics of software-defined objects.
This survey systematically charts the evolution and current landscape of this
approach. We establish the foundational concepts of memory objects and
descriptors and introduce a novel taxonomy of descriptor addressing modes,
providing a structured framework for analyzing and comparing diverse
implementations. Our unified analysis reveals how this paradigm holistically
addresses the intertwined challenges of memory protection, management, and
processing. As a culminating case study, we re-examine the CentroID model,
demonstrating how its hybrid tagged-pointer encoding and descriptor processing
mechanisms embody the path toward practical and efficient object-aware designs.
Finally, we outline how the explicit cross-layer communication of object
semantics provides a foundational research direction for next-generation cache
hierarchies, unified virtual memory, and even 128-bit architectures.

</details>


### [4] [A Memory-Efficient Retrieval Architecture for RAG-Enabled Wearable Medical LLMs-Agents](https://arxiv.org/abs/2510.27107)
*Zhipeng Liao,Kunming Shao,Jiangnan Yu,Liang Zhao,Tim Kwang-Ting Cheng,Chi-Ying Tsui,Jie Yang,Mohamad Sawan*

Main category: cs.AR

TL;DR: 提出了一种用于边缘RAG的分层检索架构，通过两阶段检索方案结合近似检索和精确检索，显著降低能耗和内存访问，同时保持检索精度。


<details>
  <summary>Details</summary>
Motivation: 解决在边缘设备部署医疗AI代理时，RAG实现中检索阶段带来的高内存访问和能耗问题，同时确保隐私保护。

Method: 采用分层检索架构，结合近似检索生成候选集，然后在预选文档嵌入上进行高精度检索的两阶段方案。

Result: 在TSMC 28nm技术下，相比纯INT8检索，整体内存访问减少近50%，计算量减少75%，1MB数据检索的总能耗为177.76μJ/查询。

Conclusion: 该分层检索架构能有效降低边缘RAG的能耗和内存访问，同时维持检索准确性，适合在资源受限的边缘设备上部署医疗AI代理。

Abstract: With powerful and integrative large language models (LLMs), medical AI agents
have demonstrated unique advantages in providing personalized medical
consultations, continuous health monitoring, and precise treatment plans.
Retrieval-Augmented Generation (RAG) integrates personal medical documents into
LLMs by an external retrievable database to address the costly retraining or
fine-tuning issues in deploying customized agents. While deploying medical
agents in edge devices ensures privacy protection, RAG implementations impose
substantial memory access and energy consumption during the retrieval stage.
This paper presents a hierarchical retrieval architecture for edge RAG,
leveraging a two-stage retrieval scheme that combines approximate retrieval for
candidate set generation, followed by high-precision retrieval on pre-selected
document embeddings. The proposed architecture significantly reduces energy
consumption and external memory access while maintaining retrieval accuracy.
Simulation results show that, under TSMC 28nm technology, the proposed
hierarchical retrieval architecture has reduced the overall memory access by
nearly 50% and the computation by 75% compared to pure INT8 retrieval, and the
total energy consumption for 1 MB data retrieval is 177.76 {\mu}J/query.

</details>
