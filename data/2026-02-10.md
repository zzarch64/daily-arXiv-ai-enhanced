<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Investigating Energy Bounds of Analog Compute-in-Memory with Local Normalization](https://arxiv.org/abs/2602.08081)
*Brian Rojkov,Shubham Ranjan,Derek Wright,Manoj Sachdev*

Main category: cs.AR

TL;DR: 该论文提出了一种增益范围MAC（GR-MAC）架构，通过局部归一化解决传统模拟存内计算在处理低比特浮点格式时的能效问题，使ADC分辨率要求与输入分布无关，显著提升能效。


<details>
  <summary>Details</summary>
Motivation: 现代边缘AI工作负载需要最大能效，推动模拟存内计算架构发展。同时，大语言模型流行促使采用低比特浮点格式，但传统直接累加CIM通过归一化到共享固定点尺度处理浮点数，导致硬件分辨率受输入动态范围而非精度决定，且ADC能耗占主导。

Method: 提出增益范围MAC（GR-MAC），为每个输入、权重和MAC输出引入局部归一化。归一化开销由低功耗数字逻辑处理，使计算密集的MAC操作保持在能效高的低精度模拟域中。

Result: 能量建模显示，在MAC中添加增益范围级可在35dB SQNR标准下实现4位输入动态范围增加而不增加能耗。ADC分辨率要求变得与输入分布假设无关，相比传统下界可减少1.5位。

Conclusion: GR-MAC为现代AI工作负载解锁模拟存内计算有利的能效扩展趋势提供了途径，解决了传统架构在处理浮点格式时的能效瓶颈问题。

Abstract: Modern edge AI workloads demand maximum energy efficiency, motivating the pursuit of analog Compute-in-Memory (CIM) architectures. Simultaneously, the popularity of Large-Language-Models (LLMs) drives the adoption of low-bit floating-point formats which prioritize dynamic range. However, the conventional direct-accumulation CIM accommodates floating-points by normalizing them to a shared widened fixed-point scale. Consequently, hardware resolution is dictated by the input's dynamic range rather than its precision, and energy consumption is dominated by the ADC. We address this limitation by introducing local normalization for each input, weight, and multiply-accumulate (MAC) output via a Gain-Ranging MAC (GR-MAC). Normalization overhead is handled by low-power digital logic, enabling the computationally expensive MAC operation to remain in the energy-efficient low-precision analog regime. Energy modelling shows that the addition of a gain-ranging Stage to the MAC enables a 4-bit increase in input dynamic range without increased energy consumption at a 35 dB SQNR standard. Additionally, the ADC resolution requirement becomes invariant to input distribution assumptions, allowing construction of an upper bound with a 1.5-bit reduction compared to the conventional lower bound. These results establish a pathway towards unlocking favourable energy scaling trends of analog CIM for modern AI workloads.

</details>


### [2] [Antiferromagnetic Tunnel Junctions (AFMTJs) for In-Memory Computing: Modeling and Case Study](https://arxiv.org/abs/2602.08323)
*Yousuf Choudhary,Tosiron Adegbija*

Main category: cs.AR

TL;DR: AFMTJs（反铁磁隧道结）通过超快亚晶格动力学实现皮秒级开关和飞焦耳级写入，相比传统MTJs具有显著性能优势


<details>
  <summary>Details</summary>
Motivation: 传统磁隧道结（MTJs）在速度和能耗方面存在限制，需要开发更高效的计算元件来满足可扩展、低功耗计算需求

Method: 开发了首个端到端AFMTJ仿真框架，整合多亚晶格Landau-Lifshitz-Gilbert动力学与电路级建模，采用SPICE进行仿真

Result: AFMTJs相比传统MTJs写入延迟降低约8倍，写入能耗降低约9倍；在存内计算架构中，相比CPU基准实现17.5倍平均加速和近20倍能耗节省

Conclusion: AFMTJs是构建可扩展、低功耗计算系统的有前景的基础元件，显著优于MTJ基存内计算方案

Abstract: Antiferromagnetic Tunnel Junctions (AFMTJs) enable picosecond switching and femtojoule writes through ultrafast sublattice dynamics. We present the first end-to-end AFMTJ simulation framework integrating multi-sublattice Landau-Lifshitz-Gilbert (LLG) dynamics with circuit-level modeling. SPICE-based simulations show that AFMTJs achieve ~8x lower write latency and ~9x lower write energy than conventional MTJs. When integrated into an in-memory computing architecture, AFMTJs deliver 17.5x average speedup and nearly 20x energy savings versus a CPU baseline-significantly outperforming MTJ-based IMC. These results establish AFMTJs as a compelling primitive for scalable, low-power computing.

</details>


### [3] [karl. -- A Research Vehicle for Automated and Connected Driving](https://arxiv.org/abs/2602.08842)
*Jean-Pierre Busch,Lukas Ostendorf,Guido Linden,Lennart Reiher,Till Beemelmanns,Bastian Lampe,Timo Woopen,Lutz Eckstein*

Main category: cs.AR

TL;DR: 介绍karl.——一款用于自动驾驶和网联驾驶研究的L4级研究车辆平台，旨在为缺乏自有研究车辆的机构提供灵活强大的研究工具


<details>
  <summary>Details</summary>
Motivation: 自动驾驶和网联智能交通系统研究需要真实世界的测试验证，但只有少数大型企业拥有L4级研究车辆，限制了其他机构的独立研究能力

Method: 设计并开发了karl.研究车辆平台，详细介绍了其设计理念、技术选择和实现细节，使其成为灵活强大的研究、工程和验证平台

Result: 成功开发了karl.研究车辆，为自动驾驶和网联驾驶研究提供了可访问的L4级平台，支持真实世界测试、数据收集和未来用例演示

Conclusion: karl.研究车辆平台填补了研究机构缺乏自有L4级测试车辆的空白，通过分享设计细节帮助更多机构开展独立研究，促进自动驾驶和网联驾驶技术发展

Abstract: As highly automated driving is transitioning from single-vehicle closed-access testing to commercial deployments of public ride-hailing in selected areas (e.g., Waymo), automated driving and connected cooperative intelligent transport systems (C-ITS) remain active fields of research. Even though simulation is omnipresent in the development and validation life cycle of automated and connected driving technology, the complex nature of public road traffic and software that masters it still requires real-world integration and testing with actual vehicles. Dedicated vehicles for research and development allow testing and validation of software and hardware components under real-world conditions early on. They also enable collecting and publishing real-world datasets that let others conduct research without vehicle access, and support early demonstration of futuristic use cases. In this paper, we present karl., our new research vehicle for automated and connected driving. Apart from major corporations, few institutions worldwide have access to their own L4-capable research vehicles, restricting their ability to carry out independent research. This paper aims to help bridge that gap by sharing the reasoning, design choices, and technical details that went into making karl. a flexible and powerful platform for research, engineering, and validation in the context of automated and connected driving. More impressions of karl. are available at https://karl.ac.

</details>
