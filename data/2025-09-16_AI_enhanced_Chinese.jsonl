{"id": "2509.10627", "categories": ["cs.AR", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.10627", "abs": "https://arxiv.org/abs/2509.10627", "authors": ["Yu-Hong Lai", "Chieh-Lin Tsai", "Wen Sheng Lim", "Han-Wen Hu", "Tei-Wei Kuo", "Yuan-Hao Chang"], "title": "ReCross: Efficient Embedding Reduction Scheme for In-Memory Computing using ReRAM-Based Crossbar", "comment": null, "summary": "Deep learning-based recommendation models (DLRMs) are widely deployed in\ncommercial applications to enhance user experience. However, the large and\nsparse embedding layers in these models impose substantial memory bandwidth\nbottlenecks due to high memory access costs and irregular access patterns,\nleading to increased inference time and energy consumption. While resistive\nrandom access memory (ReRAM) based crossbars offer a fast and energy-efficient\nsolution through in-memory embedding reduction operations, naively mapping\nembeddings onto crossbar arrays leads to poor crossbar utilization and thus\ndegrades performance. We present ReCross, an efficient ReRAM-based in-memory\ncomputing (IMC) scheme designed to minimize execution time and enhance energy\nefficiency in DLRM embedding reduction. ReCross co-optimizes embedding access\npatterns and ReRAM crossbar characteristics by intelligently grouping and\nmapping co-occurring embeddings, replicating frequently accessed embeddings\nacross crossbars, and dynamically selecting in-memory processing operations\nusing a newly designed dynamic switch ADC circuit that considers runtime energy\ntrade-offs. Experimental results demonstrate that ReCross achieves a 3.97x\nreduction in execution time and a 6.1x improvement in energy efficiency\ncompared to state-of-the-art IMC approaches.", "AI": {"tldr": "ReCross\u662f\u4e00\u79cd\u57fa\u4e8eReRAM\u7684\u5185\u5b58\u8ba1\u7b97\u65b9\u6848\uff0c\u901a\u8fc7\u667a\u80fd\u5206\u7ec4\u548c\u6620\u5c04\u5171\u73b0\u5d4c\u5165\u3001\u590d\u5236\u9891\u7e41\u8bbf\u95ee\u7684\u5d4c\u5165\u4ee5\u53ca\u52a8\u6001\u9009\u62e9\u5185\u5b58\u5904\u7406\u64cd\u4f5c\uff0c\u663e\u8457\u63d0\u5347\u4e86DLRM\u5d4c\u5165\u7f29\u51cf\u7684\u6267\u884c\u65f6\u95f4\u548c\u80fd\u6548\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u63a8\u8350\u6a21\u578b\u4e2d\u7684\u5927\u578b\u7a00\u758f\u5d4c\u5165\u5c42\u5b58\u5728\u5185\u5b58\u5e26\u5bbd\u74f6\u9888\uff0c\u5bfc\u81f4\u63a8\u7406\u65f6\u95f4\u589e\u52a0\u548c\u80fd\u8017\u4e0a\u5347\u3002\u867d\u7136ReRAM\u4ea4\u53c9\u9635\u5217\u63d0\u4f9b\u4e86\u5feb\u901f\u8282\u80fd\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u7b80\u5355\u7684\u5d4c\u5165\u6620\u5c04\u4f1a\u5bfc\u81f4\u4ea4\u53c9\u9635\u5217\u5229\u7528\u7387\u4f4e\u4e0b\u3002", "method": "ReCross\u901a\u8fc7\u534f\u540c\u4f18\u5316\u5d4c\u5165\u8bbf\u95ee\u6a21\u5f0f\u548cReRAM\u4ea4\u53c9\u9635\u5217\u7279\u6027\uff0c\u5305\u62ec\u667a\u80fd\u5206\u7ec4\u6620\u5c04\u5171\u73b0\u5d4c\u5165\u3001\u8de8\u4ea4\u53c9\u9635\u5217\u590d\u5236\u9891\u7e41\u8bbf\u95ee\u7684\u5d4c\u5165\uff0c\u4ee5\u53ca\u4f7f\u7528\u65b0\u8bbe\u8ba1\u7684\u52a8\u6001\u5f00\u5173ADC\u7535\u8def\u52a8\u6001\u9009\u62e9\u5185\u5b58\u5904\u7406\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u6700\u5148\u8fdb\u7684IMC\u65b9\u6cd5\u76f8\u6bd4\uff0cReCross\u5b9e\u73b0\u4e863.97\u500d\u7684\u6267\u884c\u65f6\u95f4\u51cf\u5c11\u548c6.1\u500d\u7684\u80fd\u6548\u63d0\u5347\u3002", "conclusion": "ReCross\u901a\u8fc7\u9ad8\u6548\u7684ReRAM\u5185\u5b58\u8ba1\u7b97\u65b9\u6848\uff0c\u6709\u6548\u89e3\u51b3\u4e86DLRM\u5d4c\u5165\u5c42\u7684\u5185\u5b58\u5e26\u5bbd\u74f6\u9888\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u6027\u80fd\u548c\u80fd\u6e90\u6548\u7387\u3002"}}
{"id": "2509.10702", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.10702", "abs": "https://arxiv.org/abs/2509.10702", "authors": ["Charles Hong", "Qijing Huang", "Grace Dinh", "Mahesh Subedar", "Yakun Sophia Shao"], "title": "DOSA: Differentiable Model-Based One-Loop Search for DNN Accelerators", "comment": "Published at MICRO 2023", "summary": "In the hardware design space exploration process, it is critical to optimize\nboth hardware parameters and algorithm-to-hardware mappings. Previous work has\nlargely approached this simultaneous optimization problem by separately\nexploring the hardware design space and the mapspace - both individually large\nand highly nonconvex spaces - independently. The resulting combinatorial\nexplosion has created significant difficulties for optimizers.\n  In this paper, we introduce DOSA, which consists of differentiable\nperformance models and a gradient descent-based optimization technique to\nsimultaneously explore both spaces and identify high-performing design points.\nExperimental results demonstrate that DOSA outperforms random search and\nBayesian optimization by 2.80x and 12.59x, respectively, in improving DNN model\nenergy-delay product, given a similar number of samples. We also demonstrate\nthe modularity and flexibility of DOSA by augmenting our analytical model with\na learned model, allowing us to optimize buffer sizes and mappings of a real\nDNN accelerator and attain a 1.82x improvement in energy-delay product.", "AI": {"tldr": "DOSA\u662f\u4e00\u4e2a\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u786c\u4ef6\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6027\u80fd\u6a21\u578b\u540c\u65f6\u4f18\u5316\u786c\u4ef6\u53c2\u6570\u548c\u7b97\u6cd5\u5230\u786c\u4ef6\u7684\u6620\u5c04\uff0c\u663e\u8457\u63d0\u5347\u4e86DNN\u52a0\u901f\u5668\u7684\u80fd\u6548\u6bd4\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5c06\u786c\u4ef6\u8bbe\u8ba1\u7a7a\u95f4\u548c\u6620\u5c04\u7a7a\u95f4\u5206\u5f00\u63a2\u7d22\uff0c\u5bfc\u81f4\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u96be\u4ee5\u627e\u5230\u6700\u4f18\u8bbe\u8ba1\u70b9\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u540c\u65f6\u4f18\u5316\u8fd9\u4e24\u4e2a\u9ad8\u5ea6\u975e\u51f8\u7a7a\u95f4\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faDOSA\u6846\u67b6\uff0c\u5305\u542b\u53ef\u5fae\u5206\u6027\u80fd\u6a21\u578b\u548c\u57fa\u4e8e\u68af\u5ea6\u4e0b\u964d\u7684\u4f18\u5316\u6280\u672f\uff0c\u80fd\u591f\u540c\u65f6\u63a2\u7d22\u786c\u4ef6\u8bbe\u8ba1\u7a7a\u95f4\u548c\u6620\u5c04\u7a7a\u95f4\uff0c\u5e76\u652f\u6301\u4e0e\u5b66\u4e60\u6a21\u578b\u7684\u6a21\u5757\u5316\u96c6\u6210\u3002", "result": "DOSA\u5728\u76f8\u540c\u91c7\u6837\u6570\u91cf\u4e0b\uff0c\u6bd4\u968f\u673a\u641c\u7d22\u548c\u8d1d\u53f6\u65af\u4f18\u5316\u5206\u522b\u63d0\u53472.80\u500d\u548c12.59\u500d\u7684\u80fd\u6548\u5ef6\u8fdf\u79ef\u3002\u5728\u771f\u5b9eDNN\u52a0\u901f\u5668\u4e0a\u4f18\u5316\u7f13\u51b2\u5927\u5c0f\u548c\u6620\u5c04\uff0c\u5b9e\u73b0\u4e861.82\u500d\u7684\u80fd\u6548\u5ef6\u8fdf\u79ef\u6539\u8fdb\u3002", "conclusion": "DOSA\u901a\u8fc7\u53ef\u5fae\u5206\u5efa\u6a21\u548c\u68af\u5ea6\u4f18\u5316\u6709\u6548\u89e3\u51b3\u4e86\u786c\u4ef6\u8bbe\u8ba1\u7a7a\u95f4\u63a2\u7d22\u7684\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u4e3aDNN\u52a0\u901f\u5668\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7075\u6d3b\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2509.10751", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.10751", "abs": "https://arxiv.org/abs/2509.10751", "authors": ["Lucas M. Leipnitz de Fraga", "Cl\u00e1udio Machado Diniz"], "title": "Design and Analysis of Approximate Hardware Accelerators for VVC Intra Angular Prediction", "comment": "Accepted SBCCI 2025", "summary": "The Versatile Video Coding (VVC) standard significantly improves compression\nefficiency over its predecessor, HEVC, but at the cost of substantially higher\ncomputational complexity, particularly in intra-frame prediction. This stage\nemploys various directional modes, each requiring multiple multiplications\nbetween reference samples and constant coefficients. To optimize these\noperations at hardware accelerators, multiplierless constant multiplication\n(MCM) blocks offer a promising solution. However, VVC's interpolation filters\nhave more than fifty distinct coefficients, making MCM implementations\nresource-intensive. This work proposes an approximation method to reduce the\nnumber of interpolation coefficients by averaging fixed subsets of them,\ntherefore decreasing MCM block size and potentially lowering circuit area and\npower consumption. Six different MCM block architectures for angular intra\nprediction are introduced, in which five use the approximation method\nintroduced in this work, and evaluate the trade-off between coefficient\nreduction and coding efficiency compared with a conventional multiplier\narchitecture. Experimental results in ten videos demonstrate that only two MCM\nimplementations exceed a 4% BD-Rate increase and 2.6% on average in the worst\ncase, while two of the MCM implementations have circuit area reduction of 20%\nand 44%. For three of the architectures, parallel sample prediction modules\nwere synthesized, showing a reduction of 30% gate area compared to single\nsample processing units, and a reduction in energy consumption for two of the\nimplementations.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8fd1\u4f3c\u65b9\u6cd5\u6765\u51cf\u5c11VVC\u5e27\u5185\u9884\u6d4b\u4e2d\u63d2\u503c\u6ee4\u6ce2\u5668\u7684\u7cfb\u6570\u6570\u91cf\uff0c\u901a\u8fc7\u5e73\u5747\u56fa\u5b9a\u5b50\u96c6\u6765\u964d\u4f4eMCM\u5757\u5927\u5c0f\uff0c\u5728\u4fdd\u6301\u7f16\u7801\u6548\u7387\u7684\u540c\u65f6\u51cf\u5c11\u7535\u8def\u9762\u79ef\u548c\u529f\u8017\u3002", "motivation": "VVC\u6807\u51c6\u76f8\u6bd4HEVC\u663e\u8457\u63d0\u9ad8\u4e86\u538b\u7f29\u6548\u7387\uff0c\u4f46\u5e26\u6765\u4e86\u66f4\u9ad8\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u7279\u522b\u662f\u5728\u5e27\u5185\u9884\u6d4b\u9636\u6bb5\u3002\u63d2\u503c\u6ee4\u6ce2\u5668\u670950\u591a\u4e2a\u4e0d\u540c\u7cfb\u6570\uff0c\u4f7f\u5f97\u65e0\u4e58\u6cd5\u5668\u5e38\u6570\u4e58\u6cd5(MCM)\u5757\u7684\u5b9e\u73b0\u8d44\u6e90\u5bc6\u96c6\u3002", "method": "\u63d0\u51fa\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u901a\u8fc7\u5e73\u5747\u56fa\u5b9a\u5b50\u96c6\u7684\u63d2\u503c\u7cfb\u6570\u6765\u51cf\u5c11\u7cfb\u6570\u6570\u91cf\uff0c\u964d\u4f4eMCM\u5757\u5927\u5c0f\u3002\u5f15\u5165\u4e86\u516d\u79cd\u4e0d\u540c\u7684MCM\u5757\u67b6\u6784\uff0c\u5176\u4e2d\u4e94\u79cd\u4f7f\u7528\u8be5\u8fd1\u4f3c\u65b9\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u53ea\u6709\u4e24\u79cdMCM\u5b9e\u73b0\u8d85\u8fc7\u4e864%\u7684BD-Rate\u589e\u52a0\uff0c\u6700\u574f\u60c5\u51b5\u4e0b\u5e73\u5747\u4e3a2.6%\u3002\u4e24\u79cdMCM\u5b9e\u73b0\u5206\u522b\u51cf\u5c11\u4e8620%\u548c44%\u7684\u7535\u8def\u9762\u79ef\u3002\u4e09\u79cd\u67b6\u6784\u7684\u5e76\u884c\u6837\u672c\u9884\u6d4b\u6a21\u5757\u51cf\u5c11\u4e8630%\u7684\u95e8\u9762\u79ef\uff0c\u4e24\u79cd\u5b9e\u73b0\u964d\u4f4e\u4e86\u80fd\u8017\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u53ef\u63a5\u53d7\u7684\u7f16\u7801\u6548\u7387\u635f\u5931\u4e0b\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u786c\u4ef6\u5b9e\u73b0\u7684\u8d44\u6e90\u6d88\u8017\u548c\u529f\u8017\uff0c\u4e3aVVC\u5e27\u5185\u9884\u6d4b\u7684\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2509.11503", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.11503", "abs": "https://arxiv.org/abs/2509.11503", "authors": ["Rishab Parthasarathy", "Akshay Attaluri", "Gilford Ting"], "title": "always_comm: An FPGA-based Hardware Accelerator for Audio/Video Compression and Transmission", "comment": "8 pages, 8 figures, 1 table, equal contribution", "summary": "We present a design for an extensible video conferencing stack implemented\nentirely in hardware on a Nexys4 DDR FPGA, which uses the M-JPEG codec to\ncompress video and a UDP networking stack to communicate between the FPGA and\nthe receiving computer. This networking stack accepts real-time updates from\nboth the video codec and the audio controller, which means that video will be\nable to be streamed at 30 FPS from the FPGA to a computer. On the computer\nside, a Python script reads the Ethernet packets and decodes the packets into\nthe video and the audio for real time playback. We evaluate this architecture\nusing both functional, simulation-driven verification in Cocotb and by\nsynthesizing SystemVerilog RTL code using Vivado for deployment on our Nexys4\nDDR FPGA, where we evaluate both end-to-end latency and throughput of video\ntransmission.", "AI": {"tldr": "\u5728Nexys4 DDR FPGA\u4e0a\u5b9e\u73b0\u7684\u5168\u786c\u4ef6\u89c6\u9891\u4f1a\u8bae\u7cfb\u7edf\uff0c\u4f7f\u7528M-JPEG\u7f16\u89e3\u7801\u548cUDP\u7f51\u7edc\u534f\u8bae\uff0c\u652f\u630130FPS\u5b9e\u65f6\u89c6\u9891\u6d41\u4f20\u8f93", "motivation": "\u8bbe\u8ba1\u4e00\u4e2a\u5b8c\u5168\u5728\u786c\u4ef6\u4e0a\u5b9e\u73b0\u7684\u53ef\u6269\u5c55\u89c6\u9891\u4f1a\u8bae\u7cfb\u7edf\uff0c\u901a\u8fc7FPGA\u5b9e\u73b0\u9ad8\u6548\u7684\u89c6\u9891\u538b\u7f29\u548c\u7f51\u7edc\u4f20\u8f93\uff0c\u51cf\u5c11\u5bf9\u8ba1\u7b97\u673a\u8d44\u6e90\u7684\u4f9d\u8d56", "method": "\u4f7f\u7528M-JPEG\u7f16\u89e3\u7801\u5668\u538b\u7f29\u89c6\u9891\uff0cUDP\u7f51\u7edc\u534f\u8bae\u6808\u8fdb\u884c\u901a\u4fe1\uff0cFPGA\u5904\u7406\u89c6\u9891\u7f16\u7801\u548c\u97f3\u9891\u63a7\u5236\uff0c\u8ba1\u7b97\u673a\u7aef\u7528Python\u811a\u672c\u89e3\u7801\u548c\u64ad\u653e", "result": "\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b030FPS\u7684\u89c6\u9891\u6d41\u4f20\u8f93\uff0c\u901a\u8fc7Cocotb\u4eff\u771f\u9a8c\u8bc1\u548cVivado\u7efc\u5408\u90e8\u7f72\uff0c\u8bc4\u4f30\u4e86\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u4f20\u8f93\u541e\u5410\u91cf", "conclusion": "\u8be5\u786c\u4ef6\u5b9e\u73b0\u7684\u89c6\u9891\u4f1a\u8bae\u67b6\u6784\u662f\u53ef\u884c\u7684\uff0c\u80fd\u591f\u6ee1\u8db3\u5b9e\u65f6\u89c6\u9891\u4f20\u8f93\u7684\u9700\u6c42\uff0c\u4e3a\u5b8c\u5168\u786c\u4ef6\u5316\u7684\u89c6\u9891\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u53c2\u8003"}}
{"id": "2509.11529", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.11529", "abs": "https://arxiv.org/abs/2509.11529", "authors": ["Rishab Parthasarathy"], "title": "SuperUROP: An FPGA-Based Spatial Accelerator for Sparse Matrix Operations", "comment": "7 pages, 6 figures, work done as the Citadel Undergraduate Research\n  Scholar in the MIT SuperUROP program", "summary": "Solving sparse systems of linear equations is a fundamental problem in the\nfield of numerical methods, with applications spanning from circuit design to\nurban planning. These problems can have millions of constraints, such as when\nlaying out transistors on a circuit, or trying to optimize traffic light\ntimings, making fast sparse solvers extremely important. However, existing\nstate-of-the-art software-level solutions for solving sparse linear systems,\ntermed iterative solvers, are extremely inefficient on current hardware. This\ninefficiency can be attributed to two key reasons: (1) poor short-term data\nreuse, which causes frequent, irregular memory accesses, and (2) complex data\ndependencies, which limit parallelism. Hence, in this paper, we present an FPGA\nimplementation of the existing Azul accelerator, an SRAM-only hardware\naccelerator that achieves both high memory bandwidth utilization and arithmetic\nintensity. Azul features a grid of tiles, each of which is composed of a\nprocessing element (PE) and a small independent SRAM memory, which are all\nconnected over a network on chip (NoC). We implement Azul on FPGA using simple\nRISC-V CPU cores connected to a memory hierarchy of different FPGA memory\nmodules. We utilize custom RISC-V ISA augmentations to implement a task-based\nprogramming model for the various PEs, allowing communication over the NoC.\nFinally, we design simple distributed test cases so that we can functionally\nverify the FPGA implementation, verifying equivalent performance to an\narchitectural simulation of the Azul framework.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86Azul\u52a0\u901f\u5668\u7684FPGA\u5b9e\u73b0\uff0c\u8fd9\u662f\u4e00\u79cdSRAM-only\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u7528\u4e8e\u89e3\u51b3\u7a00\u758f\u7ebf\u6027\u65b9\u7a0b\u7ec4\u95ee\u9898\uff0c\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u8bbf\u95ee\u548c\u5e76\u884c\u6027\u6765\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u7a00\u758f\u7ebf\u6027\u65b9\u7a0b\u7ec4\u6c42\u89e3\u5728\u6570\u503c\u65b9\u6cd5\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u8f6f\u4ef6\u7ea7\u8fed\u4ee3\u6c42\u89e3\u5668\u5728\u5f53\u524d\u786c\u4ef6\u4e0a\u6548\u7387\u4f4e\u4e0b\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u5185\u5b58\u8bbf\u95ee\u4e0d\u89c4\u5219\u548c\u6570\u636e\u4f9d\u8d56\u590d\u6742\u9650\u5236\u4e86\u5e76\u884c\u6027\u3002", "method": "\u5728FPGA\u4e0a\u5b9e\u73b0Azul\u52a0\u901f\u5668\uff0c\u91c7\u7528\u57fa\u4e8eRISC-V CPU\u6838\u5fc3\u7684\u7f51\u683c\u67b6\u6784\uff0c\u6bcf\u4e2atile\u5305\u542b\u5904\u7406\u5355\u5143\u548c\u72ec\u7acbSRAM\uff0c\u901a\u8fc7NoC\u8fde\u63a5\uff0c\u5e76\u4f7f\u7528\u81ea\u5b9a\u4e49RISC-V ISA\u6269\u5c55\u5b9e\u73b0\u4efb\u52a1\u7f16\u7a0b\u6a21\u578b\u3002", "result": "\u8bbe\u8ba1\u4e86\u5206\u5e03\u5f0f\u6d4b\u8bd5\u7528\u4f8b\u8fdb\u884c\u529f\u80fd\u9a8c\u8bc1\uff0c\u786e\u8ba4FPGA\u5b9e\u73b0\u7684\u6027\u80fd\u4e0eAzul\u6846\u67b6\u67b6\u6784\u4eff\u771f\u7b49\u6548\u3002", "conclusion": "FPGA\u5b9e\u73b0\u7684Azul\u52a0\u901f\u5668\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7a00\u758f\u7ebf\u6027\u65b9\u7a0b\u7ec4\u6c42\u89e3\u4e2d\u7684\u5185\u5b58\u5e26\u5bbd\u5229\u7528\u548c\u7b97\u672f\u5f3a\u5ea6\u95ee\u9898\uff0c\u4e3a\u786c\u4ef6\u52a0\u901f\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2509.12053", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.12053", "abs": "https://arxiv.org/abs/2509.12053", "authors": ["Yujun Lin", "Zhekai Zhang", "Song Han"], "title": "LEGO: Spatial Accelerator Generation and Optimization for Tensor Applications", "comment": "The first two authors have equal contributions; Published as a\n  conference paper in HPCA 2025; 13 pages, 14 figures", "summary": "Modern tensor applications, especially foundation models and generative AI\napplications require multiple input modalities (both vision and language),\nwhich increases the demand for flexible accelerator architecture. Existing\nframeworks suffer from the trade-off between design flexibility and\nproductivity of RTL generation: either limited to very few hand-written\ntemplates or cannot automatically generate the RTL. To address this challenge,\nwe propose the LEGO framework, which targets tensor applications and\nautomatically generates spatial architecture design and outputs synthesizable\nRTL code without handwritten RTL design templates. Leveraging the\naffine-transformation-based architecture representation, LEGO front end finds\ninterconnections between function units, synthesizes the memory system, and\nfuses different spatial dataflow designs based on data reuse analysis. LEGO\nback end then translates the hardware in a primitive-level graph to perform\nlower-level optimizations, and applies a set of linear-programming algorithms\nto optimally insert pipeline registers and reduce the overhead of unused logic\nwhen switching spatial dataflows. Our evaluation demonstrates that LEGO can\nachieve 3.2x speedup and 2.4x energy efficiency compared to previous work\nGemmini, and can generate one architecture for diverse modern foundation models\nin generative AI applications.", "AI": {"tldr": "LEGO\u6846\u67b6\u662f\u4e00\u4e2a\u81ea\u52a8\u751f\u6210\u5f20\u91cf\u5e94\u7528\u7a7a\u95f4\u67b6\u6784\u8bbe\u8ba1\u548c\u53ef\u7efc\u5408RTL\u4ee3\u7801\u7684\u6846\u67b6\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u6846\u67b6\u5728\u7075\u6d3b\u6027\u548c\u751f\u4ea7\u529b\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u76f8\u6bd4Gemmini\u5b9e\u73b0\u4e863.2\u500d\u52a0\u901f\u548c2.4\u500d\u80fd\u6548\u63d0\u5347\u3002", "motivation": "\u73b0\u4ee3\u5f20\u91cf\u5e94\u7528\uff08\u7279\u522b\u662f\u57fa\u7840\u6a21\u578b\u548c\u751f\u6210\u5f0fAI\u5e94\u7528\uff09\u9700\u8981\u591a\u6a21\u6001\u8f93\u5165\uff0c\u5bf9\u7075\u6d3b\u52a0\u901f\u5668\u67b6\u6784\u9700\u6c42\u589e\u52a0\u3002\u73b0\u6709\u6846\u67b6\u8981\u4e48\u5c40\u9650\u4e8e\u5c11\u6570\u624b\u5de5\u6a21\u677f\uff0c\u8981\u4e48\u65e0\u6cd5\u81ea\u52a8\u751f\u6210RTL\uff0c\u5b58\u5728\u8bbe\u8ba1\u7075\u6d3b\u6027\u548cRTL\u751f\u6210\u751f\u4ea7\u529b\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "method": "LEGO\u6846\u67b6\u57fa\u4e8e\u4eff\u5c04\u53d8\u6362\u67b6\u6784\u8868\u793a\uff0c\u524d\u7aef\u5206\u6790\u529f\u80fd\u5355\u5143\u4e92\u8fde\u3001\u5408\u6210\u5b58\u50a8\u7cfb\u7edf\u3001\u57fa\u4e8e\u6570\u636e\u91cd\u7528\u5206\u6790\u878d\u5408\u4e0d\u540c\u7a7a\u95f4\u6570\u636e\u6d41\u8bbe\u8ba1\uff1b\u540e\u7aef\u5c06\u786c\u4ef6\u8f6c\u6362\u4e3a\u539f\u59cb\u7ea7\u56fe\u8fdb\u884c\u4f4e\u7ea7\u4f18\u5316\uff0c\u5e94\u7528\u7ebf\u6027\u89c4\u5212\u7b97\u6cd5\u4f18\u5316\u6d41\u6c34\u7ebf\u5bc4\u5b58\u5668\u63d2\u5165\u548c\u51cf\u5c11\u672a\u4f7f\u7528\u903b\u8f91\u5f00\u9500\u3002", "result": "\u8bc4\u4f30\u663e\u793aLEGO\u76f8\u6bd4\u4e4b\u524d\u5de5\u4f5cGemmini\u5b9e\u73b0\u4e863.2\u500d\u52a0\u901f\u548c2.4\u500d\u80fd\u6548\u63d0\u5347\uff0c\u80fd\u591f\u4e3a\u751f\u6210\u5f0fAI\u5e94\u7528\u4e2d\u7684\u591a\u6837\u5316\u73b0\u4ee3\u57fa\u7840\u6a21\u578b\u751f\u6210\u7edf\u4e00\u67b6\u6784\u3002", "conclusion": "LEGO\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u5f20\u91cf\u52a0\u901f\u5668\u8bbe\u8ba1\u4e2d\u7075\u6d3b\u6027\u4e0e\u751f\u4ea7\u529b\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u52a8\u5316RTL\u751f\u6210\u548c\u4f18\u5316\u6280\u672f\uff0c\u4e3a\u591a\u6a21\u6001AI\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u786c\u4ef6\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
