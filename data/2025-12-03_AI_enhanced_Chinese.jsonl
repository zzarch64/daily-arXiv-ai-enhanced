{"id": "2512.02189", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02189", "abs": "https://arxiv.org/abs/2512.02189", "authors": ["Aaron Jarmusch", "Sunita Chandrasekaran"], "title": "Microbenchmarking NVIDIA's Blackwell Architecture: An in-depth Architectural Analysis", "comment": null, "summary": "As GPU architectures rapidly evolve to meet the overcoming demands of exascale computing and machine learning, the performance implications of architectural innovations remain poorly understood across diverse workloads. NVIDIA's Blackwell (B200) generation introduce significant architectural advances including the 5th generation tensor cores, tensor memory (TMEM), decompression engine (DE), and dual chips; however systematic methodologies for quantifying these improvements lag behind hardware development cycles. We contribute an open-source microbenchmark suite that offers practical insights into optimizing workloads to fully utilize the rich feature sets of the modern GPU architecture. This work aims to enable application developers make informed architectural decisions and guide future GPU design directions.\n  Our work studies Blackwell GPUs, compares them to H200 generation with regards to the memory subsystem, tensor core pipeline and floating-point precisions (FP32, FP16, FP8, FP6, FP4). Our systematic evaluation of dense/sparse GEMM, transformer inference, and training workloads demonstrate that B200's tensor core enhancements achieves 1.56x higher mixed-precision throughput and 42% better energy efficiency than H200. Our memory analysis reveals 58% reduction in memory access latency in cache-misses, fundamentally changing optimal algorithm design strategies.", "AI": {"tldr": "\u5f00\u53d1\u5f00\u6e90\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7cfb\u7edf\u8bc4\u4f30NVIDIA Blackwell (B200) GPU\u67b6\u6784\u521b\u65b0\uff0c\u76f8\u6bd4H200\u5b9e\u73b01.56\u500d\u6df7\u5408\u7cbe\u5ea6\u541e\u5410\u63d0\u5347\u548c42%\u80fd\u6548\u6539\u8fdb\uff0c\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\u964d\u4f4e58%", "motivation": "GPU\u67b6\u6784\u5feb\u901f\u53d1\u5c55\u4ee5\u6ee1\u8db3\u767e\u4ebf\u4ebf\u6b21\u8ba1\u7b97\u548c\u673a\u5668\u5b66\u4e60\u9700\u6c42\uff0c\u4f46\u67b6\u6784\u521b\u65b0\u7684\u6027\u80fd\u5f71\u54cd\u5728\u4e0d\u540c\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7406\u89e3\u4e0d\u8db3\u3002Blackwell\u67b6\u6784\u5f15\u5165\u591a\u9879\u521b\u65b0\uff08\u7b2c\u4e94\u4ee3\u5f20\u91cf\u6838\u5fc3\u3001\u5f20\u91cf\u5185\u5b58\u3001\u89e3\u538b\u7f29\u5f15\u64ce\u7b49\uff09\uff0c\u4f46\u7cfb\u7edf\u91cf\u5316\u8fd9\u4e9b\u6539\u8fdb\u7684\u65b9\u6cd5\u6ede\u540e\u4e8e\u786c\u4ef6\u5f00\u53d1\u5468\u671f", "method": "\u5f00\u53d1\u5f00\u6e90\u5fae\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff0c\u7cfb\u7edf\u8bc4\u4f30Blackwell GPU\u5e76\u4e0eH200\u6bd4\u8f83\uff0c\u5206\u6790\u5185\u5b58\u5b50\u7cfb\u7edf\u3001\u5f20\u91cf\u6838\u5fc3\u6d41\u6c34\u7ebf\u548c\u6d6e\u70b9\u7cbe\u5ea6\uff08FP32\u5230FP4\uff09\uff0c\u8bc4\u4f30\u5bc6\u96c6/\u7a00\u758fGEMM\u3001Transformer\u63a8\u7406\u548c\u8bad\u7ec3\u5de5\u4f5c\u8d1f\u8f7d", "result": "B200\u5f20\u91cf\u6838\u5fc3\u589e\u5f3a\u5b9e\u73b01.56\u500d\u6df7\u5408\u7cbe\u5ea6\u541e\u5410\u63d0\u5347\u548c42%\u80fd\u6548\u6539\u8fdb\uff1b\u5185\u5b58\u5206\u6790\u663e\u793a\u7f13\u5b58\u672a\u547d\u4e2d\u65f6\u5185\u5b58\u8bbf\u95ee\u5ef6\u8fdf\u964d\u4f4e58%\uff0c\u4ece\u6839\u672c\u4e0a\u6539\u53d8\u4e86\u6700\u4f18\u7b97\u6cd5\u8bbe\u8ba1\u7b56\u7565", "conclusion": "\u5f00\u6e90\u5fae\u57fa\u51c6\u5957\u4ef6\u4e3a\u5e94\u7528\u5f00\u53d1\u8005\u63d0\u4f9b\u5b9e\u7528\u6d1e\u5bdf\uff0c\u5e2e\u52a9\u5145\u5206\u5229\u7528\u73b0\u4ee3GPU\u67b6\u6784\u7279\u6027\uff0c\u652f\u6301\u660e\u667a\u7684\u67b6\u6784\u51b3\u7b56\u5e76\u6307\u5bfc\u672a\u6765GPU\u8bbe\u8ba1\u65b9\u5411"}}
{"id": "2512.02346", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02346", "abs": "https://arxiv.org/abs/2512.02346", "authors": ["Hongyang Shang", "An Guo", "Shuai Dong", "Junyi Yang", "Ye Ke", "Arindam Basu"], "title": "Near-Memory Architecture for Threshold-Ordinal Surface-Based Corner Detection of Event Cameras", "comment": null, "summary": "Event-based Cameras (EBCs) are widely utilized in surveillance and autonomous driving applications due to their high speed and low power consumption. Corners are essential low-level features in event-driven computer vision, and novel algorithms utilizing event-based representations, such as Threshold-Ordinal Surface (TOS), have been developed for corner detection. However, the implementation of these algorithms on resource-constrained edge devices is hindered by significant latency, undermining the advantages of EBCs. To address this challenge, a near-memory architecture for efficient TOS updates (NM-TOS) is proposed. This architecture employs a read-write decoupled 8T SRAM cell and optimizes patch update speed through pipelining. Hardware-software co-optimized peripheral circuits and dynamic voltage and frequency scaling (DVFS) enable power and latency reductions. Compared to traditional digital implementations, our architecture reduces latency/energy by 24.7x/1.2x at Vdd = 1.2 V or 1.93x/6.6x at Vdd = 0.6 V based on 65nm CMOS process. Monte Carlo simulations confirm robust circuit operation, demonstrating zero bit error rate at operating voltages above 0.62 V, with only 0.2% at 0.61 V and 2.5% at 0.6 V. Corner detection evaluation using precision-recall area under curve (AUC) metrics reveals minor AUC reductions of 0.027 and 0.015 at 0.6 V for two popular EBC datasets.", "AI": {"tldr": "\u63d0\u51faNM-TOS\u8fd1\u5185\u5b58\u67b6\u6784\uff0c\u901a\u8fc78T SRAM\u5355\u5143\u548c\u6d41\u6c34\u7ebf\u4f18\u5316\uff0c\u663e\u8457\u964d\u4f4e\u4e8b\u4ef6\u76f8\u673a\u89d2\u70b9\u68c0\u6d4b\u7684\u5ef6\u8fdf\u548c\u80fd\u8017", "motivation": "\u4e8b\u4ef6\u76f8\u673a\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u89d2\u70b9\u68c0\u6d4b\u7b97\u6cd5\uff08\u5982TOS\uff09\u5b58\u5728\u9ad8\u5ef6\u8fdf\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u9ad8\u901f\u4f4e\u529f\u8017\u4f18\u52bf\u7684\u53d1\u6325", "method": "\u8bbe\u8ba1\u8fd1\u5185\u5b58\u67b6\u6784NM-TOS\uff0c\u91c7\u7528\u8bfb\u5199\u89e3\u8026\u76848T SRAM\u5355\u5143\uff0c\u901a\u8fc7\u6d41\u6c34\u7ebf\u4f18\u5316\u8865\u4e01\u66f4\u65b0\u901f\u5ea6\uff0c\u7ed3\u5408\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u4f18\u5316\u7684\u5916\u56f4\u7535\u8def\u548cDVFS\u6280\u672f", "result": "\u76f8\u6bd4\u4f20\u7edf\u6570\u5b57\u5b9e\u73b0\uff0c\u57281.2V\u4e0b\u5ef6\u8fdf\u964d\u4f4e24.7\u500d/\u80fd\u8017\u964d\u4f4e1.2\u500d\uff0c\u57280.6V\u4e0b\u5ef6\u8fdf\u964d\u4f4e1.93\u500d/\u80fd\u8017\u964d\u4f4e6.6\u500d\uff1b\u8499\u7279\u5361\u6d1b\u4eff\u771f\u663e\u793a\u7535\u8def\u9c81\u68d2\u6027\u826f\u597d", "conclusion": "NM-TOS\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u4e8b\u4ef6\u76f8\u673a\u89d2\u70b9\u68c0\u6d4b\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u5ef6\u8fdf\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u68c0\u6d4b\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u80fd\u6548"}}
{"id": "2512.02859", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02859", "abs": "https://arxiv.org/abs/2512.02859", "authors": ["Cristian Tirelli", "Rodrigo Otoni", "Laura Pozzi"], "title": "Monomorphism-based CGRA Mapping via Space and Time Decoupling", "comment": null, "summary": "Coarse-Grain Reconfigurable Arrays (CGRAs) provide flexibility and energy efficiency in accelerating compute-intensive loops. Existing compilation techniques often struggle with scalability, unable to map code onto large CGRAs. To address this, we propose a novel approach to the mapping problem where the time and space dimensions are decoupled and explored separately. We leverage an SMT formulation to traverse the time dimension first, and then perform a monomorphism-based search to find a valid spatial solution. Experimental results show that our approach achieves the same mapping quality of state-of-the-art techniques while significantly reducing compilation time, with this reduction being particularly tangible when compiling for large CGRAs. We achieve approximately $10^5\\times$ average compilation speedup for the benchmarks evaluated on a $20\\times 20$ CGRA.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684CGRA\u6620\u5c04\u65b9\u6cd5\uff0c\u901a\u8fc7\u89e3\u8026\u65f6\u95f4\u548c\u7a7a\u95f4\u7ef4\u5ea6\u5206\u522b\u63a2\u7d22\uff0c\u663e\u8457\u63d0\u5347\u7f16\u8bd1\u901f\u5ea6\uff0c\u7279\u522b\u5728\u5927\u89c4\u6a21CGRA\u4e0a\u6548\u679c\u660e\u663e\u3002", "motivation": "\u73b0\u6709CGRA\u7f16\u8bd1\u6280\u672f\u5b58\u5728\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u96be\u4ee5\u5c06\u4ee3\u7801\u6620\u5c04\u5230\u5927\u89c4\u6a21CGRA\u4e0a\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7f16\u8bd1\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u89e3\u8026\u65f6\u95f4\u548c\u7a7a\u95f4\u7ef4\u5ea6\u7684\u6620\u5c04\u65b9\u6cd5\uff1a\u9996\u5148\u4f7f\u7528SMT\u516c\u5f0f\u904d\u5386\u65f6\u95f4\u7ef4\u5ea6\uff0c\u7136\u540e\u57fa\u4e8e\u5355\u6001\u641c\u7d22\u5bfb\u627e\u6709\u6548\u7684\u7a7a\u95f4\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u5728\u4fdd\u6301\u4e0e\u6700\u5148\u8fdb\u6280\u672f\u76f8\u540c\u6620\u5c04\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u7f16\u8bd1\u65f6\u95f4\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21CGRA\u4e0a\u6548\u679c\u663e\u8457\u3002\u572820\u00d720 CGRA\u4e0a\u5b9e\u73b0\u7ea610^5\u500d\u7684\u5e73\u5747\u7f16\u8bd1\u52a0\u901f\u3002", "conclusion": "\u63d0\u51fa\u7684\u89e3\u8026\u65f6\u95f4-\u7a7a\u95f4\u7ef4\u5ea6\u6620\u5c04\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86CGRA\u7f16\u8bd1\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u5728\u5927\u89c4\u6a21CGRA\u4e0a\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u7f16\u8bd1\u901f\u5ea6\u63d0\u5347\u3002"}}
{"id": "2512.02875", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02875", "abs": "https://arxiv.org/abs/2512.02875", "authors": ["Cristian Tirelli", "Lorenzo Ferretti", "Laura Pozzi"], "title": "SAT-MapIt: A SAT-based Modulo Scheduling Mapper for Coarse Grain Reconfigurable Architectures", "comment": null, "summary": "Coarse-Grain Reconfigurable Arrays (CGRAs) are emerging low-power architectures aimed at accelerating compute-intensive application loops. The acceleration that a CGRA can ultimately provide, however, heavily depends on the quality of the mapping, i.e. on how effectively the loop is compiled onto the given platform. State of the Art compilation techniques achieve mapping through modulo scheduling, a strategy which attempts to minimize the II (Iteration Interval) needed to execute a loop, and they do so usually through well known graph algorithms, such as Max-Clique Enumeration.\n  We address the mapping problem through a SAT formulation, instead, and thus explore the solution space more effectively than current SoA tools. To formulate the SAT problem, we introduce an ad-hoc schedule called the \\textit{kernel mobility schedule} (KMS), which we use in conjunction with the data-flow graph and the architectural information of the CGRA in order to create a set of boolean statements that describe all constraints to be obeyed by the mapping for a given II. We then let the SAT solver efficiently navigate this complex space. As in other SoA techniques, the process is iterative: if a valid mapping does not exist for the given II, the II is increased and a new KMS and set of constraints is generated and solved.\n  Our experimental results show that SAT-MapIt obtains better results compared to SoA alternatives in $47.72\\%$ of the benchmarks explored: sometimes finding a lower II, and others even finding a valid mapping when none could previously be found.", "AI": {"tldr": "SAT-MapIt\uff1a\u4f7f\u7528SAT\u6c42\u89e3\u5668\u4e3aCGRA\u8fdb\u884c\u6620\u5c04\u7f16\u8bd1\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u572847.72%\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u66f4\u597d", "motivation": "CGRA\uff08\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217\uff09\u662f\u65b0\u5174\u7684\u4f4e\u529f\u8017\u67b6\u6784\uff0c\u7528\u4e8e\u52a0\u901f\u8ba1\u7b97\u5bc6\u96c6\u578b\u5faa\u73af\u3002\u4f46\u52a0\u901f\u6548\u679c\u4e25\u91cd\u4f9d\u8d56\u4e8e\u6620\u5c04\u8d28\u91cf\uff0c\u73b0\u6709\u6280\u672f\u4f7f\u7528\u6a21\u8c03\u5ea6\u548c\u56fe\u7b97\u6cd5\uff08\u5982\u6700\u5927\u56e2\u679a\u4e3e\uff09\uff0c\u5b58\u5728\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u57fa\u4e8eSAT\uff08\u53ef\u6ee1\u8db3\u6027\uff09\u7684\u6620\u5c04\u65b9\u6cd5\uff1a1\uff09\u5f15\u5165\u6838\u79fb\u52a8\u6027\u8c03\u5ea6\uff08KMS\uff09\u4f5c\u4e3a\u7279\u6b8a\u8c03\u5ea6\u65b9\u6848\uff1b2\uff09\u7ed3\u5408\u6570\u636e\u6d41\u56fe\u548cCGRA\u67b6\u6784\u4fe1\u606f\u751f\u6210\u5e03\u5c14\u7ea6\u675f\uff1b3\uff09\u4f7f\u7528SAT\u6c42\u89e3\u5668\u9ad8\u6548\u641c\u7d22\u89e3\u7a7a\u95f4\uff1b4\uff09\u91c7\u7528\u8fed\u4ee3\u8fc7\u7a0b\uff0c\u5982\u679c\u5f53\u524dII\uff08\u8fed\u4ee3\u95f4\u9694\uff09\u65e0\u89e3\u5219\u589e\u52a0II\u91cd\u65b0\u6c42\u89e3\u3002", "result": "SAT-MapIt\u572847.72%\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff1a\u6709\u65f6\u627e\u5230\u66f4\u4f4e\u7684II\uff0c\u6709\u65f6\u5728\u73b0\u6709\u65b9\u6cd5\u65e0\u6cd5\u627e\u5230\u6620\u5c04\u7684\u60c5\u51b5\u4e0b\u627e\u5230\u6709\u6548\u6620\u5c04\u3002", "conclusion": "\u57fa\u4e8eSAT\u7684\u6620\u5c04\u65b9\u6cd5\u6bd4\u73b0\u6709\u56fe\u7b97\u6cd5\u66f4\u6709\u6548\u5730\u63a2\u7d22\u89e3\u7a7a\u95f4\uff0c\u4e3aCGRA\u7f16\u8bd1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6620\u5c04\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.02884", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.02884", "abs": "https://arxiv.org/abs/2512.02884", "authors": ["Cristian Tirelli", "Laura Pozzi"], "title": "Mapping code on Coarse Grained Reconfigurable Arrays using a SAT solver", "comment": null, "summary": "Emerging low-powered architectures like Coarse-Grain Reconfigurable Arrays (CGRAs) are becoming more common. Often included as co-processors, they are used to accelerate compute-intensive workloads like loops. The speedup obtained is defined by the hardware design of the accelerator and by the quality of the compilation. State of the art (SoA) compilation techniques leverage modulo scheduling to minimize the Iteration Interval (II), exploit the architecture parallelism and, consequentially, reduce the execution time of the accelerated workload. In our work, we focus on improving the compilation process by finding the lowest II for any given topology, through a satisfiability (SAT) formulation of the mapping problem. We introduce a novel schedule, called Kernel Mobility Schedule, to encode all the possible mappings for a given Data Flow Graph (DFG) and for a given II. The schedule is used together with the CGRA architectural information to generate all the constraints necessary to find a valid mapping. Experimental results demonstrate that our method not only reduces compilation time on average but also achieves higher quality mappings compared to existing SoA techniques.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSAT\u7684CGRA\u6620\u5c04\u65b9\u6cd5\uff0c\u901a\u8fc7Kernel Mobility Schedule\u7f16\u7801\u6240\u6709\u53ef\u80fd\u6620\u5c04\uff0c\u663e\u8457\u51cf\u5c11\u7f16\u8bd1\u65f6\u95f4\u5e76\u63d0\u9ad8\u6620\u5c04\u8d28\u91cf", "motivation": "CGRA\u4f5c\u4e3a\u534f\u5904\u7406\u5668\u52a0\u901f\u8ba1\u7b97\u5bc6\u96c6\u578b\u5faa\u73af\uff0c\u73b0\u6709\u7f16\u8bd1\u6280\u672f\u4f7f\u7528\u6a21\u8c03\u5ea6\u6700\u5c0f\u5316\u8fed\u4ee3\u95f4\u9694\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u7f16\u8bd1\u65b9\u6cd5", "method": "\u4f7f\u7528\u53ef\u6ee1\u8db3\u6027(SAT)\u516c\u5f0f\u5316\u6620\u5c04\u95ee\u9898\uff0c\u5f15\u5165Kernel Mobility Schedule\u7f16\u7801\u7ed9\u5b9a\u6570\u636e\u6d41\u56fe\u548c\u8fed\u4ee3\u95f4\u9694\u7684\u6240\u6709\u53ef\u80fd\u6620\u5c04\uff0c\u7ed3\u5408CGRA\u67b6\u6784\u4fe1\u606f\u751f\u6210\u7ea6\u675f\u6761\u4ef6", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5e73\u5747\u51cf\u5c11\u7f16\u8bd1\u65f6\u95f4\uff0c\u800c\u4e14\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u83b7\u5f97\u66f4\u9ad8\u8d28\u91cf\u7684\u6620\u5c04", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8eSAT\u7684\u7f16\u8bd1\u65b9\u6cd5\u80fd\u6709\u6548\u627e\u5230\u4efb\u610f\u62d3\u6251\u7ed3\u6784\u7684\u6700\u4f4e\u8fed\u4ee3\u95f4\u9694\uff0c\u5728\u7f16\u8bd1\u65f6\u95f4\u548c\u6620\u5c04\u8d28\u91cf\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u6280\u672f"}}
