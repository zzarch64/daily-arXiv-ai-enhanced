{"id": "2511.16831", "categories": ["cs.AR", "cs.GR"], "pdf": "https://arxiv.org/pdf/2511.16831", "abs": "https://arxiv.org/abs/2511.16831", "authors": ["Yipeng Wang", "Mengtian Yang", "Chieh-pu Lo", "Jaydeep P. Kulkarni"], "title": "Vorion: A RISC-V GPU with Hardware-Accelerated 3D Gaussian Rendering and Training", "comment": null, "summary": "3D Gaussian Splatting (3DGS) has recently emerged as a foundational technique for real-time neural rendering, 3D scene generation, volumetric video (4D) capture. However, its rendering and training impose massive computation, making real-time rendering on edge devices and real-time 4D reconstruction on workstations currently infeasible. Given its fixed-function nature and similarity with traditional rasterization, 3DGS presents a strong case for dedicated hardware in the graphics pipeline of next-generation GPUs. This work, Vorion, presents the first GPGPU prototype with hardware-accelerated 3DGS rendering and training. Vorion features scalable architecture, minimal hardware change to traditional rasterizers, z-tiling to increase parallelism, and Gaussian/pixel-centric hybrid dataflow. We prototype the minimal system (8 SIMT cores, 2 Gaussian rasterizer) using TSMC 16nm FinFET technology, which achieves 19 FPS for rendering. The scaled design with 16 rasterizers achieves 38.6 iterations/s for training.", "AI": {"tldr": "Vorion\u662f\u9996\u4e2a\u652f\u6301\u786c\u4ef6\u52a0\u901f3D\u9ad8\u65af\u6cfc\u6e85\u6e32\u67d3\u548c\u8bad\u7ec3\u7684GPGPU\u539f\u578b\uff0c\u901a\u8fc7\u53ef\u6269\u5c55\u67b6\u6784\u3001\u6700\u5c0f\u786c\u4ef6\u6539\u52a8\u548c\u6df7\u5408\u6570\u636e\u6d41\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\u3002", "motivation": "3D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u867d\u7136\u524d\u666f\u5e7f\u9614\uff0c\u4f46\u5176\u6e32\u67d3\u548c\u8bad\u7ec3\u8ba1\u7b97\u91cf\u5de8\u5927\uff0c\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f6\u6e32\u67d3\uff0c\u5728\u5de5\u4f5c\u7ad9\u4e0a\u65e0\u6cd5\u5b9e\u73b0\u5b9e\u65f64D\u91cd\u5efa\uff0c\u9700\u8981\u4e13\u7528\u786c\u4ef6\u652f\u6301\u3002", "method": "\u91c7\u7528\u53ef\u6269\u5c55\u67b6\u6784\uff0c\u5bf9\u4f20\u7edf\u5149\u6805\u5316\u5668\u8fdb\u884c\u6700\u5c0f\u786c\u4ef6\u6539\u52a8\uff0c\u5f15\u5165z-tiling\u589e\u52a0\u5e76\u884c\u6027\uff0c\u4f7f\u7528\u9ad8\u65af/\u50cf\u7d20\u4e2d\u5fc3\u6df7\u5408\u6570\u636e\u6d41\uff0c\u5728TSMC 16nm\u5de5\u827a\u4e0a\u5b9e\u73b0\u539f\u578b\u7cfb\u7edf\u3002", "result": "\u6700\u5c0f\u7cfb\u7edf\uff088\u4e2aSIMT\u6838\u5fc3\uff0c2\u4e2a\u9ad8\u65af\u5149\u6805\u5316\u5668\uff09\u5b9e\u73b019 FPS\u6e32\u67d3\u6027\u80fd\uff1b\u6269\u5c55\u8bbe\u8ba1\uff0816\u4e2a\u5149\u6805\u5316\u5668\uff09\u8fbe\u523038.6\u6b21\u8fed\u4ee3/\u79d2\u7684\u8bad\u7ec3\u901f\u5ea6\u3002", "conclusion": "Vorion\u8bc1\u660e\u4e863D\u9ad8\u65af\u6cfc\u6e85\u6280\u672f\u5728\u4e13\u7528\u786c\u4ef6\u4e0a\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u4e0b\u4e00\u4ee3GPU\u56fe\u5f62\u7ba1\u7ebf\u63d0\u4f9b\u4e86\u786c\u4ef6\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17123", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.17123", "abs": "https://arxiv.org/abs/2511.17123", "authors": ["Jiaxun Fang", "Li Zhang", "Shaoyi Huang"], "title": "Layer-wise Weight Selection for Power-Efficient Neural Network Acceleration", "comment": null, "summary": "Systolic array accelerators execute CNNs with energy dominated by the switching activity of multiply accumulate (MAC) units. Although prior work exploits weight dependent MAC power for compression, existing methods often use global activation models, coarse energy proxies, or layer-agnostic policies, which limits their effectiveness on real hardware. We propose an energy aware, layer-wise compression framework that explicitly leverages MAC and layer level energy characteristics. First, we build a layer-aware MAC energy model that combines per-layer activation statistics with an MSB-Hamming distance grouping of 22-bit partial sum transitions, and integrate it with a tile-level systolic mapping to estimate convolution-layer energy. On top of this model, we introduce an energy accuracy co-optimized weight selection algorithm within quantization aware training and an energy-prioritized layer-wise schedule that compresses high energy layers more aggressively under a global accuracy constraint. Experiments on different CNN models demonstrate up to 58.6\\% energy reduction with 2-3\\% accuracy drop, outperforming a state-of-the-art power-aware baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u91cf\u611f\u77e5\u7684\u9010\u5c42\u538b\u7f29\u6846\u67b6\uff0c\u901a\u8fc7\u5c42\u611f\u77e5MAC\u80fd\u91cf\u6a21\u578b\u548c\u80fd\u91cf-\u7cbe\u5ea6\u534f\u540c\u4f18\u5316\u7684\u6743\u91cd\u9009\u62e9\u7b97\u6cd5\uff0c\u5728CNN\u6a21\u578b\u4e0a\u5b9e\u73b0\u6700\u9ad858.6%\u7684\u80fd\u91cf\u51cf\u5c11\uff0c\u7cbe\u5ea6\u4ec5\u4e0b\u964d2-3%\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4f7f\u7528\u5168\u5c40\u6fc0\u6d3b\u6a21\u578b\u3001\u7c97\u7c92\u5ea6\u80fd\u91cf\u4ee3\u7406\u6216\u5c42\u65e0\u5173\u7b56\u7565\uff0c\u9650\u5236\u4e86\u5728\u771f\u5b9e\u786c\u4ef6\u4e0a\u7684\u6709\u6548\u6027\u3002\u9700\u8981\u66f4\u7cbe\u786e\u7684\u5c42\u7ea7\u80fd\u91cf\u7279\u6027\u548cMAC\u80fd\u91cf\u6a21\u578b\u3002", "method": "\u6784\u5efa\u5c42\u611f\u77e5MAC\u80fd\u91cf\u6a21\u578b\uff0c\u7ed3\u5408\u6bcf\u5c42\u6fc0\u6d3b\u7edf\u8ba1\u548c22\u4f4d\u90e8\u5206\u548c\u8f6c\u6362\u7684MSB-Hamming\u8ddd\u79bb\u5206\u7ec4\uff1b\u5728\u91cf\u5316\u611f\u77e5\u8bad\u7ec3\u4e2d\u5f15\u5165\u80fd\u91cf-\u7cbe\u5ea6\u534f\u540c\u4f18\u5316\u7684\u6743\u91cd\u9009\u62e9\u7b97\u6cd5\uff1b\u91c7\u7528\u80fd\u91cf\u4f18\u5148\u7684\u9010\u5c42\u8c03\u5ea6\u7b56\u7565\u3002", "result": "\u5728\u4e0d\u540cCNN\u6a21\u578b\u4e0a\u5b9e\u9a8c\u8868\u660e\uff0c\u6700\u9ad8\u53ef\u5b9e\u73b058.6%\u7684\u80fd\u91cf\u51cf\u5c11\uff0c\u7cbe\u5ea6\u4ec5\u4e0b\u964d2-3%\uff0c\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7684\u529f\u7387\u611f\u77e5\u57fa\u51c6\u65b9\u6cd5\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u80fd\u91cf\u611f\u77e5\u9010\u5c42\u538b\u7f29\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11CNN\u5728\u8109\u52a8\u9635\u5217\u52a0\u901f\u5668\u4e0a\u7684\u80fd\u91cf\u6d88\u8017\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u7cbe\u5ea6\u635f\u5931\u3002"}}
{"id": "2511.17235", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.17235", "abs": "https://arxiv.org/abs/2511.17235", "authors": ["Rohit Prasad"], "title": "NX-CGRA: A Programmable Hardware Accelerator for Core Transformer Algorithms on Edge Devices", "comment": "This paper has been accepted for publication at the Design, Automation and Test in Europe (DATE) Conference 2026. 2026 IEEE. Personal use of this material is permitted", "summary": "The increasing diversity and complexity of transformer workloads at the edge present significant challenges in balancing performance, energy efficiency, and architectural flexibility. This paper introduces NX-CGRA, a programmable hardware accelerator designed to support a range of transformer inference algorithms, including both linear and non-linear functions. Unlike fixed-function accelerators optimized for narrow use cases, NX-CGRA employs a coarse-grained reconfigurable array (CGRA) architecture with software-driven programmability, enabling efficient execution across varied kernel patterns. The architecture is evaluated using representative benchmarks derived from real-world transformer models, demonstrating high overall efficiency and favorable energy-area tradeoffs across different classes of operations. These results indicate the potential of NX-CGRA as a scalable and adaptable hardware solution for edge transformer deployment under constrained power and silicon budgets.", "AI": {"tldr": "NX-CGRA\u662f\u4e00\u79cd\u53ef\u7f16\u7a0b\u786c\u4ef6\u52a0\u901f\u5668\uff0c\u91c7\u7528\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217\u67b6\u6784\uff0c\u652f\u6301\u591a\u79cdtransformer\u63a8\u7406\u7b97\u6cd5\uff0c\u5728\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u4e0b\u5b9e\u73b0\u6027\u80fd\u3001\u80fd\u6548\u548c\u67b6\u6784\u7075\u6d3b\u6027\u7684\u5e73\u8861\u3002", "motivation": "\u8fb9\u7f18\u8ba1\u7b97\u4e2dtransformer\u5de5\u4f5c\u8d1f\u8f7d\u7684\u591a\u6837\u6027\u548c\u590d\u6742\u6027\u65e5\u76ca\u589e\u52a0\uff0c\u9700\u8981\u5728\u6027\u80fd\u3001\u80fd\u6548\u548c\u67b6\u6784\u7075\u6d3b\u6027\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\uff0c\u800c\u56fa\u5b9a\u529f\u80fd\u52a0\u901f\u5668\u65e0\u6cd5\u6ee1\u8db3\u8fd9\u79cd\u9700\u6c42\u3002", "method": "\u91c7\u7528\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217(CGRA)\u67b6\u6784\uff0c\u5177\u6709\u8f6f\u4ef6\u9a71\u52a8\u7684\u53ef\u7f16\u7a0b\u6027\uff0c\u80fd\u591f\u9ad8\u6548\u6267\u884c\u5404\u79cd\u5185\u6838\u6a21\u5f0f\uff0c\u5305\u62ec\u7ebf\u6027\u548c\u975e\u7ebf\u6027\u51fd\u6570\u3002", "result": "\u4f7f\u7528\u771f\u5b9etransformer\u6a21\u578b\u7684\u4ee3\u8868\u6027\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86\u9ad8\u6574\u4f53\u6548\u7387\u548c\u826f\u597d\u7684\u80fd\u8017-\u9762\u79ef\u6743\u8861\uff0c\u9002\u7528\u4e8e\u4e0d\u540c\u7c7b\u522b\u7684\u64cd\u4f5c\u3002", "conclusion": "NX-CGRA\u4f5c\u4e3a\u53ef\u6269\u5c55\u548c\u9002\u5e94\u6027\u5f3a\u7684\u786c\u4ef6\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u53d7\u9650\u7684\u529f\u8017\u548c\u7845\u9762\u79ef\u9884\u7b97\u4e0b\u5177\u6709\u5728\u8fb9\u7f18\u90e8\u7f72transformer\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.17265", "categories": ["cs.AR", "cs.AI", "cs.ET", "cs.PF"], "pdf": "https://arxiv.org/pdf/2511.17265", "abs": "https://arxiv.org/abs/2511.17265", "authors": ["Shady Agwa", "Yikang Shen", "Shiwei Wang", "Themis Prodromakis"], "title": "DISCA: A Digital In-memory Stochastic Computing Architecture Using A Compressed Bent-Pyramid Format", "comment": "6 pages, 5 figures", "summary": "Nowadays, we are witnessing an Artificial Intelligence revolution that dominates the technology landscape in various application domains, such as healthcare, robotics, automotive, security, and defense. Massive-scale AI models, which mimic the human brain's functionality, typically feature millions and even billions of parameters through data-intensive matrix multiplication tasks. While conventional Von-Neumann architectures struggle with the memory wall and the end of Moore's Law, these AI applications are migrating rapidly towards the edge, such as in robotics and unmanned aerial vehicles for surveillance, thereby adding more constraints to the hardware budget of AI architectures at the edge. Although in-memory computing has been proposed as a promising solution for the memory wall, both analog and digital in-memory computing architectures suffer from substantial degradation of the proposed benefits due to various design limitations. We propose a new digital in-memory stochastic computing architecture, DISCA, utilizing a compressed version of the quasi-stochastic Bent-Pyramid data format. DISCA inherits the same computational simplicity of analog computing, while preserving the same scalability, productivity, and reliability of digital systems. Post-layout modeling results of DISCA show an energy efficiency of 3.59 TOPS/W per bit at 500 MHz using a commercial 180nm CMOS technology. Therefore, DISCA significantly improves the energy efficiency for matrix multiplication workloads by orders of magnitude if scaled and compared to its counterpart architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6570\u5b57\u5185\u5b58\u968f\u673a\u8ba1\u7b97\u67b6\u6784DISCA\uff0c\u91c7\u7528\u538b\u7f29\u7684\u51c6\u968f\u673aBent-Pyramid\u6570\u636e\u683c\u5f0f\uff0c\u5728\u4fdd\u6301\u6570\u5b57\u7cfb\u7edf\u53ef\u6269\u5c55\u6027\u548c\u53ef\u9760\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u7c7b\u4f3c\u6a21\u62df\u8ba1\u7b97\u7684\u7b80\u5355\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u77e9\u9635\u4e58\u6cd5\u4efb\u52a1\u7684\u80fd\u6548\u3002", "motivation": "AI\u5e94\u7528\u5411\u8fb9\u7f18\u8fc1\u79fb\u9762\u4e34\u786c\u4ef6\u9884\u7b97\u7ea6\u675f\uff0c\u4f20\u7edf\u51af\u00b7\u8bfa\u4f9d\u66fc\u67b6\u6784\u53d7\u9650\u4e8e\u5185\u5b58\u5899\u548c\u6469\u5c14\u5b9a\u5f8b\u7ec8\u7ed3\uff0c\u73b0\u6709\u5185\u5b58\u8ba1\u7b97\u67b6\u6784\u56e0\u8bbe\u8ba1\u9650\u5236\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u91c7\u7528\u538b\u7f29\u7684\u51c6\u968f\u673aBent-Pyramid\u6570\u636e\u683c\u5f0f\u7684\u6570\u5b57\u5185\u5b58\u968f\u673a\u8ba1\u7b97\u67b6\u6784DISCA\uff0c\u7ed3\u5408\u4e86\u6a21\u62df\u8ba1\u7b97\u7684\u7b80\u5355\u6027\u548c\u6570\u5b57\u7cfb\u7edf\u7684\u4f18\u52bf\u3002", "result": "\u540e\u5e03\u5c40\u5efa\u6a21\u663e\u793a\uff0c\u5728180nm CMOS\u6280\u672f\u4e0b\uff0cDISCA\u5728500MHz\u9891\u7387\u4e0b\u5b9e\u73b0\u6bcf\u6bd4\u72793.59 TOPS/W\u7684\u80fd\u6548\u3002", "conclusion": "DISCA\u76f8\u6bd4\u540c\u7c7b\u67b6\u6784\u5c06\u77e9\u9635\u4e58\u6cd5\u5de5\u4f5c\u8d1f\u8f7d\u7684\u80fd\u6548\u63d0\u5347\u4e86\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u4e3a\u8fb9\u7f18AI\u5e94\u7528\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.17418", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.17418", "abs": "https://arxiv.org/abs/2511.17418", "authors": ["Houji Zhou", "Ling Yang", "Zhiwei Zhou", "Yi Li", "Xiangshui Miao"], "title": "MemIntelli: A Generic End-to-End Simulation Framework for Memristive Intelligent Computing", "comment": null, "summary": "Memristive in-memory computing (IMC) has emerged as a promising solution for addressing the bottleneck in the Von Neumann architecture. However, the couplingbetweenthecircuitandalgorithm in IMC makes computing reliability susceptible to non-ideal effects in devices and peripheral circuits. In this respect, efficient softwarehardwareco-simulationtoolsarehighlydesiredtoembedthedevice and circuit models into the algorithms. In this paper, for the first time, we proposed an end-to-end simulation framework supporting flexible variable-precision computing, named MemIntelli, to realize the pre-verification of diverse intelligent applications on memristive devices. At the device and circuit level, mathematical functions are employed to abstract the devices and circuits through meticulous equivalent circuit modeling. On the architecture level, MemIntelli achieves flexible variable-precision IMC supporting integer and floating data representation with bit-slicing. Moreover, MemIntelli is compatible with NumPy and PyTorch for seamless integration with applications. To demonstrate its capabilities, diverse intelligent algorithms, such as equation solving, data clustering, wavelet transformation, and neural network training and inference, were employed to showcase the robust processing ability of MemIntelli. This research presents a comprehensive simulation tool that facilitates the co-design of the IMC system, spanning from device to application.", "AI": {"tldr": "\u63d0\u51fa\u4e86MemIntelli\u7aef\u5230\u7aef\u4eff\u771f\u6846\u67b6\uff0c\u652f\u6301\u7075\u6d3b\u53ef\u53d8\u7cbe\u5ea6\u8ba1\u7b97\uff0c\u5b9e\u73b0\u5fc6\u963b\u5668\u4e0a\u591a\u6837\u5316\u667a\u80fd\u5e94\u7528\u7684\u9884\u9a8c\u8bc1", "motivation": "\u5fc6\u963b\u5185\u5b58\u8ba1\u7b97\u4e2d\u7535\u8def\u4e0e\u7b97\u6cd5\u7684\u8026\u5408\u4f7f\u5f97\u8ba1\u7b97\u53ef\u9760\u6027\u6613\u53d7\u5668\u4ef6\u548c\u5916\u56f4\u7535\u8def\u975e\u7406\u60f3\u6548\u5e94\u5f71\u54cd\uff0c\u9700\u8981\u9ad8\u6548\u7684\u8f6f\u786c\u4ef6\u534f\u540c\u4eff\u771f\u5de5\u5177", "method": "\u5728\u5668\u4ef6\u548c\u7535\u8def\u5c42\u9762\u4f7f\u7528\u6570\u5b66\u51fd\u6570\u8fdb\u884c\u7b49\u6548\u7535\u8def\u5efa\u6a21\uff0c\u5728\u67b6\u6784\u5c42\u9762\u5b9e\u73b0\u652f\u6301\u6574\u6570\u548c\u6d6e\u70b9\u6570\u636e\u8868\u793a\u7684\u7075\u6d3b\u53ef\u53d8\u7cbe\u5ea6\u5185\u5b58\u8ba1\u7b97\uff0c\u517c\u5bb9NumPy\u548cPyTorch", "result": "\u5c55\u793a\u4e86\u65b9\u7a0b\u6c42\u89e3\u3001\u6570\u636e\u805a\u7c7b\u3001\u5c0f\u6ce2\u53d8\u6362\u3001\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u63a8\u7406\u7b49\u591a\u79cd\u667a\u80fd\u7b97\u6cd5\u7684\u5f3a\u5927\u5904\u7406\u80fd\u529b", "conclusion": "\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4ece\u5668\u4ef6\u5230\u5e94\u7528\u7684\u5168\u9762\u4eff\u771f\u5de5\u5177\uff0c\u4fc3\u8fdb\u5185\u5b58\u8ba1\u7b97\u7cfb\u7edf\u7684\u534f\u540c\u8bbe\u8ba1"}}
