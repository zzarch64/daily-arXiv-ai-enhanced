{"id": "2602.17114", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.17114", "abs": "https://arxiv.org/abs/2602.17114", "authors": ["Seemron Neupane", "Aashish Ghimire"], "title": "Low-Cost IoT-Enabled Tele-ECG Monitoring for Resource-Constrained Settings: System Design and Prototype", "comment": null, "summary": "With the availability of automation machinery and its superiority, are being slothful and inviting many diseases to invade them. The world still has so many places where people lack basic health facilities. Due to early detection and intervention, CDV can be cured to an extreme extent. It heavily reduces travel and associated costs. A remote ECG monitoring system enables community health workers to support and empower patients through telemedicine. However, there remains some financial and logistical burden. Heart disease cannot be taken lightly. These patients require regular health check-ups and the attention of health personnel in a short period if their health deteriorates suddenly and rapidly. Chronic diseases are extremely variable in their symptoms and evolution of treatment. Some, if not treated early, will end the patient's life. The trend of the INTERNET OF THINGS, IoT, is spreading massively. This paper focuses on the three main: the operator, the doctor, and the server over which the data is being sent.", "AI": {"tldr": "\u57fa\u4e8e\u7269\u8054\u7f51\u7684\u8fdc\u7a0bECG\u76d1\u6d4b\u7cfb\u7edf\uff0c\u901a\u8fc7\u8fd0\u8425\u5546\u3001\u533b\u751f\u548c\u670d\u52a1\u5668\u4e09\u65b9\u534f\u4f5c\uff0c\u5b9e\u73b0\u5fc3\u8840\u7ba1\u75be\u75c5\u7684\u65e9\u671f\u68c0\u6d4b\u548c\u8fdc\u7a0b\u533b\u7597\u652f\u6301", "motivation": "\u968f\u7740\u81ea\u52a8\u5316\u673a\u68b0\u666e\u53ca\u5bfc\u81f4\u4eba\u4eec\u8fd0\u52a8\u51cf\u5c11\u3001\u75be\u75c5\u589e\u591a\uff0c\u8bb8\u591a\u5730\u533a\u7f3a\u4e4f\u57fa\u672c\u533b\u7597\u8bbe\u65bd\u3002\u5fc3\u8840\u7ba1\u75be\u75c5\uff08CDV\uff09\u901a\u8fc7\u65e9\u671f\u68c0\u6d4b\u548c\u5e72\u9884\u53ef\u5927\u5e45\u6cbb\u6108\uff0c\u4f46\u5b58\u5728\u8d22\u52a1\u548c\u7269\u6d41\u8d1f\u62c5\u3002\u60a3\u8005\u9700\u8981\u5b9a\u671f\u5065\u5eb7\u68c0\u67e5\u548c\u7d27\u6025\u533b\u7597\u5173\u6ce8\uff0c\u6162\u6027\u75be\u75c5\u75c7\u72b6\u591a\u53d8\u4e14\u9700\u8981\u53ca\u65f6\u6cbb\u7597", "method": "\u91c7\u7528\u7269\u8054\u7f51\uff08IoT\uff09\u6280\u672f\u6784\u5efa\u8fdc\u7a0bECG\u76d1\u6d4b\u7cfb\u7edf\uff0c\u91cd\u70b9\u5173\u6ce8\u4e09\u4e2a\u4e3b\u8981\u7ec4\u6210\u90e8\u5206\uff1a\u8fd0\u8425\u5546\uff08\u8d1f\u8d23\u6570\u636e\u4f20\u8f93\uff09\u3001\u533b\u751f\uff08\u63d0\u4f9b\u533b\u7597\u652f\u6301\uff09\u548c\u670d\u52a1\u5668\uff08\u5904\u7406\u548c\u5206\u6790\u6570\u636e\uff09", "result": "\u8fdc\u7a0bECG\u76d1\u6d4b\u7cfb\u7edf\u80fd\u591f\u663e\u8457\u51cf\u5c11\u65c5\u884c\u548c\u76f8\u5173\u6210\u672c\uff0c\u4f7f\u793e\u533a\u536b\u751f\u5de5\u4f5c\u8005\u80fd\u591f\u901a\u8fc7\u8fdc\u7a0b\u533b\u7597\u652f\u6301\u548c\u8d4b\u80fd\u60a3\u8005\uff0c\u5b9e\u73b0\u5fc3\u8840\u7ba1\u75be\u75c5\u7684\u65e9\u671f\u68c0\u6d4b\u548c\u5e72\u9884", "conclusion": "\u7269\u8054\u7f51\u6280\u672f\u5728\u533b\u7597\u9886\u57df\u7684\u5e94\u7528\uff0c\u7279\u522b\u662f\u8fdc\u7a0bECG\u76d1\u6d4b\u7cfb\u7edf\uff0c\u4e3a\u89e3\u51b3\u533b\u7597\u8d44\u6e90\u4e0d\u8db3\u3001\u964d\u4f4e\u533b\u7597\u6210\u672c\u3001\u5b9e\u73b0\u65e9\u671f\u75be\u75c5\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5bf9\u5fc3\u8840\u7ba1\u75be\u75c5\u7ba1\u7406\u5177\u6709\u91cd\u8981\u610f\u4e49"}}
{"id": "2602.17119", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.17119", "abs": "https://arxiv.org/abs/2602.17119", "authors": ["Zhenyu Bai", "Pranav Dangi", "Rohan Juneja", "Zhaoying Li", "Zhanglu Yan", "Huiying Lan", "Tulika Mitra"], "title": "A Data-Driven Dynamic Execution Orchestration Architecture", "comment": "ASPLOS 2026", "summary": "Domain-specific accelerators deliver exceptional performance on their target workloads through fabrication-time orchestrated datapaths. However, such specialized architectures often exhibit performance fragility when exposed to new kernels or irregular input patterns. In contrast, programmable architectures like FPGAs, CGRAs, and GPUs rely on compile-time orchestration to support a broader range of applications; but they are typically less efficient under irregular or sparse data. Pushing the boundaries of programmable architectures requires designs that can achieve efficiency and high-performance on par with specialized accelerators while retaining the agility of general-purpose architectures.\n  We introduce Canon, a parallel architecture that bridges the gap between specialized and general purpose architectures. Canon exploits data-level and instruction-level parallelism through its novel design. First, it employs a novel dynamic data-driven orchestration mechanism using programmable Finite State Machines (FSMs). These FSMs are programmed at compile time to encode high-level dataflow per state and translate incoming meta-information (e.g., sparse coordinates) into control instructions at runtime. Second, Canon introduces a time-lapsed SIMD execution in which instructions are issued across a row of processing elements over several cycles, creating a staggered pipelined execution. These innovations amortize control overhead, allowing dynamic instruction changes while constructing a continuously evolving dataflow that maximizes parallelism. Experimental evaluation shows that Canon delivers high performance across diverse data-agnostic and data-driven kernels while achieving efficiency comparable to specialized accelerators, yet retaining the flexibility of a general-purpose architecture.", "AI": {"tldr": "Canon\u662f\u4e00\u79cd\u65b0\u578b\u5e76\u884c\u67b6\u6784\uff0c\u901a\u8fc7\u52a8\u6001\u6570\u636e\u9a71\u52a8\u7f16\u6392\u548c\u65f6\u95f4\u9519\u4f4dSIMD\u6267\u884c\uff0c\u5728\u4fdd\u6301\u901a\u7528\u67b6\u6784\u7075\u6d3b\u6027\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u4e13\u7528\u52a0\u901f\u5668\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "motivation": "\u4e13\u7528\u52a0\u901f\u5668\u867d\u7136\u9488\u5bf9\u7279\u5b9a\u5de5\u4f5c\u8d1f\u8f7d\u5177\u6709\u4f18\u5f02\u6027\u80fd\uff0c\u4f46\u5bf9\u65b0\u5185\u6838\u6216\u4e0d\u89c4\u5219\u8f93\u5165\u6a21\u5f0f\u8868\u73b0\u8106\u5f31\uff1b\u800c\u53ef\u7f16\u7a0b\u67b6\u6784\uff08\u5982FPGA\u3001CGRA\u3001GPU\uff09\u867d\u7136\u652f\u6301\u66f4\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5728\u4e0d\u89c4\u5219\u6216\u7a00\u758f\u6570\u636e\u4e0b\u6548\u7387\u8f83\u4f4e\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u8fbe\u5230\u4e13\u7528\u52a0\u901f\u5668\u6548\u7387\uff0c\u53c8\u80fd\u4fdd\u6301\u901a\u7528\u67b6\u6784\u7075\u6d3b\u6027\u7684\u8bbe\u8ba1\u3002", "method": "1. \u4f7f\u7528\u53ef\u7f16\u7a0b\u6709\u9650\u72b6\u6001\u673a\uff08FSM\uff09\u5b9e\u73b0\u52a8\u6001\u6570\u636e\u9a71\u52a8\u7f16\u6392\u673a\u5236\uff0c\u5728\u7f16\u8bd1\u65f6\u7f16\u7801\u9ad8\u7ea7\u6570\u636e\u6d41\uff0c\u8fd0\u884c\u65f6\u5c06\u5143\u4fe1\u606f\uff08\u5982\u7a00\u758f\u5750\u6807\uff09\u8f6c\u6362\u4e3a\u63a7\u5236\u6307\u4ee4\uff1b2. \u5f15\u5165\u65f6\u95f4\u9519\u4f4dSIMD\u6267\u884c\uff0c\u6307\u4ee4\u5728\u591a\u4e2a\u5468\u671f\u5185\u8de8\u5904\u7406\u5355\u5143\u884c\u53d1\u51fa\uff0c\u521b\u5efa\u4ea4\u9519\u6d41\u6c34\u7ebf\u6267\u884c\u3002\u8fd9\u4e9b\u521b\u65b0\u5206\u644a\u4e86\u63a7\u5236\u5f00\u9500\uff0c\u5141\u8bb8\u52a8\u6001\u6307\u4ee4\u66f4\u6539\uff0c\u540c\u65f6\u6784\u5efa\u6301\u7eed\u6f14\u5316\u7684\u6570\u636e\u6d41\u4ee5\u6700\u5927\u5316\u5e76\u884c\u6027\u3002", "result": "\u5b9e\u9a8c\u8bc4\u4f30\u8868\u660e\uff0cCanon\u5728\u591a\u79cd\u6570\u636e\u65e0\u5173\u548c\u6570\u636e\u9a71\u52a8\u5185\u6838\u4e0a\u90fd\u80fd\u63d0\u4f9b\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u5b9e\u73b0\u4e0e\u4e13\u7528\u52a0\u901f\u5668\u76f8\u5f53\u7684\u6548\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u901a\u7528\u67b6\u6784\u7684\u7075\u6d3b\u6027\u3002", "conclusion": "Canon\u6210\u529f\u5f25\u5408\u4e86\u4e13\u7528\u67b6\u6784\u548c\u901a\u7528\u67b6\u6784\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u52a8\u6001\u7f16\u6392\u548c\u6267\u884c\u673a\u5236\uff0c\u5728\u4fdd\u6301\u7075\u6d3b\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u548c\u9ad8\u6548\u7387\uff0c\u4e3a\u53ef\u7f16\u7a0b\u67b6\u6784\u7684\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2602.17169", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.17169", "abs": "https://arxiv.org/abs/2602.17169", "authors": ["Yuhuan Xia", "Tun Li", "Hongji Zhou", "Xianfa Zhou", "Chong Chen", "Ruiyu Zhang"], "title": "SimulatorCoder: DNN Accelerator Simulator Code Generation and Optimization via Large Language Models", "comment": null, "summary": "This paper presents SimulatorCoder, an agent powered by large language models (LLMs), designed to generate and optimize deep neural network (DNN) accelerator simulators based on natural language descriptions. By integrating domain-specific prompt engineering including In-Context Learning (ICL), Chain-of-Thought (CoT) reasoning, and a multi-round feedback-verification flow, SimulatorCoder systematically transforms high-level functional requirements into efficient, executable, and architecture-aligned simulator code. Experiments based on the customized SCALE-Sim benchmark demonstrate that structured prompting and feedback mechanisms substantially improve both code generation accuracy and simulator performance. The resulting simulators not only maintain cycle-level fidelity with less than 1% error compared to manually implemented counterparts, but also consistently achieve lower simulation runtimes, highlighting the effectiveness of LLM-based methods in accelerating simulator development. Our code is available at https://github.com/xiayuhuan/SimulatorCoder.", "AI": {"tldr": "SimulatorCoder\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u667a\u80fd\u4f53\uff0c\u80fd\u591f\u6839\u636e\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u81ea\u52a8\u751f\u6210\u548c\u4f18\u5316\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u6a21\u62df\u5668\u4ee3\u7801\u3002", "motivation": "\u4f20\u7edfDNN\u52a0\u901f\u5668\u6a21\u62df\u5668\u5f00\u53d1\u9700\u8981\u5927\u91cf\u624b\u52a8\u7f16\u7801\u5de5\u4f5c\uff0c\u8017\u65f6\u4e14\u5bb9\u6613\u51fa\u9519\u3002\u7814\u7a76\u65e8\u5728\u5229\u7528LLM\u81ea\u52a8\u5316\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u52a0\u901f\u6a21\u62df\u5668\u5f00\u53d1\u6d41\u7a0b\u3002", "method": "\u7ed3\u5408\u9886\u57df\u7279\u5b9a\u7684\u63d0\u793a\u5de5\u7a0b\uff0c\u5305\u62ec\u4e0a\u4e0b\u6587\u5b66\u4e60\u3001\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u591a\u8f6e\u53cd\u9988\u9a8c\u8bc1\u6d41\u7a0b\uff0c\u5c06\u9ad8\u7ea7\u529f\u80fd\u9700\u6c42\u7cfb\u7edf\u6027\u5730\u8f6c\u5316\u4e3a\u9ad8\u6548\u3001\u53ef\u6267\u884c\u4e14\u67b6\u6784\u5bf9\u9f50\u7684\u6a21\u62df\u5668\u4ee3\u7801\u3002", "result": "\u5728\u5b9a\u5236\u7684SCALE-Sim\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u7ed3\u6784\u5316\u63d0\u793a\u548c\u53cd\u9988\u673a\u5236\u663e\u8457\u63d0\u9ad8\u4e86\u4ee3\u7801\u751f\u6210\u51c6\u786e\u6027\u548c\u6a21\u62df\u5668\u6027\u80fd\u3002\u751f\u6210\u7684\u6a21\u62df\u5668\u4e0e\u624b\u52a8\u5b9e\u73b0\u7248\u672c\u76f8\u6bd4\uff0c\u5468\u671f\u7ea7\u4fdd\u771f\u5ea6\u8bef\u5dee\u5c0f\u4e8e1%\uff0c\u540c\u65f6\u8fd0\u884c\u65f6\u95f4\u66f4\u4f4e\u3002", "conclusion": "LLM\u65b9\u6cd5\u5728\u52a0\u901f\u6a21\u62df\u5668\u5f00\u53d1\u65b9\u9762\u5177\u6709\u663e\u8457\u6548\u679c\uff0c\u80fd\u591f\u751f\u6210\u9ad8\u8d28\u91cf\u3001\u9ad8\u6027\u80fd\u7684\u6a21\u62df\u5668\u4ee3\u7801\uff0c\u4e3a\u786c\u4ef6\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.17520", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2602.17520", "abs": "https://arxiv.org/abs/2602.17520", "authors": ["Yogeswar Reddy Thota", "Setareh Rafatirad", "Homayoun Houman", "Tooraj Nikoubin"], "title": "When Models Ignore Definitions: Measuring Semantic Override Hallucinations in LLM Reasoning", "comment": null, "summary": "Large language models (LLMs) demonstrate strong performance on standard digital logic and Boolean reasoning tasks, yet their reliability under locally redefined semantics remains poorly understood. In many formal settings, such as circuit specifications, examinations, and hardware documentation, operators and components are explicitly redefined within narrow scope. Correct reasoning in these contexts requires models to temporarily suppress globally learned conventions in favor of prompt-local definitions. In this work, we study a systematic failure mode we term semantic override, in which an LLM reverts to its pretrained default interpretation of operators or gate behavior despite explicit redefinition in the prompt. We also identify a related class of errors, assumption injection, where models commit to unstated hardware semantics when critical details are underspecified, rather than requesting clarification. We introduce a compact micro-benchmark of 30 logic and digital-circuit reasoning tasks designed as verifier-style traps, spanning Boolean algebra, operator overloading, redefined gates, and circuit-level semantics. Evaluating three frontier LLMs, we observe persistent noncompliance with local specifications, confident but incompatible assumptions, and dropped constraints even in elementary settings. Our findings highlight a gap between surface-level correctness and specification-faithful reasoning, motivating evaluation protocols that explicitly test local unlearning and semantic compliance in formal domains.", "AI": {"tldr": "LLMs\u5728\u6807\u51c6\u6570\u5b57\u903b\u8f91\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u5c40\u90e8\u91cd\u5b9a\u4e49\u8bed\u4e49\u4e0b\u4f1a\u51fa\u73b0\"\u8bed\u4e49\u8986\u76d6\"\u548c\"\u5047\u8bbe\u6ce8\u5165\"\u7684\u7cfb\u7edf\u6027\u6545\u969c\uff0c\u65e0\u6cd5\u6b63\u786e\u6291\u5236\u9884\u8bad\u7ec3\u77e5\u8bc6\u800c\u9075\u5faa\u63d0\u793a\u4e2d\u7684\u5c40\u90e8\u5b9a\u4e49\u3002", "motivation": "\u7814\u7a76LLMs\u5728\u5c40\u90e8\u91cd\u5b9a\u4e49\u8bed\u4e49\u73af\u5883\u4e0b\u7684\u53ef\u9760\u6027\u95ee\u9898\u3002\u5728\u7535\u8def\u89c4\u8303\u3001\u8003\u8bd5\u3001\u786c\u4ef6\u6587\u6863\u7b49\u6b63\u5f0f\u573a\u666f\u4e2d\uff0c\u64cd\u4f5c\u7b26\u548c\u7ec4\u4ef6\u7ecf\u5e38\u5728\u72ed\u7a84\u8303\u56f4\u5185\u88ab\u663e\u5f0f\u91cd\u5b9a\u4e49\uff0c\u4f46LLMs\u80fd\u5426\u6682\u65f6\u6291\u5236\u5168\u5c40\u5b66\u4e60\u60ef\u4f8b\u800c\u9075\u5faa\u63d0\u793a\u4e2d\u7684\u5c40\u90e8\u5b9a\u4e49\u5c1a\u4e0d\u6e05\u695a\u3002", "method": "\u521b\u5efa\u5305\u542b30\u4e2a\u903b\u8f91\u548c\u6570\u5b57\u7535\u8def\u63a8\u7406\u4efb\u52a1\u7684\u5fae\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u5e03\u5c14\u4ee3\u6570\u3001\u64cd\u4f5c\u7b26\u91cd\u8f7d\u3001\u91cd\u5b9a\u4e49\u95e8\u548c\u7535\u8def\u7ea7\u8bed\u4e49\uff0c\u8bbe\u8ba1\u4e3a\u9a8c\u8bc1\u5668\u98ce\u683c\u7684\u9677\u9631\u3002\u8bc4\u4f30\u4e09\u4e2a\u524d\u6cbfLLM\u6a21\u578b\uff0c\u89c2\u5bdf\u5b83\u4eec\u5728\u5c40\u90e8\u89c4\u8303\u4e0b\u7684\u8868\u73b0\u3002", "result": "\u53d1\u73b0LLMs\u5b58\u5728\u6301\u7eed\u4e0d\u9075\u5b88\u5c40\u90e8\u89c4\u8303\u7684\u95ee\u9898\uff0c\u5305\u62ec\uff1a\u8bed\u4e49\u8986\u76d6\uff08\u6a21\u578b\u56de\u5f52\u5230\u9884\u8bad\u7ec3\u9ed8\u8ba4\u89e3\u91ca\u800c\u5ffd\u7565\u63d0\u793a\u4e2d\u7684\u91cd\u5b9a\u4e49\uff09\u3001\u5047\u8bbe\u6ce8\u5165\uff08\u5728\u5173\u952e\u7ec6\u8282\u672a\u6307\u5b9a\u65f6\u505a\u51fa\u672a\u58f0\u660e\u7684\u786c\u4ef6\u8bed\u4e49\u5047\u8bbe\uff09\u3001\u7ea6\u675f\u4e22\u5f03\uff08\u5373\u4f7f\u5728\u57fa\u672c\u8bbe\u7f6e\u4e2d\u4e5f\u4f1a\u5ffd\u7565\u7ea6\u675f\uff09\u3002", "conclusion": "LLMs\u5728\u8868\u9762\u6b63\u786e\u6027\u548c\u89c4\u8303\u5fe0\u5b9e\u63a8\u7406\u4e4b\u95f4\u5b58\u5728\u5dee\u8ddd\uff0c\u9700\u8981\u5f00\u53d1\u4e13\u95e8\u8bc4\u4f30\u5c40\u90e8\u9057\u5fd8\u548c\u8bed\u4e49\u5408\u89c4\u6027\u7684\u6d4b\u8bd5\u534f\u8bae\uff0c\u7279\u522b\u662f\u5728\u5f62\u5f0f\u5316\u9886\u57df\u4e2d\u3002"}}
