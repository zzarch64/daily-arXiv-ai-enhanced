<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Online Learning Extreme Learning Machine with Low-Complexity Predictive Plasticity Rule and FPGA Implementation](https://arxiv.org/abs/2512.21777)
*Zhenya Zang,Xingda Li,David Day Uei Li*

Main category: cs.AR

TL;DR: 提出一种简化的生物启发式局部学习规则，无需全局反向传播和膜电位积分，仅基于预测误差触发权重更新，使用稀疏二进制驱动向量加法，集成到ELM中替代矩阵求逆，复杂度从O(M³)降至O(M)，精度损失小，适合边缘设备在线学习。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络需要全局反向传播，计算量大；事件驱动训练需要膜电位积分，复杂度高。这些方法不适合资源受限的边缘设备进行在线学习。需要一种简化、高效的学习规则。

Method: 提出生物启发的预测性局部学习规则：1) 仅当预测错误时触发权重更新；2) 使用稀疏二进制驱动向量加法进行更新；3) 将该规则集成到极限学习机(ELM)中，替代传统计算密集的矩阵求逆操作。

Result: 1) 训练复杂度从O(M³)降至O(M)，M为隐藏层节点数；2) 精度损失小（训练集3.6%，测试集2.0%）；3) FPGA实现显示计算和内存需求显著降低；4) 适合低功耗边缘设备在线学习。

Conclusion: 提出的简化局部学习规则有效替代了传统反向传播和矩阵求逆，大幅降低计算复杂度，保持可接受的精度损失，在FPGA上验证了其高效性，为边缘设备的在线学习提供了有前景的解决方案。

Abstract: We propose a simplified, biologically inspired predictive local learning rule that eliminates the need for global backpropagation in conventional neural networks and membrane integration in event-based training. Weight updates are triggered only on prediction errors and are performed using sparse, binary-driven vector additions. We integrate this rule into an extreme learning machine (ELM), replacing the conventional computationally intensive matrix inversion. Compared to standard ELM, our approach reduces the complexity of the training from O(M^3) to O(M), in terms of M nodes in the hidden layer, while maintaining comparable accuracy (within 3.6% and 2.0% degradation on training and test datasets, respectively). We demonstrate an FPGA implementation and compare it with existing studies, showing significant reductions in computational and memory requirements. This design demonstrates strong potential for energy-efficient online learning on low-cost edge devices.

</details>


### [2] [Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling](https://arxiv.org/abs/2512.22066)
*Hannah Atmer,Yuan Yao,Thiemo Voigt,Stefanos Kaxiras*

Main category: cs.AR

TL;DR: 研究LLM推理中SRAM大小和运行频率对能效的影响，发现大缓存增加静态能耗但无相应延迟收益，高频率通过减少执行时间降低总能耗，最佳配置为1200-1400MHz频率和32-64KB小缓存。


<details>
  <summary>Details</summary>
Motivation: LLM的能耗决定了部署成本和环境影响，需要研究硬件配置（SRAM大小和运行频率）对LLM推理能效和性能的影响，特别是计算密集型预填充阶段和内存密集型解码阶段的差异行为。

Method: 采用OpenRAM进行能耗建模、LLMCompass进行延迟模拟、ScaleSIM进行脉动阵列操作强度分析的仿真方法，研究SRAM大小和运行频率对LLM推理能效的影响。

Result: 总能耗主要由SRAM大小决定，大缓存显著增加泄漏导致的静态能耗；高频率虽减少预填充延迟，但对内存受限的解码阶段影响有限；高计算频率通过减少执行时间降低总能耗；最佳配置为1200-1400MHz频率和32-64KB小缓存。

Conclusion: 为设计能效优化的LLM加速器提供具体架构指导：采用高频率和小缓存配置，在数据中心环境中平衡低延迟和高能效，内存带宽是性能上限，增加计算频率只在内存受限前有效。

Abstract: Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.

</details>
