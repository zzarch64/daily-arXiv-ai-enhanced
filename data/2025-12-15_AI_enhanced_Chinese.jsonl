{"id": "2512.11550", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.11550", "abs": "https://arxiv.org/abs/2512.11550", "authors": ["Yifan Zhang", "Zhiheng Chen", "Ye Qiao", "Sitao Huang"], "title": "PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration", "comment": null, "summary": "Aggressively quantized large language models (LLMs), such as BitNet-style 1.58-bit Transformers with ternary weights, make it feasible to deploy generative AI on low-power edge FPGAs. However, as prompts grow to tens of thousands of tokens, edge hardware performance drops sharply with sequence length due to quadratic prefill cost and rapidly increasing KV-cache bandwidth demands, making inference latency of longer context length a first-order system concern. Recent studies on LLMs expose a fundamental prefill-decode asymmetry: prefill is compute-bound and dominated by dense matrix-matrix operations, whereas decoding is memory-bandwidth-bound and dominated by KV-cache traffic. A static accelerator must provision resources and a single dataflow for both regimes, leading to duplicated attention logic, underutilized fabric, and tight LUT/URAM limits that cap model size and usable context. We propose a prefill--decode disaggregated LLM accelerator, PD-Swap, that uses Dynamic Partial Reconfiguration (DPR) to time-multiplex the attention module on edge FPGAs. The core table-lookup ternary matrix multiplication and weight-buffering engines remain static, while the attention subsystem is a reconfigurable partition with two phase-specialized architectures: a compute-heavy, token-parallel prefill engine and a bandwidth-optimized, KV-cache-centric decoding engine. A roofline-inspired model and design space exploration jointly optimize reconfigurable-region size, parallelism under reconfiguration and routability constraints, and reconfiguration latency is hidden by computation latency. PD-Swap achieves up to 27~tokens/s decoding throughput, outperforming prior state-of-the-art works by 1.3x--2.1x (larger gains at longer context lengths), without extra area cost.", "AI": {"tldr": "PD-Swap\uff1a\u57fa\u4e8e\u52a8\u6001\u90e8\u5206\u91cd\u914d\u7f6e\u7684\u9884\u586b\u5145-\u89e3\u7801\u5206\u79bbLLM\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u65f6\u95f4\u590d\u7528\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5728\u8fb9\u7f18FPGA\u4e0a\u5b9e\u73b0\u9ad8\u6548\u7684\u957f\u4e0a\u4e0b\u6587\u63a8\u7406", "motivation": "\u8fb9\u7f18FPGA\u90e8\u7f72\u7684\u91cf\u5316LLM\u5728\u5904\u7406\u957f\u4e0a\u4e0b\u6587\u65f6\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u9884\u586b\u5145\u548c\u89e3\u7801\u9636\u6bb5\u7684\u8ba1\u7b97\u7279\u6027\u4e0d\u540c\uff1a\u9884\u586b\u5145\u662f\u8ba1\u7b97\u5bc6\u96c6\u578b\uff0c\u89e3\u7801\u662f\u5185\u5b58\u5e26\u5bbd\u5bc6\u96c6\u578b\u3002\u9759\u6001\u52a0\u901f\u5668\u9700\u8981\u4e3a\u4e24\u79cd\u6a21\u5f0f\u63d0\u4f9b\u8d44\u6e90\uff0c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\u548c\u6027\u80fd\u74f6\u9888\u3002", "method": "\u63d0\u51faPD-Swap\u52a0\u901f\u5668\uff0c\u4f7f\u7528\u52a8\u6001\u90e8\u5206\u91cd\u914d\u7f6e\u6280\u672f\u65f6\u95f4\u590d\u7528\u6ce8\u610f\u529b\u6a21\u5757\u3002\u6838\u5fc3\u7684\u4e09\u5143\u77e9\u9635\u4e58\u6cd5\u548c\u6743\u91cd\u7f13\u51b2\u5f15\u64ce\u4fdd\u6301\u9759\u6001\uff0c\u6ce8\u610f\u529b\u5b50\u7cfb\u7edf\u4f5c\u4e3a\u53ef\u91cd\u914d\u7f6e\u5206\u533a\uff0c\u5305\u542b\u4e24\u4e2a\u4e13\u95e8\u5316\u67b6\u6784\uff1a\u8ba1\u7b97\u5bc6\u96c6\u7684token\u5e76\u884c\u9884\u586b\u5145\u5f15\u64ce\u548c\u5e26\u5bbd\u4f18\u5316\u7684KV\u7f13\u5b58\u4e2d\u5fc3\u89e3\u7801\u5f15\u64ce\u3002", "result": "PD-Swap\u5728\u8fb9\u7f18FPGA\u4e0a\u5b9e\u73b0\u9ad8\u8fbe27 tokens/s\u7684\u89e3\u7801\u541e\u5410\u91cf\uff0c\u6bd4\u73b0\u6709\u6700\u4f18\u5de5\u4f5c\u63d0\u53471.3-2.1\u500d\uff08\u4e0a\u4e0b\u6587\u8d8a\u957f\u63d0\u5347\u8d8a\u5927\uff09\uff0c\u4e14\u4e0d\u589e\u52a0\u989d\u5916\u9762\u79ef\u6210\u672c\u3002", "conclusion": "\u901a\u8fc7\u9884\u586b\u5145-\u89e3\u7801\u5206\u79bb\u67b6\u6784\u548c\u52a8\u6001\u90e8\u5206\u91cd\u914d\u7f6e\uff0cPD-Swap\u6709\u6548\u89e3\u51b3\u4e86\u8fb9\u7f18FPGA\u4e0aLLM\u957f\u4e0a\u4e0b\u6587\u63a8\u7406\u7684\u6027\u80fd\u74f6\u9888\uff0c\u4e3a\u4f4e\u529f\u8017\u8fb9\u7f18\u8bbe\u5907\u90e8\u7f72\u751f\u6210\u5f0fAI\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
