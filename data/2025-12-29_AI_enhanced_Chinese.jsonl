{"id": "2512.21777", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.21777", "abs": "https://arxiv.org/abs/2512.21777", "authors": ["Zhenya Zang", "Xingda Li", "David Day Uei Li"], "title": "Online Learning Extreme Learning Machine with Low-Complexity Predictive Plasticity Rule and FPGA Implementation", "comment": null, "summary": "We propose a simplified, biologically inspired predictive local learning rule that eliminates the need for global backpropagation in conventional neural networks and membrane integration in event-based training. Weight updates are triggered only on prediction errors and are performed using sparse, binary-driven vector additions. We integrate this rule into an extreme learning machine (ELM), replacing the conventional computationally intensive matrix inversion. Compared to standard ELM, our approach reduces the complexity of the training from O(M^3) to O(M), in terms of M nodes in the hidden layer, while maintaining comparable accuracy (within 3.6% and 2.0% degradation on training and test datasets, respectively). We demonstrate an FPGA implementation and compare it with existing studies, showing significant reductions in computational and memory requirements. This design demonstrates strong potential for energy-efficient online learning on low-cost edge devices.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7b80\u5316\u7684\u751f\u7269\u542f\u53d1\u5f0f\u5c40\u90e8\u5b66\u4e60\u89c4\u5219\uff0c\u65e0\u9700\u5168\u5c40\u53cd\u5411\u4f20\u64ad\u548c\u819c\u7535\u4f4d\u79ef\u5206\uff0c\u4ec5\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u89e6\u53d1\u6743\u91cd\u66f4\u65b0\uff0c\u4f7f\u7528\u7a00\u758f\u4e8c\u8fdb\u5236\u9a71\u52a8\u5411\u91cf\u52a0\u6cd5\uff0c\u96c6\u6210\u5230ELM\u4e2d\u66ff\u4ee3\u77e9\u9635\u6c42\u9006\uff0c\u590d\u6742\u5ea6\u4eceO(M\u00b3)\u964d\u81f3O(M)\uff0c\u7cbe\u5ea6\u635f\u5931\u5c0f\uff0c\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u5728\u7ebf\u5b66\u4e60\u3002", "motivation": "\u4f20\u7edf\u795e\u7ecf\u7f51\u7edc\u9700\u8981\u5168\u5c40\u53cd\u5411\u4f20\u64ad\uff0c\u8ba1\u7b97\u91cf\u5927\uff1b\u4e8b\u4ef6\u9a71\u52a8\u8bad\u7ec3\u9700\u8981\u819c\u7535\u4f4d\u79ef\u5206\uff0c\u590d\u6742\u5ea6\u9ad8\u3002\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8bbe\u5907\u8fdb\u884c\u5728\u7ebf\u5b66\u4e60\u3002\u9700\u8981\u4e00\u79cd\u7b80\u5316\u3001\u9ad8\u6548\u7684\u5b66\u4e60\u89c4\u5219\u3002", "method": "\u63d0\u51fa\u751f\u7269\u542f\u53d1\u7684\u9884\u6d4b\u6027\u5c40\u90e8\u5b66\u4e60\u89c4\u5219\uff1a1) \u4ec5\u5f53\u9884\u6d4b\u9519\u8bef\u65f6\u89e6\u53d1\u6743\u91cd\u66f4\u65b0\uff1b2) \u4f7f\u7528\u7a00\u758f\u4e8c\u8fdb\u5236\u9a71\u52a8\u5411\u91cf\u52a0\u6cd5\u8fdb\u884c\u66f4\u65b0\uff1b3) \u5c06\u8be5\u89c4\u5219\u96c6\u6210\u5230\u6781\u9650\u5b66\u4e60\u673a(ELM)\u4e2d\uff0c\u66ff\u4ee3\u4f20\u7edf\u8ba1\u7b97\u5bc6\u96c6\u7684\u77e9\u9635\u6c42\u9006\u64cd\u4f5c\u3002", "result": "1) \u8bad\u7ec3\u590d\u6742\u5ea6\u4eceO(M\u00b3)\u964d\u81f3O(M)\uff0cM\u4e3a\u9690\u85cf\u5c42\u8282\u70b9\u6570\uff1b2) \u7cbe\u5ea6\u635f\u5931\u5c0f\uff08\u8bad\u7ec3\u96c63.6%\uff0c\u6d4b\u8bd5\u96c62.0%\uff09\uff1b3) FPGA\u5b9e\u73b0\u663e\u793a\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u663e\u8457\u964d\u4f4e\uff1b4) \u9002\u5408\u4f4e\u529f\u8017\u8fb9\u7f18\u8bbe\u5907\u5728\u7ebf\u5b66\u4e60\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b80\u5316\u5c40\u90e8\u5b66\u4e60\u89c4\u5219\u6709\u6548\u66ff\u4ee3\u4e86\u4f20\u7edf\u53cd\u5411\u4f20\u64ad\u548c\u77e9\u9635\u6c42\u9006\uff0c\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4fdd\u6301\u53ef\u63a5\u53d7\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u5728FPGA\u4e0a\u9a8c\u8bc1\u4e86\u5176\u9ad8\u6548\u6027\uff0c\u4e3a\u8fb9\u7f18\u8bbe\u5907\u7684\u5728\u7ebf\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.22066", "categories": ["cs.AR", "cs.LG", "cs.PF"], "pdf": "https://arxiv.org/pdf/2512.22066", "abs": "https://arxiv.org/abs/2512.22066", "authors": ["Hannah Atmer", "Yuan Yao", "Thiemo Voigt", "Stefanos Kaxiras"], "title": "Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling", "comment": null, "summary": "Energy consumption dictates the cost and environmental impact of deploying Large Language Models. This paper investigates the impact of on-chip SRAM size and operating frequency on the energy efficiency and performance of LLM inference, focusing on the distinct behaviors of the compute-bound prefill and memory-bound decode phases. Our simulation methodology combines OpenRAM for energy modeling, LLMCompass for latency simulation, and ScaleSIM for systolic array operational intensity. Our findings show that total energy use is predominantly determined by SRAM size in both phases, with larger buffers significantly increasing static energy due to leakage, which is not offset by corresponding latency benefits. We quantitatively explore the memory-bandwidth bottleneck, demonstrating that while high operating frequencies reduce prefill latency, their positive impact on memory-bound decode latency is capped by the external memory bandwidth. Counter-intuitively, high compute frequency can reduce total energy by reducing execution time and consequently decreasing static energy consumption more than the resulting dynamic power increase. We identify an optimal hardware configuration for the simulated workload: high operating frequencies (1200MHz-1400MHz) and a small local buffer size of 32KB to 64KB. This combination achieves the best energy-delay product, balancing low latency with high energy efficiency. Furthermore, we demonstrate how memory bandwidth acts as a performance ceiling, and that increasing compute frequency only yields performance gains up to the point where the workload becomes memory-bound. This analysis provides concrete architectural insights for designing energy-efficient LLM accelerators, especially for datacenters aiming to minimize their energy overhead.", "AI": {"tldr": "\u7814\u7a76LLM\u63a8\u7406\u4e2dSRAM\u5927\u5c0f\u548c\u8fd0\u884c\u9891\u7387\u5bf9\u80fd\u6548\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u5927\u7f13\u5b58\u589e\u52a0\u9759\u6001\u80fd\u8017\u4f46\u65e0\u76f8\u5e94\u5ef6\u8fdf\u6536\u76ca\uff0c\u9ad8\u9891\u7387\u901a\u8fc7\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u964d\u4f4e\u603b\u80fd\u8017\uff0c\u6700\u4f73\u914d\u7f6e\u4e3a1200-1400MHz\u9891\u7387\u548c32-64KB\u5c0f\u7f13\u5b58\u3002", "motivation": "LLM\u7684\u80fd\u8017\u51b3\u5b9a\u4e86\u90e8\u7f72\u6210\u672c\u548c\u73af\u5883\u5f71\u54cd\uff0c\u9700\u8981\u7814\u7a76\u786c\u4ef6\u914d\u7f6e\uff08SRAM\u5927\u5c0f\u548c\u8fd0\u884c\u9891\u7387\uff09\u5bf9LLM\u63a8\u7406\u80fd\u6548\u548c\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u8ba1\u7b97\u5bc6\u96c6\u578b\u9884\u586b\u5145\u9636\u6bb5\u548c\u5185\u5b58\u5bc6\u96c6\u578b\u89e3\u7801\u9636\u6bb5\u7684\u5dee\u5f02\u884c\u4e3a\u3002", "method": "\u91c7\u7528OpenRAM\u8fdb\u884c\u80fd\u8017\u5efa\u6a21\u3001LLMCompass\u8fdb\u884c\u5ef6\u8fdf\u6a21\u62df\u3001ScaleSIM\u8fdb\u884c\u8109\u52a8\u9635\u5217\u64cd\u4f5c\u5f3a\u5ea6\u5206\u6790\u7684\u4eff\u771f\u65b9\u6cd5\uff0c\u7814\u7a76SRAM\u5927\u5c0f\u548c\u8fd0\u884c\u9891\u7387\u5bf9LLM\u63a8\u7406\u80fd\u6548\u7684\u5f71\u54cd\u3002", "result": "\u603b\u80fd\u8017\u4e3b\u8981\u7531SRAM\u5927\u5c0f\u51b3\u5b9a\uff0c\u5927\u7f13\u5b58\u663e\u8457\u589e\u52a0\u6cc4\u6f0f\u5bfc\u81f4\u7684\u9759\u6001\u80fd\u8017\uff1b\u9ad8\u9891\u7387\u867d\u51cf\u5c11\u9884\u586b\u5145\u5ef6\u8fdf\uff0c\u4f46\u5bf9\u5185\u5b58\u53d7\u9650\u7684\u89e3\u7801\u9636\u6bb5\u5f71\u54cd\u6709\u9650\uff1b\u9ad8\u8ba1\u7b97\u9891\u7387\u901a\u8fc7\u51cf\u5c11\u6267\u884c\u65f6\u95f4\u964d\u4f4e\u603b\u80fd\u8017\uff1b\u6700\u4f73\u914d\u7f6e\u4e3a1200-1400MHz\u9891\u7387\u548c32-64KB\u5c0f\u7f13\u5b58\u3002", "conclusion": "\u4e3a\u8bbe\u8ba1\u80fd\u6548\u4f18\u5316\u7684LLM\u52a0\u901f\u5668\u63d0\u4f9b\u5177\u4f53\u67b6\u6784\u6307\u5bfc\uff1a\u91c7\u7528\u9ad8\u9891\u7387\u548c\u5c0f\u7f13\u5b58\u914d\u7f6e\uff0c\u5728\u6570\u636e\u4e2d\u5fc3\u73af\u5883\u4e2d\u5e73\u8861\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u80fd\u6548\uff0c\u5185\u5b58\u5e26\u5bbd\u662f\u6027\u80fd\u4e0a\u9650\uff0c\u589e\u52a0\u8ba1\u7b97\u9891\u7387\u53ea\u5728\u5185\u5b58\u53d7\u9650\u524d\u6709\u6548\u3002"}}
