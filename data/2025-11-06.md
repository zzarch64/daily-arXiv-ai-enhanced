<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [LogicSparse: Enabling Engine-Free Unstructured Sparsity for Quantised Deep-learning Accelerators](https://arxiv.org/abs/2511.03079)
*Changhong Li,Biswajit Basu,Shreejith Shanker*

Main category: cs.AR

TL;DR: 提出了一种将非结构化稀疏性嵌入数据流加速器的框架，无需专用稀疏引擎即可保持并行性，在LeNet-5上实现51.6倍压缩和1.23倍吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型在资源受限的边缘设备上性能受限，量化与剪枝虽能缓解此问题，但非结构化稀疏性由于不规则内存访问而未被充分利用。

Method: 引入将非结构化稀疏性嵌入数据流加速器的框架，采用硬件感知剪枝策略提高效率，无需专用稀疏引擎即可保持并行性。

Result: 在LeNet-5上实现51.6倍压缩和1.23倍吞吐量提升，仅使用5.12%的LUT资源，有效利用非结构化稀疏性加速QNN。

Conclusion: 该框架成功将非结构化稀疏性集成到FPGA数据流加速器中，显著提升QNN推理效率，为边缘设备部署提供了高效解决方案。

Abstract: FPGAs have been shown to be a promising platform for deploying Quantised
Neural Networks (QNNs) with high-speed, low-latency, and energy-efficient
inference. However, the complexity of modern deep-learning models limits the
performance on resource-constrained edge devices. While quantisation and
pruning alleviate these challenges, unstructured sparsity remains
underexploited due to irregular memory access. This work introduces a framework
that embeds unstructured sparsity into dataflow accelerators, eliminating the
need for dedicated sparse engines and preserving parallelism. A hardware-aware
pruning strategy is introduced to improve efficiency and design flow further.
On LeNet-5, the framework attains 51.6 x compression and 1.23 x throughput
improvement using only 5.12% of LUTs, effectively exploiting unstructured
sparsity for QNN acceleration.

</details>


### [2] [An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM](https://arxiv.org/abs/2511.03203)
*Deyang Yu,Chenchen Liu,Chuanjie Zhang,Xiao Fang,Weisheng Zhao*

Main category: cs.AR

TL;DR: 提出了一种基于自旋轨道转矩MRAM的事件驱动脉冲处理计算内存宏，采用混合串并联单元结构实现高效矩阵向量乘法，在28nm工艺下达到243.6 TOPS/W的峰值能效。


<details>
  <summary>Details</summary>
Motivation: 现有MRAM计算内存设计依赖复杂的模拟电路，导致能耗过高，需要更高效的解决方案。

Method: 使用SOT-MRAM交叉阵列，采用混合串并联单元结构支持矩阵向量乘法；通过轻量级电路将信号编码为脉冲，避免传统模拟电路。

Result: 在28nm工艺下实现，峰值能效达到243.6 TOPS/W，显著优于现有设计。

Conclusion: 该SOT-MRAM计算内存宏通过事件驱动脉冲处理和混合结构设计，实现了高能效的计算内存解决方案。

Abstract: The application of Magnetic Random-Access Memory (MRAM) in
computing-in-memory (CIM) has gained significant attention. However, existing
designs often suffer from high energy consumption due to their reliance on
complex analog circuits for computation. In this work, we present a Spin-Orbit-
Torque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking
processing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid
series-parallel cell structure to efficiently support matrix-vector
multiplication (MVM). Signal information is (en) decoded as spikes using
lightweight circuits, eliminating the need for conventional area- and
powerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in
28nm technology, and experimental results show that it achieves a peak energy
efficiency of 243.6 TOPS/W, significantly outperforming existing designs.

</details>


### [3] [Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics](https://arxiv.org/abs/2511.03427)
*Florentia Afentaki,Maha Shatta,Konstantinos Balaskas,Georgios Panagopoulos,Georgios Zervakis,Mehdi B. Tahoori*

Main category: cs.AR

TL;DR: 提出了首个柔性电子中的混合核函数和混合信号SVM设计，通过联合优化方法在数字/模拟域和线性/RBF核函数间分配分类器，在提高精度的同时显著降低硬件成本。


<details>
  <summary>Details</summary>
Motivation: 柔性电子技术因特征尺寸大而限制了集成密度，无法实现机器学习电路。现有SVM设计在硬件成本和精度之间存在权衡：线性核精度低但硬件开销小，RBF核精度高但硬件成本过高。

Method: 提出混合核函数和混合信号SVM设计，采用联合优化方法训练混合核SVM，并将二分类SVM映射到适当的核函数（线性/RBF）和域（数字/模拟），旨在最大化精度同时减少昂贵的RBF分类器数量。

Result: 相比最先进的单核线性SVM，精度提高7.7%；相比数字RBF实现，面积和功耗分别平均降低108倍和17倍。

Conclusion: 混合核函数和混合信号SVM设计成功平衡了柔性电子中硬件成本与精度的权衡，为近传感器应用提供了可行的机器学习解决方案。

Abstract: Flexible Electronics (FE) have emerged as a promising alternative to
silicon-based technologies, offering on-demand low-cost fabrication,
conformality, and sustainability. However, their large feature sizes severely
limit integration density, imposing strict area and power constraints, thus
prohibiting the realization of Machine Learning (ML) circuits, which can
significantly enhance the capabilities of relevant near-sensor applications.
Support Vector Machines (SVMs) offer high accuracy in such applications at
relatively low computational complexity, satisfying FE technologies'
constraints. Existing SVM designs rely solely on linear or Radial Basis
Function (RBF) kernels, forcing a trade-off between hardware costs and
accuracy. Linear kernels, implemented digitally, minimize overhead but
sacrifice performance, while the more accurate RBF kernels are prohibitively
large in digital, and their analog realization contains inherent functional
approximation. In this work, we propose the first mixed-kernel and mixed-signal
SVM design in FE, which unifies the advantages of both implementations and
balances the cost/accuracy trade-off. To that end, we introduce a
co-optimization approach that trains our mixed-kernel SVMs and maps binary SVM
classifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),
aiming to maximize accuracy whilst reducing the number of costly RBF
classifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art
single-kernel linear SVMs, and reduce area and power by 108x and 17x on average
compared to digital RBF implementations.

</details>
