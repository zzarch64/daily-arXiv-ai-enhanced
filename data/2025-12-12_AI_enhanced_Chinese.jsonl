{"id": "2512.10089", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.10089", "abs": "https://arxiv.org/abs/2512.10089", "authors": ["Jeongeun Kim", "Sabrina Yarzada", "Paul Chen", "Christopher Torng"], "title": "Algorithm-Driven On-Chip Integration for High Density and Low Cost", "comment": null, "summary": "Growing interest in semiconductor workforce development has generated demand for platforms capable of supporting large numbers of independent hardware designs for research and training without imposing high per-project overhead. Traditional multi-project wafer (MPW) services based solely on physical co-placement have historically met this need, yet their scalability breaks down as project counts rise. Recent efforts towards scalable chip tapeouts mitigate these limitations by integrating many small designs within a shared die and attempt to amortize costly resources such as IO pads and memory macros. However, foundational principles for arranging, linking, and validating such densely integrated design sites have received limited systematic investigation. This work presents a new approach with three key techniques to address this gap. First, we establish a structured formulation of the design space that enables automated, algorithm-driven packing of many projects, replacing manual layout practices. Second, we introduce an architecture that exploits only the narrow-area regions between sites to deliver on off-chip communication and other shared needs. Third, we provide a practical approach for on-chip power domains enabling per-project power characterization at a standard laboratory bench and requiring no expertise in low-power ASIC design. Experimental results show that our approach achieves substantial area reductions of up to 13x over state-of-the-art physical-only aggregation methods, offering a scalable and cost-effective path forward for large-scale tapeout environments.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u591a\u9879\u76ee\u82af\u7247\u96c6\u6210\u65b9\u6cd5\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u5e03\u5c40\u3001\u7a84\u533a\u57df\u4e92\u8fde\u67b6\u6784\u548c\u7247\u4e0a\u7535\u6e90\u57df\u6280\u672f\uff0c\u5b9e\u73b013\u500d\u9762\u79ef\u7f29\u51cf\uff0c\u4e3a\u5927\u89c4\u6a21\u6d41\u7247\u63d0\u4f9b\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u534a\u5bfc\u4f53\u4eba\u624d\u57f9\u517b\u9700\u6c42\u589e\u957f\uff0c\u9700\u8981\u652f\u6301\u5927\u91cf\u72ec\u7acb\u786c\u4ef6\u8bbe\u8ba1\u7684\u5e73\u53f0\u3002\u4f20\u7edf\u591a\u9879\u76ee\u6676\u5706(MPW)\u670d\u52a1\u5728\u9879\u76ee\u6570\u91cf\u589e\u52a0\u65f6\u6269\u5c55\u6027\u53d7\u9650\uff0c\u73b0\u6709\u96c6\u6210\u65b9\u6cd5\u7f3a\u4e4f\u7cfb\u7edf\u6027\u7684\u5e03\u5c40\u3001\u4e92\u8fde\u548c\u9a8c\u8bc1\u539f\u5219\u3002", "method": "\u63d0\u51fa\u4e09\u79cd\u5173\u952e\u6280\u672f\uff1a1) \u5efa\u7acb\u7ed3\u6784\u5316\u8bbe\u8ba1\u7a7a\u95f4\u516c\u5f0f\u5316\uff0c\u5b9e\u73b0\u81ea\u52a8\u5316\u7b97\u6cd5\u9a71\u52a8\u7684\u9879\u76ee\u6253\u5305\uff1b2) \u5229\u7528\u8bbe\u8ba1\u7ad9\u70b9\u95f4\u7684\u7a84\u533a\u57df\u5b9e\u73b0\u7247\u5916\u901a\u4fe1\u548c\u5176\u4ed6\u5171\u4eab\u9700\u6c42\uff1b3) \u63d0\u4f9b\u7247\u4e0a\u7535\u6e90\u57df\u5b9e\u7528\u65b9\u6cd5\uff0c\u652f\u6301\u6bcf\u4e2a\u9879\u76ee\u5728\u6807\u51c6\u5b9e\u9a8c\u53f0\u4e0a\u8fdb\u884c\u529f\u8017\u8868\u5f81\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u7eaf\u7269\u7406\u805a\u5408\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe13\u500d\u7684\u9762\u79ef\u7f29\u51cf\uff0c\u4e3a\u5927\u89c4\u6a21\u6d41\u7247\u73af\u5883\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u7ecf\u6d4e\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u7cfb\u7edf\u6027\u7684\u8bbe\u8ba1\u7a7a\u95f4\u516c\u5f0f\u5316\u3001\u7a84\u533a\u57df\u4e92\u8fde\u67b6\u6784\u548c\u7247\u4e0a\u7535\u6e90\u57df\u6280\u672f\uff0c\u89e3\u51b3\u4e86\u591a\u9879\u76ee\u82af\u7247\u96c6\u6210\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u4e3a\u534a\u5bfc\u4f53\u7814\u7a76\u548c\u57f9\u8bad\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u5e73\u53f0\u3002"}}
{"id": "2512.10155", "categories": ["cs.AR", "cs.SE"], "pdf": "https://arxiv.org/pdf/2512.10155", "abs": "https://arxiv.org/abs/2512.10155", "authors": ["Jeongeun Kim", "Christopher Torng"], "title": "A Vertically Integrated Framework for Templatized Chip Design", "comment": null, "summary": "Developers who primarily engage with software often struggle to incorporate custom hardware into their applications, even though specialized silicon can provide substantial benefits to machine learning and AI, as well as to the application domains that they enable. This work investigates how a chip can be generated from a high-level object-oriented software specification, targeting introductory-level chip design learners with only very light performance requirements, while maintaining mental continuity between the chip layout and the software source program. In our approach, each software object is represented as a corresponding region on the die, producing a one-to-one structural mapping that preserves these familiar abstractions throughout the design flow. To support this mapping, we employ a modular construction strategy in which vertically composed IP blocks implement the behavioral protocols expressed in software. A direct syntactic translation, however, cannot meet hardware-level efficiency or communication constraints. For this reason, we leverage formal type systems based on sequences that check whether interactions between hardware modules adhere to the communication patterns described in the software model. We further examine hardware interconnect strategies for composing many such modules and develop layout techniques suited to this object-aligned design style. Together, these contributions preserve mental continuity from software to chip design for new learners and enables practical layout generation, ultimately reducing the expertise required for software developers to participate in chip creation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4ece\u9ad8\u7ea7\u9762\u5411\u5bf9\u8c61\u8f6f\u4ef6\u89c4\u8303\u751f\u6210\u82af\u7247\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f6f\u4ef6\u5bf9\u8c61\u4e0e\u82af\u7247\u533a\u57df\u7684\u76f4\u63a5\u6620\u5c04\uff0c\u964d\u4f4e\u8f6f\u4ef6\u5f00\u53d1\u8005\u53c2\u4e0e\u82af\u7247\u8bbe\u8ba1\u7684\u95e8\u69db\u3002", "motivation": "\u8f6f\u4ef6\u5f00\u53d1\u8005\u96be\u4ee5\u5c06\u5b9a\u5236\u786c\u4ef6\u96c6\u6210\u5230\u5e94\u7528\u4e2d\uff0c\u5c3d\u7ba1\u4e13\u7528\u82af\u7247\u80fd\u4e3a\u673a\u5668\u5b66\u4e60\u548cAI\u7b49\u9886\u57df\u5e26\u6765\u663e\u8457\u4f18\u52bf\u3002\u9700\u8981\u964d\u4f4e\u82af\u7247\u8bbe\u8ba1\u7684\u5b66\u4e60\u95e8\u69db\uff0c\u8ba9\u8f6f\u4ef6\u5f00\u53d1\u8005\u4e5f\u80fd\u53c2\u4e0e\u82af\u7247\u521b\u5efa\u3002", "method": "\u91c7\u7528\u6a21\u5757\u5316\u6784\u5efa\u7b56\u7565\uff1a1) \u8f6f\u4ef6\u5bf9\u8c61\u76f4\u63a5\u6620\u5c04\u5230\u82af\u7247\u533a\u57df\uff0c\u4fdd\u6301\u7ed3\u6784\u5bf9\u5e94\u5173\u7cfb\uff1b2) \u5782\u76f4\u7ec4\u5408IP\u5757\u5b9e\u73b0\u8f6f\u4ef6\u4e2d\u8868\u8fbe\u7684\u884c\u4e3a\u534f\u8bae\uff1b3) \u4f7f\u7528\u57fa\u4e8e\u5e8f\u5217\u7684\u5f62\u5f0f\u7c7b\u578b\u7cfb\u7edf\u68c0\u67e5\u786c\u4ef6\u6a21\u5757\u4ea4\u4e92\u662f\u5426\u7b26\u5408\u8f6f\u4ef6\u6a21\u578b\u901a\u4fe1\u6a21\u5f0f\uff1b4) \u5f00\u53d1\u9002\u5408\u5bf9\u8c61\u5bf9\u9f50\u8bbe\u8ba1\u98ce\u683c\u7684\u786c\u4ef6\u4e92\u8fde\u7b56\u7565\u548c\u5e03\u5c40\u6280\u672f\u3002", "result": "\u5b9e\u73b0\u4e86\u4ece\u8f6f\u4ef6\u5230\u82af\u7247\u8bbe\u8ba1\u7684\u601d\u7ef4\u8fde\u7eed\u6027\u4fdd\u6301\uff0c\u652f\u6301\u5b9e\u7528\u7684\u5e03\u5c40\u751f\u6210\uff0c\u964d\u4f4e\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8005\u53c2\u4e0e\u82af\u7247\u521b\u5efa\u6240\u9700\u7684\u4e13\u4e1a\u77e5\u8bc6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u82af\u7247\u8bbe\u8ba1\u521d\u5b66\u8005\u63d0\u4f9b\u4e86\u4ece\u8f6f\u4ef6\u89c4\u8303\u751f\u6210\u82af\u7247\u7684\u9014\u5f84\uff0c\u901a\u8fc7\u4fdd\u6301\u8f6f\u4ef6\u62bd\u8c61\u5728\u786c\u4ef6\u8bbe\u8ba1\u6d41\u7a0b\u4e2d\u7684\u8fde\u7eed\u6027\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8f6f\u4ef6\u5f00\u53d1\u8005\u53c2\u4e0e\u82af\u7247\u8bbe\u8ba1\u7684\u95e8\u69db\u3002"}}
{"id": "2512.10180", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.10180", "abs": "https://arxiv.org/abs/2512.10180", "authors": ["Pracheta Harlikar", "Abdel-Hameed A. Badawy", "Prasanna Date"], "title": "Neuromorphic Processor Employing FPGA Technology with Universal Interconnections", "comment": null, "summary": "Neuromorphic computing, inspired by biological neural systems, holds immense promise for ultra-low-power and real-time inference applications. However, limited access to flexible, open-source platforms continues to hinder widespread adoption and experimentation. In this paper, we present a low-cost neuromorphic processor implemented on a Xilinx Zynq-7000 FPGA platform. The processor supports all-to-all configurable connectivity and employs the leaky integrate-and-fire (LIF) neuron model with customizable parameters such as threshold, synaptic weights, and refractory period. Communication with the host system is handled via a UART interface, enabling runtime reconfiguration without hardware resynthesis. The architecture was validated using benchmark datasets including the Iris classification and MNIST digit recognition tasks. Post-synthesis results highlight the design's energy efficiency and scalability, establishing its viability as a research-grade neuromorphic platform that is both accessible and adaptable for real-world spiking neural network applications. This implementation will be released as open source following project completion.", "AI": {"tldr": "\u5728Xilinx Zynq-7000 FPGA\u4e0a\u5b9e\u73b0\u4f4e\u6210\u672c\u795e\u7ecf\u5f62\u6001\u5904\u7406\u5668\uff0c\u652f\u6301\u5168\u8fde\u63a5\u53ef\u914d\u7f6e\u67b6\u6784\uff0c\u91c7\u7528LIF\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u901a\u8fc7UART\u63a5\u53e3\u5b9e\u73b0\u8fd0\u884c\u65f6\u91cd\u914d\u7f6e\uff0c\u9a8c\u8bc1\u4e86Iris\u5206\u7c7b\u548cMNIST\u8bc6\u522b\u4efb\u52a1\uff0c\u5177\u6709\u9ad8\u80fd\u6548\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u795e\u7ecf\u5f62\u6001\u8ba1\u7b97\u5177\u6709\u8d85\u4f4e\u529f\u8017\u548c\u5b9e\u65f6\u63a8\u7406\u7684\u6f5c\u529b\uff0c\u4f46\u7f3a\u4e4f\u7075\u6d3b\u3001\u5f00\u6e90\u5e73\u53f0\u963b\u788d\u4e86\u5e7f\u6cdb\u91c7\u7528\u548c\u5b9e\u9a8c\u3002\u9700\u8981\u5f00\u53d1\u4f4e\u6210\u672c\u3001\u53ef\u8bbf\u95ee\u7684\u7814\u7a76\u7ea7\u5e73\u53f0\u3002", "method": "\u5728Xilinx Zynq-7000 FPGA\u5e73\u53f0\u4e0a\u5b9e\u73b0\u795e\u7ecf\u5f62\u6001\u5904\u7406\u5668\uff0c\u652f\u6301\u5168\u8fde\u63a5\u53ef\u914d\u7f6e\u8fde\u63a5\uff0c\u91c7\u7528\u6cc4\u6f0f\u79ef\u5206\u53d1\u653e(LIF)\u795e\u7ecf\u5143\u6a21\u578b\uff0c\u53c2\u6570\u53ef\u5b9a\u5236\uff08\u9608\u503c\u3001\u7a81\u89e6\u6743\u91cd\u3001\u4e0d\u5e94\u671f\uff09\uff0c\u901a\u8fc7UART\u63a5\u53e3\u4e0e\u4e3b\u673a\u901a\u4fe1\u5b9e\u73b0\u8fd0\u884c\u65f6\u91cd\u914d\u7f6e\u3002", "result": "\u4f7f\u7528Iris\u5206\u7c7b\u548cMNIST\u6570\u5b57\u8bc6\u522b\u57fa\u51c6\u6570\u636e\u96c6\u9a8c\u8bc1\u4e86\u67b6\u6784\u6709\u6548\u6027\u3002\u7efc\u5408\u540e\u7ed3\u679c\u663e\u793a\u8bbe\u8ba1\u5177\u6709\u9ad8\u80fd\u6548\u548c\u53ef\u6269\u5c55\u6027\uff0c\u8bc1\u660e\u5176\u4f5c\u4e3a\u7814\u7a76\u7ea7\u795e\u7ecf\u5f62\u6001\u5e73\u53f0\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4f4e\u6210\u672c\u3001\u53ef\u8bbf\u95ee\u4e14\u9002\u5e94\u6027\u5f3a\u7684\u795e\u7ecf\u5f62\u6001\u5e73\u53f0\uff0c\u9002\u7528\u4e8e\u771f\u5b9e\u4e16\u754c\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\uff0c\u5c06\u5728\u9879\u76ee\u5b8c\u6210\u540e\u4f5c\u4e3a\u5f00\u6e90\u53d1\u5e03\u3002"}}
{"id": "2512.10231", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.10231", "abs": "https://arxiv.org/abs/2512.10231", "authors": ["Zhenguo Liu", "Chengao Shi", "Chen Ding", "Jiang Xu"], "title": "SemanticBBV: A Semantic Signature for Cross-Program Knowledge Reuse in Microarchitecture Simulation", "comment": "Accepted by ASP-DAC 2026 conference", "summary": "For decades, sampling-based techniques have been the de facto standard for accelerating microarchitecture simulation, with the Basic Block Vector (BBV) serving as the cornerstone program representation. Yet, the BBV's fundamental limitations: order-dependent IDs that prevent cross-program knowledge reuse and a lack of semantic content predictive of hardware performance have left a massive potential for optimization untapped.\n  To address these gaps, we introduce SemanticBBV, a novel, two-stage framework that generates robust, performance-aware signatures for cross-program simulation reuse. First, a lightweight RWKV-based semantic encoder transforms assembly basic blocks into rich Basic Block Embeddings (BBEs), capturing deep functional semantics. Second, an order-invariant Set Transformer aggregates these BBEs, weighted by execution frequency, into a final signature. Crucially, this stage is co-trained with a dual objective: a triplet loss for signature distinctiveness and a Cycles Per Instruction (CPI) regression task, directly imbuing the signature with performance sensitivity. Our evaluation demonstrates that SemanticBBV not only matches traditional BBVs in single-program accuracy but also enables unprecedented cross-program analysis. By simulating just 14 universal program points, we estimated the performance of ten SPEC CPU benchmarks with 86.3% average accuracy, achieving a 7143x simulation speedup. Furthermore, the signature shows strong adaptability to new microarchitectures with minimal fine-tuning.", "AI": {"tldr": "SemanticBBV\uff1a\u4e00\u79cd\u65b0\u9896\u7684\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u901a\u8fc7\u8bed\u4e49\u7f16\u7801\u548c\u96c6\u5408\u53d8\u6362\u5668\u751f\u6210\u6027\u80fd\u611f\u77e5\u7684\u7a0b\u5e8f\u7b7e\u540d\uff0c\u5b9e\u73b0\u8de8\u7a0b\u5e8f\u6a21\u62df\u91cd\u7528\uff0c\u76f8\u6bd4\u4f20\u7edf\u57fa\u672c\u5757\u5411\u91cf\uff08BBV\uff09\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u91c7\u6837\u7684\u5fae\u67b6\u6784\u6a21\u62df\u4f7f\u7528\u57fa\u672c\u5757\u5411\u91cf\uff08BBV\uff09\u4f5c\u4e3a\u7a0b\u5e8f\u8868\u793a\uff0c\u4f46BBV\u5b58\u5728\u4e24\u4e2a\u6839\u672c\u9650\u5236\uff1a1\uff09\u987a\u5e8f\u4f9d\u8d56\u7684ID\u963b\u788d\u8de8\u7a0b\u5e8f\u77e5\u8bc6\u91cd\u7528\uff1b2\uff09\u7f3a\u4e4f\u9884\u6d4b\u786c\u4ef6\u6027\u80fd\u7684\u8bed\u4e49\u5185\u5bb9\uff0c\u5bfc\u81f4\u5927\u91cf\u4f18\u5316\u6f5c\u529b\u672a\u88ab\u5f00\u53d1\u3002", "method": "\u63d0\u51faSemanticBBV\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u8f7b\u91cf\u7ea7RWKV\u8bed\u4e49\u7f16\u7801\u5668\u5c06\u6c47\u7f16\u57fa\u672c\u5757\u8f6c\u6362\u4e3a\u4e30\u5bcc\u7684BBE\u5d4c\u5165\uff0c\u6355\u83b7\u6df1\u5ea6\u529f\u80fd\u8bed\u4e49\uff1b2\uff09\u987a\u5e8f\u4e0d\u53d8\u7684\u96c6\u5408\u53d8\u6362\u5668\u805a\u5408BBE\uff08\u6309\u6267\u884c\u9891\u7387\u52a0\u6743\uff09\u751f\u6210\u6700\u7ec8\u7b7e\u540d\uff0c\u901a\u8fc7\u4e09\u5143\u7ec4\u635f\u5931\uff08\u7b7e\u540d\u533a\u5206\u6027\uff09\u548cCPI\u56de\u5f52\u4efb\u52a1\uff08\u6027\u80fd\u654f\u611f\u6027\uff09\u8fdb\u884c\u8054\u5408\u8bad\u7ec3\u3002", "result": "\u4ec5\u6a21\u62df14\u4e2a\u901a\u7528\u7a0b\u5e8f\u70b9\u5373\u53ef\u4f30\u8ba110\u4e2aSPEC CPU\u57fa\u51c6\u6d4b\u8bd5\u7684\u6027\u80fd\uff0c\u5e73\u5747\u51c6\u786e\u7387\u8fbe86.3%\uff0c\u5b9e\u73b07143\u500d\u6a21\u62df\u52a0\u901f\u3002\u7b7e\u540d\u5bf9\u65b0\u5fae\u67b6\u6784\u8868\u73b0\u51fa\u5f3a\u9002\u5e94\u6027\uff0c\u4ec5\u9700\u5c11\u91cf\u5fae\u8c03\u3002", "conclusion": "SemanticBBV\u4e0d\u4ec5\u5339\u914d\u4f20\u7edfBBV\u7684\u5355\u7a0b\u5e8f\u51c6\u786e\u6027\uff0c\u8fd8\u5b9e\u73b0\u4e86\u524d\u6240\u672a\u6709\u7684\u8de8\u7a0b\u5e8f\u5206\u6790\u80fd\u529b\uff0c\u4e3a\u5fae\u67b6\u6784\u6a21\u62df\u5f00\u8f9f\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
