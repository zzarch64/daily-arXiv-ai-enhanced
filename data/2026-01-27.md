<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 8]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [SPADE: A SIMD Posit-enabled compute engine for Accelerating DNN Efficiency](https://arxiv.org/abs/2601.17279)
*Sonu Kumar,Lavanya Vinnakota,Mukul Lokhande,Santosh Kumar Vishvakarma,Adam Teman*

Main category: cs.AR

TL;DR: SPADE是一个统一的多精度SIMD Posit MAC架构，支持Posit(8,0)、(16,1)、(32,2)格式，通过层次化复用子模块减少硬件开销，在FPGA和ASIC上实现高效能。


<details>
  <summary>Details</summary>
Motivation: 边缘AI系统需要平衡数值精度、能效和硬件紧凑性的算术单元。Posit算术相比浮点和定点表示具有锥形精度、宽动态范围和更好的数值鲁棒性优势。

Method: 提出SPADE架构，采用基于regime-aware的lane-fused SIMD Posit数据通路，层次化复用Posit特定子模块（LOD、补码器、移位器、乘法器）跨8/16/32位精度，无需数据通路复制。

Result: FPGA实现显示：Posit(8,0)减少45.13% LUT和80% slice；Posit(16,1)和(32,2)相比先前工作提升28.44%和17.47%；多精度支持仅增加6.9% LUT和14.9%寄存器开销。ASIC在28nm达到1.38GHz/6.1mW。在MNIST、CIFAR-10/100等数据集上验证了竞争性推理精度。

Conclusion: SPADE通过统一的多精度SIMD Posit MAC架构，在保持数值精度的同时显著减少硬件开销，为边缘AI系统提供了高效能的算术单元解决方案。

Abstract: The growing demand for edge-AI systems requires arithmetic units that balance numerical precision, energy efficiency, and compact hardware while supporting diverse formats. Posit arithmetic offers advantages over floating- and fixed-point representations through its tapered precision, wide dynamic range, and improved numerical robustness. This work presents SPADE, a unified multi-precision SIMD Posit-based multiplyaccumulate (MAC) architecture supporting Posit (8,0), Posit (16,1), and Posit (32,2) within a single framework. Unlike prior single-precision or floating/fixed-point SIMD MACs, SPADE introduces a regime-aware, lane-fused SIMD Posit datapath that hierarchically reuses Posit-specific submodules (LOD, complementor, shifter, and multiplier) across 8/16/32-bit precisions without datapath replication. FPGA implementation on a Xilinx Virtex-7 shows 45.13% LUT and 80% slice reduction for Posit (8,0), and up to 28.44% and 17.47% improvement for Posit (16,1) and Posit (32,2) over prior work, with only 6.9% LUT and 14.9% register overhead for multi-precision support. ASIC results across TSMC nodes achieve 1.38 GHz at 6.1 mW (28 nm). Evaluation on MNIST, CIFAR-10/100, and alphabet datasets confirms competitive inference accuracy.

</details>


### [2] [Athena: Synergizing Data Prefetching and Off-Chip Prediction via Online Reinforcement Learning](https://arxiv.org/abs/2601.17615)
*Rahul Bera,Zhenrong Lang,Caroline Hengartner,Konstantinos Kanellopoulos,Rakesh Kumar,Mohammad Sadrosadati,Onur Mutlu*

Main category: cs.AR

TL;DR: Athena是一个基于强化学习的框架，用于协调多级缓存预取器和片外预测器，以优化内存访问性能。


<details>
  <summary>Details</summary>
Motivation: 预取和片外预测是隐藏内存访问延迟的两种技术，但现有方法在协调这两种技术时存在不足，无法充分发挥它们的性能潜力。

Method: 将预取器和片外预测器的协调建模为强化学习问题，Athena作为RL代理观察系统特征（如准确率、带宽使用），选择协调动作（启用/禁用组件、调整预取器激进程度），并根据执行周期的变化获得奖励来学习优化策略。

Result: Athena在各种系统配置下（不同预取器、片外预测器和内存带宽组合）均优于现有协调策略，同时只产生适度的存储开销。

Conclusion: Athena提供了一个有效的强化学习框架，能够自主学习和协调预取器与片外预测器，显著提升内存密集型工作负载的性能。

Abstract: Prefetching and off-chip prediction are two techniques proposed to hide long memory access latencies in high-performance processors. In this work, we demonstrate that: (1) prefetching and off-chip prediction often provide complementary performance benefits, yet (2) naively combining them often fails to realize their full performance potential, and (3) existing prefetcher control policies leave significant room for performance improvement behind.
  Our goal is to design a holistic framework that can autonomously learn to coordinate an off-chip predictor with multiple prefetchers employed at various cache levels. To this end, we propose a new technique called Athena, which models the coordination between prefetchers and off-chip predictor (OCP) as a reinforcement learning (RL) problem. Athena acts as the RL agent that observes multiple system-level features (e.g., prefetcher/OCP accuracy, bandwidth usage) over an epoch of program execution, and uses them as state information to select a coordination action (i.e., enabling the prefetcher and/or OCP, and adjusting prefetcher aggressiveness). At the end of every epoch, Athena receives a numerical reward that measures the change in multiple system-level metrics (e.g., number of cycles taken to execute an epoch). Athena uses this reward to autonomously and continuously learn a policy to coordinate prefetchers with OCP.
  Our extensive evaluation using a diverse set of memory-intensive workloads shows that Athena consistently outperforms prior state-of-the-art coordination policies across a wide range of system configurations with various combinations of underlying prefetchers, OCPs, and main memory bandwidths, while incurring only modest storage overhead. Athena is freely available at https://github.com/CMU-SAFARI/Athena.

</details>


### [3] [Conduit: Programmer-Transparent Near-Data Processing Using Multiple Compute-Capable Resources in Solid State Drives](https://arxiv.org/abs/2601.17633)
*Rakesh Nadig,Vamanan Arulchelvan,Mayank Kabra,Harshita Gupta,Rahul Bera,Nika Mansouri Ghiasi,Nanditha Rao,Qingcai Jiang,Andreas Kosmas Kakolyris,Yu Liang,Mohammad Sadrosadati,Onur Mutlu*

Main category: cs.AR

TL;DR: Conduit是一个通用的、对程序员透明的SSD近数据处理框架，通过利用SSD的多种计算资源，实现指令粒度的卸载决策，相比现有技术性能提升1.8倍，能耗降低46%。


<details>
  <summary>Details</summary>
Motivation: 现有SSD近数据处理技术存在三个主要问题：1) 仅针对特定工作负载或内核；2) 未充分利用SSD的全部计算潜力；3) 缺乏程序员透明度。同时，现有主机与近内存加速器之间的计算分区技术也不适用于SSD，因为它们忽略了SSD资源的异构性，且卸载决策基于有限因素。

Method: Conduit采用编译时和运行时相结合的方法。编译时通过自定义编译器（如LLVM）将合适的应用代码段向量化为与SSD页面布局对齐的SIMD操作，并在向量化指令中嵌入元数据。运行时在SSD内部基于六个关键特征评估指令粒度卸载，使用成本函数选择最合适的SSD资源。

Result: 在六个数据密集型工作负载上使用内部事件驱动SSD模拟器进行评估，Conduit相比性能最佳的现有卸载策略性能提升1.8倍，能耗降低46%。

Conclusion: Conduit通过充分利用SSD的异构计算资源，实现了通用的、程序员透明的近数据处理框架，显著提升了性能并降低了能耗，为SSD近数据处理提供了更有效的解决方案。

Abstract: Solid-state drives (SSDs) are well suited for near-data processing (NDP) because they: (1) store large application datasets, and (2) support three NDP paradigms: in-storage processing (ISP), processing using DRAM in the SSD (PuD-SSD), and in-flash processing (IFP). A large body of prior SSD-based NDP techniques operate in isolation, mapping computations to only one or two NDP paradigms (i.e., ISP, PuD-SSD, or IFP) within the SSD. These techniques (1) are tailored to specific workloads or kernels, (2) do not exploit the full computational potential of an SSD, and (3) lack programmer-transparency. While several prior works propose techniques to partition computation between the host and near-memory accelerators, adapting these techniques to SSDs has limited benefits because they (1) ignore the heterogeneity of the SSD resources, and (2) make offloading decisions based on limited factors such as bandwidth utilization, or data movement cost. We propose Conduit, a general-purpose, programmer-transparent NDP framework for SSDs that leverages multiple SSD computation resources. At compile time, Conduit executes a custom compiler (e.g., LLVM) pass that (i) vectorizes suitable application code segments into SIMD operations that align with the SSD's page layout, and (ii) embeds metadata (e.g., operation type, operand sizes) into the vectorized instructions to guide runtime offloading decisions. At runtime, within the SSD, Conduit performs instruction-granularity offloading by evaluating six key features, and uses a cost function to select the most suitable SSD resource. We evaluate Conduit and two prior NDP offloading techniques using an in-house event-driven SSD simulator on six data-intensive workloads. Conduit outperforms the best-performing prior offloading policy by 1.8x and reduces energy consumption by 46%.

</details>


### [4] [Late Breaking Results: Boosting Efficient Dual-Issue Execution on Lightweight RISC-V Cores](https://arxiv.org/abs/2601.17940)
*Luca Colagrande,Luca Benini*

Main category: cs.AR

TL;DR: COPIFTv2在Snitch RISC-V核心上引入轻量级队列，简化双发射编程模型，提升性能和能效


<details>
  <summary>Details</summary>
Motivation: 大规模ML加速器需要大量PE，每个PE的面积和能耗预算严格。现有双发射方案COPIFT虽然能提升性能，但编程模型复杂且容易出错，需要繁琐的平铺和软件流水线步骤

Method: COPIFTv2在Snitch核心中引入轻量级队列，实现整数和浮点线程间的直接细粒度通信与同步，消除了COPIFT的平铺和软件流水线步骤

Result: 相比COPIFT，COPIFTv2实现最高1.49倍加速和1.47倍能效提升，峰值IPC达到1.81。整体显著提升了轻量级核心上双发射执行的效率和可编程性

Conclusion: COPIFTv2通过轻量级队列简化了双发射编程模型，在保持高性能的同时降低了软件复杂性，实现了开源且可复现的性能提升

Abstract: Large-scale ML accelerators rely on large numbers of PEs, imposing strict bounds on the area and energy budget of each PE. Prior work demonstrates that limited dual-issue capabilities can be efficiently integrated into a lightweight in-order open-source RISC-V core (Snitch), with a geomean IPC boost of 1.6x and a geomean energy efficiency gain of 1.3x, obtained by concurrently executing integer and FP instructions. Unfortunately, this required a complex and error-prone low level programming model (COPIFT). We introduce COPIFTv2 which augments Snitch with lightweight queues enabling direct, fine-grained communication and synchronization between integer and FP threads. By eliminating the tiling and software pipelining steps of COPIFT, we can remove much of its complexity and software overheads. As a result, COPIFTv2 achieves up to a 1.49x speedup and a 1.47x energy-efficiency gain over COPIFT, and a peak IPC of 1.81. Overall, COPIFTv2 significantly enhances the efficiency and programmability of dual-issue execution on lightweight cores. Our implementation is fully open source and performance experiments are reproducible using free software.

</details>


### [5] [Memory-Efficient FPGA Implementation of Stochastic Simulated Annealing](https://arxiv.org/abs/2601.18007)
*Duckgyu Shin,Naoya Onizawa,Warren J. Gross,Takahiro Hanyu*

Main category: cs.AR

TL;DR: 提出硬件感知随机模拟退火算法(HA-SSA)，在FPGA上实现内存高效的组合优化求解，比传统SA快114倍，内存效率比SSA高6倍


<details>
  <summary>Details</summary>
Motivation: 传统模拟退火算法(SA)在问题规模增大时计算时间急剧增加，虽然随机模拟退火(SSA)收敛更快，但在FPGA实现中需要大量内存存储中间结果，需要更内存高效的算法

Method: 提出硬件感知随机模拟退火算法(HA-SSA)，针对FPGA实现优化内存使用，减少中间结果存储需求，同时保持SSA的计算速度

Result: 在最大割组合优化问题上，HA-SSA比传统SA收敛速度快达114倍；在FPGA实现中，内存效率比传统SSA高6倍，同时保持高解质量

Conclusion: HA-SSA算法在FPGA上实现了内存高效的组合优化求解，显著提升了收敛速度和内存效率，为硬件加速优化算法提供了有效方案

Abstract: Simulated annealing (SA) is a well-known algorithm for solving combinatorial optimization problems. However, the computation time of SA increases rapidly, as the size of the problem grows. Recently, a stochastic simulated annealing (SSA) algorithm that converges faster than conventional SA has been reported. In this paper, we present a hardware-aware SSA (HA- SSA) algorithm for memory-efficient FPGA implementations. HA-SSA can reduce the memory usage of storing intermediate results while maintaining the computing speed of SSA. For evaluation purposes, the proposed algorithm is compared with the conventional SSA and SA approaches on maximum cut combinatorial optimization problems. HA-SSA achieves a convergence speed that is up to 114-times faster than that of the conventional SA algorithm depending on the maximum cut problem selected from the G-set which is a dataset of the maximum cut problems. HA-SSA is implemented on a field-programmable gate array (FPGA) (Xilinx Kintex-7), and it achieves up to 6-times the memory efficiency of conventional SSA while maintaining high solution quality for optimization problems.

</details>


### [6] [CIM-Tuner: Balancing the Compute and Storage Capacity of SRAM-CIM Accelerator via Hardware-mapping Co-exploration](https://arxiv.org/abs/2601.18070)
*Jinwu Chen,Yuhui Shi,He Wang,Zhe Jiang,Jun Yang,Xin Si,Zhenhua Zhu*

Main category: cs.AR

TL;DR: CIM-Tuner是一个自动工具，通过硬件-映射协同探索，在面积约束下实现SRAM-CIM加速器的硬件平衡和最优映射策略。


<details>
  <summary>Details</summary>
Motivation: 现有的SRAM-CIM加速器设计多样且映射策略未充分探索，这阻碍了计算与存储平衡的全面优化，可能导致显著的性能下降。

Method: 通过CIM宏的矩阵抽象和通用加速器模板确保跨设计的普适性；采用细粒度两级映射策略（加速器级调度和宏级分块）实现高效映射。

Result: 相比现有CIM映射方法，CIM-Tuner在扩展的策略空间中实现了1.58倍的能效提升和2.11倍的吞吐量提升；在相同面积预算下应用于SOTA CIM加速器也获得可比改进。

Conclusion: CIM-Tuner是一个有效的自动工具，能够优化SRAM-CIM加速器的硬件平衡和映射策略，显著提升性能，且已开源验证。

Abstract: As an emerging type of AI computing accelerator, SRAM Computing-In-Memory (CIM) accelerators feature high energy efficiency and throughput. However, various CIM designs and under-explored mapping strategies impede the full exploration of compute and storage balancing in SRAM-CIM accelerator, potentially leading to significant performance degradation. To address this issue, we propose CIM-Tuner, an automatic tool for hardware balancing and optimal mapping strategy under area constraint via hardware-mapping co-exploration. It ensures universality across various CIM designs through a matrix abstraction of CIM macros and a generalized accelerator template. For efficient mapping with different hardware configurations, it employs fine-grained two-level strategies comprising accelerator-level scheduling and macro-level tiling. Compared to prior CIM mapping, CIM-Tuner's extended strategy space achieves 1.58$\times$ higher energy efficiency and 2.11$\times$ higher throughput. Applied to SOTA CIM accelerators with identical area budget, CIM-Tuner also delivers comparable improvements. The simulation accuracy is silicon-verified and CIM-Tuner tool is open-sourced at https://github.com/champloo2878/CIM-Tuner.git.

</details>


### [7] [RTeAAL Sim: Using Tensor Algebra to Represent and Accelerate RTL Simulation (Extended Version)](https://arxiv.org/abs/2601.18140)
*Yan Zhu,Boru Chen,Christopher W. Fletcher,Nandeeka Nayak*

Main category: cs.AR

TL;DR: RTeAAL Sim将RTL仿真重构为稀疏张量代数问题，通过张量表示电路和仿真过程，减少编译开销和前端压力，性能与Verilator相当。


<details>
  <summary>Details</summary>
Motivation: 传统RTL仿真在CPU上存在瓶颈：仿真器将电路嵌入二进制导致编译时间长，执行时受CPU前端限制且指令缓存压力大。

Method: 将RTL仿真重新表述为稀疏张量代数问题，用张量表示RTL电路，将仿真过程作为稀疏张量代数内核实现，从而将仿真行为与二进制大小解耦。

Result: 原型系统即使只实现了部分优化，已能减少编译开销和前端压力，在不同CPU和ISA上性能与高度优化的Verilator仿真器相当。

Conclusion: 张量代数方法使RTL仿真能够利用成熟的张量代数优化技术，有效解决了传统仿真器的编译和性能瓶颈问题。

Abstract: RTL simulation on CPUs remains a persistent bottleneck in hardware design. State-of-the-art simulators embed the circuit directly into the simulation binary, resulting in long compilation times and execution that is fundamentally CPU frontend-bound, with severe instruction-cache pressure.
  This work proposes RTeAAL Sim, which reformulates RTL simulation as a sparse tensor algebra problem. By representing RTL circuits as tensors and simulation as a sparse tensor algebra kernel, RTeAAL Sim decouples simulation behavior from binary size and makes RTL simulation amenable to well-studied tensor algebra optimizations. We demonstrate that a prototype of our tensor-based simulator, even with a subset of these optimizations, already mitigates the compilation overhead and frontend pressure and achieves performance competitive with the highly optimized Verilator simulator across multiple CPUs and ISAs.

</details>


### [8] [Lifecycle Cost-Effectiveness Modeling for Redundancy-Enhanced Multi-Chiplet Architectures](https://arxiv.org/abs/2601.18159)
*Zizhen Liu,Fangzhiyi Wang,Mengdi Wang,Jing Ye,Hayden Kwok-Hay So,Cheng Liu,Huawei Li*

Main category: cs.AR

TL;DR: 提出一个用于多芯片架构的全面成本效益框架，引入生命周期成本效益(LCE)指标，通过联合优化制造成本和运行寿命来评估摊销计算成本。


<details>
  <summary>Details</summary>
Motivation: 随着计算密集型应用需求增长，多芯片架构成为有前景的替代方案，但有效管理经济效率仍然具有挑战性。现有成本模型要么忽略了芯片运行寿命期间计算价值的摊销，要么未能评估广泛采用的冗余策略如何影响长期成本效率。

Method: 提出一个综合成本效益框架，包含：(1) 覆盖芯片内和芯片间级别的冗余感知成本建模，(2) 可靠性驱动的寿命估计，(3) 冗余配置对整体经济效益的定量分析。通过广泛的权衡研究和多目标优化来验证模型有效性。

Result: 广泛的权衡和多目标优化研究证明了模型的有效性，揭示了模块级和芯片级冗余之间的必要协同优化策略，以实现成本高效的多芯片架构设计。

Conclusion: 该论文提出了一个全面的成本效益框架，通过引入LCE指标和集成冗余感知成本建模、可靠性驱动寿命估计等方法，为设计经济高效的多芯片架构提供了重要工具和策略。

Abstract: The growing demand for compute-intensive applications has made multi-chiplet architectures a promising alternative to monolithic designs, offering improved scalability and manufacturing flexibility. However, effectively managing the economic effectiveness remains challenging. Existing cost models either overlook the amortization of compute value over a chip's operational lifetime or fail to evaluate how redundancy strategies, which are widely adopted to enhance yield and fault tolerance, impact long-term cost efficiency. This paper presents a comprehensive cost-effectiveness framework for multi-chiplet architectures, introducing a novel Lifecycle Cost Effectiveness (LCE) metric that evaluates amortized compute costs by jointly optimizing manufacturing expenses and operational lifetime. Our approach uniquely integrates: (1) redundancy-aware cost modeling spanning both intra- and inter-chiplet levels, (2) reliability-driven lifetime estimation, and (3) quantitative analysis of how redundancy configurations on overall economic effectiveness. Extensive trade-off and multi-objective optimization studies demonstrate the effectiveness of the model and reveal essential co-optimization strategies between module and chiplet-level redundancy to achieve cost-efficient multi-chiplet architecture designs.

</details>
