{"id": "2509.08067", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.08067", "abs": "https://arxiv.org/abs/2509.08067", "authors": ["Rares Ifrim", "Decebal Popescu"], "title": "Analyzing the capabilities of HLS and RTL tools in the design of an FPGA Montgomery Multiplier", "comment": null, "summary": "We present the analysis of various FPGA design implementations of a\nMontgomery Modular Multiplier, compatible with the BLS12-381 elliptic curve,\nusing the Coarsely Integrated Operand Scanning approach of working with\ncomplete partial products on different digit sizes. The scope of the\nimplemented designs is to achieve a high-frequency, high-throughput solution\ncapable of computing millions of operations per second, which can provide a\nstrong foundation for different Elliptic Curve Cryptography operations such as\npoint addition and point multiplication. One important constraint for our\ndesigns was to only use FPGA DSP primitives for the arithmetic operations\nbetween digits employed in the CIOS algorithm as these primitives, when\npipelined properly, can operate at a high frequency while also relaxing the\nresource consumption of FPGA LUTs and FFs. The target of the analysis is to see\nhow different design choices and tool configurations influence the frequency,\nlatency and resource consumption when working with the latest AMD-Xilinx tools\nand Alveo FPGA boards in an RTL-HLS hybrid approach. We compare three\ncategories of designs: a Verilog naive approach where we rely on the Vivado\nsynthesizer to automatically choose when and where to use DSPs, a Verilog\noptimized approach by manually instantiating the DSP primitives ourselves and a\ncomplete High-Level Synthesis approach. We also compare the FPGA\nimplementations with an optimized software implementation of the same\nMontgomery multiplier written in Rust."}
{"id": "2509.08193", "categories": ["cs.AR", "cs.AI", "cs.ET"], "pdf": "https://arxiv.org/pdf/2509.08193", "abs": "https://arxiv.org/abs/2509.08193", "authors": ["Shvetank Prakash", "Andrew Cheng", "Olof Kindgren", "Ashiq Ahamed", "Graham Knight", "Jed Kufel", "Francisco Rodriguez", "Arya Tschand", "David Kong", "Mariam Elgamal", "Jerry Huang", "Emma Chen", "Gage Hills", "Richard Price", "Emre Ozer", "Vijay Janapa Reddi"], "title": "Lifetime-Aware Design of Item-Level Intelligence", "comment": null, "summary": "We present FlexiFlow, a lifetime-aware design framework for item-level\nintelligence (ILI) where computation is integrated directly into disposable\nproducts like food packaging and medical patches. Our framework leverages\nnatively flexible electronics which offer significantly lower costs than\nsilicon but are limited to kHz speeds and several thousands of gates. Our\ninsight is that unlike traditional computing with more uniform deployment\npatterns, ILI applications exhibit 1000X variation in operational lifetime,\nfundamentally changing optimal architectural design decisions when considering\ntrillion-item deployment scales. To enable holistic design and optimization, we\nmodel the trade-offs between embodied carbon footprint and operational carbon\nfootprint based on application-specific lifetimes. The framework includes: (1)\nFlexiBench, a workload suite targeting sustainability applications from\nspoilage detection to health monitoring; (2) FlexiBits, area-optimized RISC-V\ncores with 1/4/8-bit datapaths achieving 2.65X to 3.50X better energy\nefficiency per workload execution; and (3) a carbon-aware model that selects\noptimal architectures based on deployment characteristics. We show that\nlifetime-aware microarchitectural design can reduce carbon footprint by 1.62X,\nwhile algorithmic decisions can reduce carbon footprint by 14.5X. We validate\nour approach through the first tape-out using a PDK for flexible electronics\nwith fully open-source tools, achieving 30.9kHz operation. FlexiFlow enables\nexploration of computing at the Extreme Edge where conventional design\nmethodologies must be reevaluated to account for new constraints and\nconsiderations."}
{"id": "2509.08405", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.08405", "abs": "https://arxiv.org/abs/2509.08405", "authors": ["Chengzhen Meng", "Xiuzhuang Chen", "Hongjun Dai"], "title": "FASE: FPGA-Assisted Syscall Emulation for Rapid End-to-End Processor Performance Validation", "comment": "14 pages, 19 figures, to be submitted to IEEE TCAD", "summary": "The rapid advancement of AI workloads and domain-specific architectures has\nled to increasingly diverse processor microarchitectures, whose design\nexploration requires fast and accurate performance validation. However,\ntraditional workflows defer validation process until RTL design and SoC\nintegration are complete, significantly prolonging development and iteration\ncycle.\n  In this work, we present FASE framework, FPGA-Assisted Syscall Emulation, the\nfirst work for adapt syscall emulation on FPGA platforms, enabling complex\nmulti-thread benchmarks to directly run on the processor design without\nintegrating SoC or target OS for early-stage performance validation. FASE\nintroduces three key innovations to address three critical challenges for\nadapting FPGA-based syscall emulation: (1) only a minimal CPU interface is\nexposed, with other hardware components untouched, addressing the lack of a\nunified hardware interface in FPGA systems; (2) a Host-Target Protocol (HTP) is\nproposed to minimize cross-device data traffic, mitigating the low-bandwidth\nand high-latency communication between FPGA and host; and (3) a host-side\nruntime is proposed to remotely handle Linux-style system calls, addressing the\nchallenge of cross-device syscall delegation.\n  Experiments ware conducted on Xilinx FPGA with open-sourced RISC-V SMP\nprocessor Rocket. With single-thread CoreMark, FASE introduces less than 1%\nperformance error and achieves over 2000x higher efficiency compared to Proxy\nKernel due to FPGA acceleration. With complex OpenMP benchmarks, FASE\ndemonstrates over 96% performance validation accuracy for most single-thread\nworkloads and over 91.5% for most multi-thread workloads compared to full SoC\nvalidation, significantly reducing development complexity and time-to-feedback.\nAll components of FASE framework are released as open-source."}
{"id": "2509.08416", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.08416", "abs": "https://arxiv.org/abs/2509.08416", "authors": ["Yan Tan", "Xiangchen Meng", "Zijun Jiang", "Yangdi Lyu"], "title": "AutoVeriFix: Automatically Correcting Errors and Enhancing Functional Correctness in LLM-Generated Verilog Code", "comment": null, "summary": "Large language models (LLMs) have demonstrated impressive capabilities in\ngenerating software code for high-level programming languages such as Python\nand C++. However, their application to hardware description languages, such as\nVerilog, is challenging due to the scarcity of high-quality training data.\nCurrent approaches to Verilog code generation using LLMs often focus on\nsyntactic correctness, resulting in code with functional errors. To address\nthese challenges, we present AutoVeriFix, a novel Python-assisted two-stage\nframework designed to enhance the functional correctness of LLM-generated\nVerilog code. In the first stage, LLMs are employed to generate high-level\nPython reference models that define the intended circuit behavior. In the\nsecond stage, these Python models facilitate the creation of automated tests\nthat guide the generation of Verilog RTL implementations. Simulation\ndiscrepancies between the reference model and the Verilog code are iteratively\nused to identify and correct errors, thereby improving the functional accuracy\nand reliability of the LLM-generated Verilog code. Experimental results\ndemonstrate that our approach significantly outperforms existing\nstate-of-the-art methods in improving the functional correctness of generated\nVerilog code."}
{"id": "2509.08542", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.08542", "abs": "https://arxiv.org/abs/2509.08542", "authors": ["Wenlun Zhang", "Xinyu Li", "Shimpei Ando", "Kentaro Yoshioka"], "title": "BitROM: Weight Reload-Free CiROM Architecture Towards Billion-Parameter 1.58-bit LLM Inference", "comment": "Accepted to ASP-DAC 2026", "summary": "Compute-in-Read-Only-Memory (CiROM) accelerators offer outstanding energy\nefficiency for CNNs by eliminating runtime weight updates. However, their\nscalability to Large Language Models (LLMs) is fundamentally constrained by\ntheir vast parameter sizes. Notably, LLaMA-7B - the smallest model in LLaMA\nseries - demands more than 1,000 cm2 of silicon area even in advanced CMOS\nnodes. This paper presents BitROM, the first CiROM-based accelerator that\novercomes this limitation through co-design with BitNet's 1.58-bit quantization\nmodel, enabling practical and efficient LLM inference at the edge. BitROM\nintroduces three key innovations: 1) a novel Bidirectional ROM Array that\nstores two ternary weights per transistor; 2) a Tri-Mode Local Accumulator\noptimized for ternary-weight computations; and 3) an integrated Decode-Refresh\n(DR) eDRAM that supports on-die KV-cache management, significantly reducing\nexternal memory access during decoding. In addition, BitROM integrates\nLoRA-based adapters to enable efficient transfer learning across various\ndownstream tasks. Evaluated in 65nm CMOS, BitROM achieves 20.8 TOPS/W and a bit\ndensity of 4,967 kB/mm2 - offering a 10x improvement in area efficiency over\nprior digital CiROM designs. Moreover, the DR eDRAM contributes to a 43.6%\nreduction in external DRAM access, further enhancing deployment efficiency for\nLLMs in edge applications."}
