{"id": "2512.15251", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2512.15251", "abs": "https://arxiv.org/abs/2512.15251", "authors": ["Michael Mecik", "Martin Kumm"], "title": "Implementation and Analysis of Thermometer Encoding in DWN FPGA Accelerators", "comment": "Accepted at the 2025 Asilomar Conference on Signals, Systems, and Computers", "summary": "Fully parallel neural network accelerators on field-programmable gate arrays (FPGAs) offer high throughput for latency-critical applications but face hardware resource constraints. Weightless neural networks (WNNs) efficiently replace arithmetic with logic-based inference. Differential weightless neural networks (DWN) further optimize resource usage by learning connections between encoders and LUT layers via gradient-based training. However, DWNs rely on thermometer encoding, and the associated hardware cost has not been fully evaluated. We present a DWN hardware generator that includes thermometer encoding explicitly. Experiments on the Jet Substructure Classification (JSC) task show that encoding can increase LUT usage by up to 3.20$\\times$, dominating costs in small networks and highlighting the need for encoding-aware hardware design in DWN accelerators.", "AI": {"tldr": "DWN\u786c\u4ef6\u751f\u6210\u5668\u5305\u542b\u6e29\u5ea6\u8ba1\u7f16\u7801\uff0c\u5b9e\u9a8c\u663e\u793a\u7f16\u7801\u4f1a\u589e\u52a0LUT\u4f7f\u7528\u8fbe3.20\u500d\uff0c\u5728\u5c0f\u7f51\u7edc\u4e2d\u5360\u4e3b\u5bfc\u6210\u672c\uff0c\u5f3a\u8c03DWN\u52a0\u901f\u5668\u9700\u8981\u7f16\u7801\u611f\u77e5\u7684\u786c\u4ef6\u8bbe\u8ba1\u3002", "motivation": "FPGA\u4e0a\u7684\u5168\u5e76\u884c\u795e\u7ecf\u7f51\u7edc\u52a0\u901f\u5668\u5728\u5ef6\u8fdf\u5173\u952e\u5e94\u7528\u4e2d\u63d0\u4f9b\u9ad8\u541e\u5410\u91cf\uff0c\u4f46\u9762\u4e34\u786c\u4ef6\u8d44\u6e90\u9650\u5236\u3002DWN\u901a\u8fc7\u57fa\u4e8e\u68af\u5ea6\u7684\u8bad\u7ec3\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\uff0c\u4f46\u5176\u4f9d\u8d56\u6e29\u5ea6\u8ba1\u7f16\u7801\uff0c\u76f8\u5173\u7684\u786c\u4ef6\u6210\u672c\u5c1a\u672a\u5145\u5206\u8bc4\u4f30\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5305\u542b\u6e29\u5ea6\u8ba1\u7f16\u7801\u7684DWN\u786c\u4ef6\u751f\u6210\u5668\uff0c\u5e76\u5728Jet Substructure Classification (JSC)\u4efb\u52a1\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u7f16\u7801\u53ef\u4ee5\u589e\u52a0LUT\u4f7f\u7528\u8fbe3.20\u500d\uff0c\u5728\u5c0f\u7f51\u7edc\u4e2d\u5360\u4e3b\u5bfc\u6210\u672c\uff0c\u7a81\u663e\u4e86\u7f16\u7801\u5bf9\u786c\u4ef6\u8d44\u6e90\u7684\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "DWN\u52a0\u901f\u5668\u9700\u8981\u7f16\u7801\u611f\u77e5\u7684\u786c\u4ef6\u8bbe\u8ba1\uff0c\u6e29\u5ea6\u8ba1\u7f16\u7801\u7684\u786c\u4ef6\u6210\u672c\u5728\u5c0f\u578b\u7f51\u7edc\u4e2d\u53ef\u80fd\u4e3b\u5bfc\u603b\u4f53\u8d44\u6e90\u4f7f\u7528\uff0c\u9700\u8981\u5728\u8bbe\u8ba1\u65f6\u5145\u5206\u8003\u8651\u3002"}}
{"id": "2512.15515", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.15515", "abs": "https://arxiv.org/abs/2512.15515", "authors": ["Zhihan Xu", "Rajgopal Kannan", "Viktor K. Prasanna"], "title": "FAME: FPGA Acceleration of Secure Matrix Multiplication with Homomorphic Encryption", "comment": null, "summary": "Homomorphic Encryption (HE) enables secure computation on encrypted data, addressing privacy concerns in cloud computing. However, the high computational cost of HE operations, particularly matrix multiplication (MM), remains a major barrier to its practical deployment. Accelerating homomorphic encrypted MM (HE MM) is therefore crucial for applications such as privacy-preserving machine learning.\n  In this paper, we present a bandwidth-efficient FPGA implementation of HE MM. We first develop a cost model to evaluate the on-chip memory requirements for a given set of HE parameters and input matrix sizes. Our analysis shows that optimizing on-chip memory usage is critical for scalable and efficient HE MM. To this end, we design a novel datapath for Homomorphic Linear Transformation (HLT), the primary bottleneck in HE MM. The proposed datapath significantly reduces off-chip memory traffic and on-chip memory demand by enabling fine-grained data reuse. Leveraging this datapath, we introduce FAME, the first FPGA-based accelerator specifically tailored for HE MM. FAME supports arbitrary matrix shapes and is configurable across a wide range of HE parameter sets. We implement FAME on an Alveo U280 FPGA and evaluate its performance across diverse matrix sizes and shapes. Experimental results show that FAME achieves an average speedup of 221x over state-of-the-art CPU-based implementations, demonstrating its scalability and practicality for large-scale consecutive HE MM and real-world workloads.", "AI": {"tldr": "\u63d0\u51faFAME\uff1a\u9996\u4e2a\u4e13\u4e3a\u540c\u6001\u52a0\u5bc6\u77e9\u9635\u4e58\u6cd5\u4f18\u5316\u7684FPGA\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u6570\u636e\u901a\u8def\u8bbe\u8ba1\u51cf\u5c11\u5185\u5b58\u8bbf\u95ee\uff0c\u5b9e\u73b0221\u500d\u52a0\u901f\u3002", "motivation": "\u540c\u6001\u52a0\u5bc6\uff08HE\uff09\u867d\u7136\u80fd\u4fdd\u62a4\u4e91\u8ba1\u7b97\u7684\u9690\u79c1\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u6210\u672c\uff08\u7279\u522b\u662f\u77e9\u9635\u4e58\u6cd5\uff09\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002\u52a0\u901fHE\u77e9\u9635\u4e58\u6cd5\u5bf9\u9690\u79c1\u4fdd\u62a4\u673a\u5668\u5b66\u4e60\u7b49\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002", "method": "1. \u5f00\u53d1\u6210\u672c\u6a21\u578b\u8bc4\u4f30HE\u53c2\u6570\u548c\u8f93\u5165\u77e9\u9635\u5927\u5c0f\u7684\u7247\u4e0a\u5185\u5b58\u9700\u6c42\uff1b2. \u8bbe\u8ba1\u65b0\u578b\u540c\u6001\u7ebf\u6027\u53d8\u6362\uff08HLT\uff09\u6570\u636e\u901a\u8def\uff0c\u901a\u8fc7\u7ec6\u7c92\u5ea6\u6570\u636e\u91cd\u7528\u51cf\u5c11\u7247\u5916\u5185\u5b58\u6d41\u91cf\u548c\u7247\u4e0a\u5185\u5b58\u9700\u6c42\uff1b3. \u57fa\u4e8e\u6b64\u901a\u8def\u6784\u5efaFAME\u52a0\u901f\u5668\uff0c\u652f\u6301\u4efb\u610f\u77e9\u9635\u5f62\u72b6\u548c\u591a\u79cdHE\u53c2\u6570\u914d\u7f6e\u3002", "result": "\u5728Alveo U280 FPGA\u4e0a\u5b9e\u73b0FAME\uff0c\u5b9e\u9a8c\u663e\u793a\u76f8\u6bd4\u6700\u5148\u8fdb\u7684CPU\u5b9e\u73b0\u5e73\u5747\u52a0\u901f221\u500d\uff0c\u8bc1\u660e\u5176\u5728\u5927\u89c4\u6a21\u8fde\u7eedHE\u77e9\u9635\u4e58\u6cd5\u548c\u5b9e\u9645\u5de5\u4f5c\u8d1f\u8f7d\u4e2d\u7684\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "FAME\u901a\u8fc7\u4f18\u5316\u5185\u5b58\u4f7f\u7528\u548c\u6570\u636e\u91cd\u7528\uff0c\u663e\u8457\u63d0\u5347\u4e86HE\u77e9\u9635\u4e58\u6cd5\u7684\u6548\u7387\uff0c\u4e3a\u9690\u79c1\u4fdd\u62a4\u8ba1\u7b97\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u786c\u4ef6\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
