{"id": "2511.17773", "categories": ["cs.AR", "cs.CR"], "pdf": "https://arxiv.org/pdf/2511.17773", "abs": "https://arxiv.org/abs/2511.17773", "authors": ["Shiv Kaushik", "Mahesh Madhav", "Nagi Aboulenein", "Jason Bessette", "Sandeep Brahmadathan", "Ben Chaffin", "Matthew Erler", "Stephan Jourdan", "Thomas Maciukenas", "Ramya Masti", "Jon Perry", "Massimo Sutera", "Scott Tetrick", "Bret Toll", "David Turley", "Carl Worth", "Atiq Bajwa"], "title": "Optimized Memory Tagging on AmpereOne Processors", "comment": "12 pages, 8 figures", "summary": "Memory-safety escapes continue to form the launching pad for a wide range of security attacks, especially for the substantial base of deployed software that is coded in pointer-based languages such as C/C++. Although compiler and Instruction Set Architecture (ISA) extensions have been introduced to address elements of this issue, the overhead and/or comprehensive applicability have limited broad production deployment. The Memory Tagging Extension (MTE) to the ARM AArch64 Instruction Set Architecture is a valuable tool to address memory-safety escapes; when used in synchronous tag-checking mode, MTE provides deterministic detection and prevention of sequential buffer overflow attacks, and probabilistic detection and prevention of exploits resulting from temporal use-after-free pointer programming bugs. The AmpereOne processor, launched in 2024, is the first datacenter processor to support MTE. Its optimized MTE implementation uniquely incurs no memory capacity overhead for tag storage and provides synchronous tag-checking with single-digit performance impact across a broad range of datacenter class workloads. Furthermore, this paper analyzes the complete hardware-software stack, identifying application memory management as the primary remaining source of overhead and highlighting clear opportunities for software optimization. The combination of an efficient hardware foundation and a clear path for software improvement makes the MTE implementation of the AmpereOne processor highly attractive for deployment in production cloud environments.", "AI": {"tldr": "AmpereOne\u5904\u7406\u5668\u662f\u9996\u4e2a\u652f\u6301ARM MTE\u7684\u6570\u636e\u4e2d\u5fc3\u5904\u7406\u5668\uff0c\u5176\u4f18\u5316\u7684MTE\u5b9e\u73b0\u65e0\u5185\u5b58\u5bb9\u91cf\u5f00\u9500\uff0c\u540c\u6b65\u6807\u7b7e\u68c0\u67e5\u5bf9\u6570\u636e\u4e2d\u5fc3\u5de5\u4f5c\u8d1f\u8f7d\u6027\u80fd\u5f71\u54cd\u4ec5\u4e3a\u4e2a\u4f4d\u6570\u767e\u5206\u6bd4\uff0c\u4e3a\u751f\u4ea7\u4e91\u73af\u5883\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u6548\u786c\u4ef6\u57fa\u7840\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8eC/C++\u7b49\u6307\u9488\u8bed\u8a00\u8f6f\u4ef6\u4e2d\u7684\u5185\u5b58\u5b89\u5168\u95ee\u9898\uff0c\u8fd9\u4e9b\u5b89\u5168\u6f0f\u6d1e\u6784\u6210\u4e86\u5e7f\u6cdb\u5b89\u5168\u653b\u51fb\u7684\u57fa\u7840\uff0c\u73b0\u6709\u7f16\u8bd1\u5668\u6269\u5c55\u548cISA\u6269\u5c55\u5728\u5f00\u9500\u548c\u9002\u7528\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u91c7\u7528ARM AArch64\u6307\u4ee4\u96c6\u67b6\u6784\u4e2d\u7684\u5185\u5b58\u6807\u7b7e\u6269\u5c55(MTE)\uff0c\u5728AmpereOne\u5904\u7406\u5668\u4e2d\u5b9e\u73b0\u4f18\u5316\u7684MTE\u786c\u4ef6\u652f\u6301\uff0c\u5305\u62ec\u65e0\u5185\u5b58\u5bb9\u91cf\u5f00\u9500\u7684\u6807\u7b7e\u5b58\u50a8\u548c\u540c\u6b65\u6807\u7b7e\u68c0\u67e5\u673a\u5236\u3002", "result": "AmpereOne\u5904\u7406\u5668\u7684MTE\u5b9e\u73b0\u80fd\u591f\u786e\u5b9a\u6027\u68c0\u6d4b\u548c\u9884\u9632\u987a\u5e8f\u7f13\u51b2\u533a\u6ea2\u51fa\u653b\u51fb\uff0c\u6982\u7387\u6027\u68c0\u6d4b\u548c\u9884\u9632\u4f7f\u7528\u65f6\u5e8f\u91ca\u653e\u540e\u4f7f\u7528\u6307\u9488\u7f16\u7a0b\u9519\u8bef\uff0c\u6027\u80fd\u5f71\u54cd\u4ec5\u4e3a\u4e2a\u4f4d\u6570\u767e\u5206\u6bd4\u3002", "conclusion": "AmpereOne\u5904\u7406\u5668\u7684\u9ad8\u6548MTE\u5b9e\u73b0\u4e0e\u660e\u786e\u7684\u8f6f\u4ef6\u4f18\u5316\u8def\u5f84\u76f8\u7ed3\u5408\uff0c\u4f7f\u5176\u5728\u751f\u4ea7\u4e91\u73af\u5883\u90e8\u7f72\u4e2d\u6781\u5177\u5438\u5f15\u529b\uff0c\u5e94\u7528\u7a0b\u5e8f\u5185\u5b58\u7ba1\u7406\u662f\u5269\u4f59\u7684\u4e3b\u8981\u5f00\u9500\u6765\u6e90\uff0c\u5b58\u5728\u660e\u786e\u7684\u8f6f\u4ef6\u4f18\u5316\u673a\u4f1a\u3002"}}
{"id": "2511.17971", "categories": ["cs.AR", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.17971", "abs": "https://arxiv.org/abs/2511.17971", "authors": ["Jinsong Zhang", "Minghe Li", "Jiayi Tian", "Jinming Lu", "Zheng Zhang"], "title": "Comprehensive Design Space Exploration for Tensorized Neural Network Hardware Accelerators", "comment": null, "summary": "High-order tensor decomposition has been widely adopted to obtain compact deep neural networks for edge deployment. However, existing studies focus primarily on its algorithmic advantages such as accuracy and compression ratio-while overlooking the hardware deployment efficiency. Such hardware-unaware designs often obscure the potential latency and energy benefits of tensorized models. Although several works attempt to reduce computational cost by optimizing the contraction sequence based on the number of multiply-accumulate operations, they typically neglect the underlying hardware characteristics, resulting in suboptimal real-world performance. We observe that the contraction path, hardware architecture, and dataflow mapping are tightly coupled and must be optimized jointly within a unified design space to maximize deployment efficiency on real devices. To this end, we propose a co-exploration framework that unifies these dimensions within a unified design space for efficient training and inference of tensorized neural networks on edge platforms. The framework formulates a latency oriented search objective and solves it via a global latency-driven exploration across the unified design space to achieve end-to-end model efficiency. The optimized configurations are implemented on a configurable FPGA kernel, achieving up to 4 and 3.85 lower inference and training latency compared with the dense baseline.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u534f\u540c\u63a2\u7d22\u6846\u67b6\uff0c\u5c06\u5f20\u91cf\u5206\u89e3\u6a21\u578b\u7684\u6536\u7f29\u8def\u5f84\u3001\u786c\u4ef6\u67b6\u6784\u548c\u6570\u636e\u6d41\u6620\u5c04\u8054\u5408\u4f18\u5316\uff0c\u4ee5\u6700\u5927\u5316\u8fb9\u7f18\u8bbe\u5907\u4e0a\u7684\u90e8\u7f72\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u9ad8\u9636\u5f20\u91cf\u5206\u89e3\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u7b97\u6cd5\u4f18\u52bf\u800c\u5ffd\u89c6\u786c\u4ef6\u90e8\u7f72\u6548\u7387\uff0c\u786c\u4ef6\u65e0\u5173\u8bbe\u8ba1\u5f80\u5f80\u63a9\u76d6\u4e86\u5f20\u91cf\u5316\u6a21\u578b\u7684\u6f5c\u5728\u5ef6\u8fdf\u548c\u80fd\u8017\u4f18\u52bf\u3002", "method": "\u63d0\u51fa\u534f\u540c\u63a2\u7d22\u6846\u67b6\uff0c\u5728\u7edf\u4e00\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u8054\u5408\u4f18\u5316\u6536\u7f29\u8def\u5f84\u3001\u786c\u4ef6\u67b6\u6784\u548c\u6570\u636e\u6d41\u6620\u5c04\uff0c\u901a\u8fc7\u5168\u5c40\u5ef6\u8fdf\u9a71\u52a8\u63a2\u7d22\u5b9e\u73b0\u7aef\u5230\u7aef\u6a21\u578b\u6548\u7387\u3002", "result": "\u5728\u53ef\u914d\u7f6eFPGA\u5185\u6838\u4e0a\u5b9e\u73b0\u4f18\u5316\u914d\u7f6e\uff0c\u76f8\u6bd4\u5bc6\u96c6\u57fa\u7ebf\u6a21\u578b\uff0c\u63a8\u7406\u548c\u8bad\u7ec3\u5ef6\u8fdf\u5206\u522b\u964d\u4f4e4\u500d\u548c3.85\u500d\u3002", "conclusion": "\u6536\u7f29\u8def\u5f84\u3001\u786c\u4ef6\u67b6\u6784\u548c\u6570\u636e\u6d41\u6620\u5c04\u9700\u8981\u5728\u4e00\u4e2a\u7edf\u4e00\u8bbe\u8ba1\u7a7a\u95f4\u4e2d\u8054\u5408\u4f18\u5316\uff0c\u624d\u80fd\u6700\u5927\u5316\u5f20\u91cf\u5316\u795e\u7ecf\u7f51\u7edc\u5728\u8fb9\u7f18\u5e73\u53f0\u4e0a\u7684\u90e8\u7f72\u6548\u7387\u3002"}}
{"id": "2511.18234", "categories": ["cs.AR", "cs.DB"], "pdf": "https://arxiv.org/pdf/2511.18234", "abs": "https://arxiv.org/abs/2511.18234", "authors": ["Quanling Zhao", "Yanru Chen", "Runyang Tian", "Sumukh Pinge", "Weihong Xu", "Augusto Vega", "Steven Holmes", "Saransh Gupta", "Tajana Rosing"], "title": "HDDB: Efficient In-Storage SQL Database Search Using Hyperdimensional Computing on Ferroelectric NAND Flash", "comment": null, "summary": "Hyperdimensional Computing (HDC) encodes information and data into high-dimensional distributed vectors that can be manipulated using simple bitwise operations and similarity searches, offering parallelism, low-precision hardware friendliness, and strong robustness to noise. These properties are a natural fit for SQL database workloads dominated by predicate evaluation and scans, which demand low energy and low latency over large fact tables. Notably, HDC's noise-tolerance maps well onto emerging ferroelectric NAND (FeNAND) memories, which provide ultra-high density and in-storage compute capability but suffer from elevated raw bit-error rates. In this work, we propose HDDB, a hardware-software co-design that combines HDC with FeNAND multi-level cells (MLC) to perform in-storage SQL predicate evaluation and analytics with massive parallelism and minimal data movement. Particularly, we introduce novel HDC encoding techniques for standard SQL data tables and formulate predicate-based filtering and aggregation as highly efficient HDC operations that can happen in-storage. By exploiting the intrinsic redundancy of HDC, HDDB maintains correct predicate and decode outcomes under substantial device noise (up to 10% randomly corrupted TLC cells) without explicit error-correction overheads. Experiments on TPC-DS fact tables show that HDDB achieves up to 80.6x lower latency and 12,636x lower energy consumption compared to conventional CPU/GPU SQL database engines, suggesting that HDDB provides a practical substrate for noise-robust, memory-centric database processing.", "AI": {"tldr": "HDDB\u662f\u4e00\u4e2a\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5c06\u8d85\u7ef4\u8ba1\u7b97\u4e0e\u94c1\u7535NAND\u5b58\u50a8\u5668\u7ed3\u5408\uff0c\u5728\u5b58\u50a8\u5185\u6267\u884cSQL\u8c13\u8bcd\u8bc4\u4f30\u548c\u5206\u6790\uff0c\u5b9e\u73b0\u5927\u89c4\u6a21\u5e76\u884c\u548c\u6700\u5c0f\u6570\u636e\u79fb\u52a8\u3002", "motivation": "\u8d85\u7ef4\u8ba1\u7b97\u7684\u566a\u58f0\u5bb9\u9519\u7279\u6027\u4e0e\u65b0\u5174\u94c1\u7535NAND\u5b58\u50a8\u5668\u7684\u9ad8\u5bc6\u5ea6\u548c\u5b58\u50a8\u5185\u8ba1\u7b97\u80fd\u529b\u5929\u7136\u5339\u914d\uff0c\u4f46\u540e\u8005\u5b58\u5728\u8f83\u9ad8\u7684\u539f\u59cb\u6bd4\u7279\u9519\u8bef\u7387\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684HDC\u7f16\u7801\u6280\u672f\u7528\u4e8e\u6807\u51c6SQL\u6570\u636e\u8868\uff0c\u5c06\u57fa\u4e8e\u8c13\u8bcd\u7684\u8fc7\u6ee4\u548c\u805a\u5408\u5236\u5b9a\u4e3a\u9ad8\u6548\u7684HDC\u64cd\u4f5c\uff0c\u5229\u7528HDC\u56fa\u6709\u5197\u4f59\u5728\u8bbe\u5907\u566a\u58f0\u4e0b\u4fdd\u6301\u6b63\u786e\u7ed3\u679c\u3002", "result": "\u5728TPC-DS\u4e8b\u5b9e\u8868\u4e0a\u7684\u5b9e\u9a8c\u663e\u793a\uff0cHDDB\u76f8\u6bd4\u4f20\u7edfCPU/GPU SQL\u6570\u636e\u5e93\u5f15\u64ce\u5b9e\u73b0\u4e8680.6\u500d\u5ef6\u8fdf\u964d\u4f4e\u548c12,636\u500d\u80fd\u8017\u964d\u4f4e\u3002", "conclusion": "HDDB\u4e3a\u566a\u58f0\u9c81\u68d2\u3001\u5185\u5b58\u4e2d\u5fc3\u7684\u6570\u636e\u5904\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u57fa\u7840\u3002"}}
{"id": "2511.18687", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.18687", "abs": "https://arxiv.org/abs/2511.18687", "authors": ["Kasidis Arunruangsirilert", "Jiro Katto"], "title": "Evaluation of NVENC Split-Frame Encoding (SFE) for UHD Video Transcoding", "comment": "2025 Picture Coding Symposium (PCS 2025), 8-11 December 2025, Aachen, Germany", "summary": "NVIDIA Encoder (NVENC) features in modern NVIDIA GPUs, offer significant advantages over software encoders by providing comparable Rate-Distortion (RD) performance while consuming considerably less power. The increasing capability of consumer devices to capture footage in Ultra High-Definition (UHD) at 4K and 8K resolutions necessitates high-performance video transcoders for internet-based delivery. To address this demand, NVIDIA introduced Split-Frame Encoding (SFE), a technique that leverages multiple on-die NVENC chips available in high-end GPUs. SFE splits a single UHD frame for parallel encoding across these physical encoders and subsequently stitches the results, which significantly improves encoding throughput. However, this approach is known to incur an RD performance penalty. The widespread adoption of NVIDIA GPUs in data centers, driven by the rise of Generative AI, means NVENC is poised to play a critical role in transcoding UHD video. To better understand the performance-efficiency tradeoff of SFE, this paper evaluates SFE's impact on RD performance, encoding throughput, power consumption, and end-to-end latency using standardized test sequences. The results show that for real-time applications, SFE nearly doubles encoding throughput with a negligible RD performance penalty, which enables the use of higher-quality presets for 4K and makes real-time 8K encoding feasible, effectively offsetting the minor RD penalty. Moreover, SFE adds no latency at 4K and can reduce it at 8K, positioning it as a key enabler for high-throughput, real-time UHD transcoding.", "AI": {"tldr": "NVIDIA\u7684Split-Frame Encoding (SFE)\u6280\u672f\u901a\u8fc7\u5c06UHD\u5e27\u5206\u5272\u5230\u591a\u4e2aNVENC\u82af\u7247\u5e76\u884c\u7f16\u7801\uff0c\u663e\u8457\u63d0\u5347\u7f16\u7801\u541e\u5410\u91cf\uff0c\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u80fd\u4ee5\u53ef\u5ffd\u7565\u7684RD\u6027\u80fd\u635f\u5931\u5b9e\u73b0\u8fd1\u4e4e\u7ffb\u500d\u7684\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u968f\u7740\u6d88\u8d39\u8bbe\u5907\u80fd\u591f\u62cd\u64444K/8K\u8d85\u9ad8\u6e05\u89c6\u9891\uff0c\u9700\u8981\u9ad8\u6027\u80fd\u89c6\u9891\u8f6c\u7801\u5668\u8fdb\u884c\u4e92\u8054\u7f51\u4f20\u8f93\u3002NVIDIA GPU\u5728\u6570\u636e\u4e2d\u5fc3\u5e7f\u6cdb\u90e8\u7f72\uff0cNVENC\u5c06\u5728UHD\u89c6\u9891\u8f6c\u7801\u4e2d\u53d1\u6325\u5173\u952e\u4f5c\u7528\u3002", "method": "\u5229\u7528\u9ad8\u7aefGPU\u4e2d\u7684\u591a\u4e2aNVENC\u82af\u7247\uff0c\u5c06\u5355\u4e2aUHD\u5e27\u5206\u5272\u8fdb\u884c\u5e76\u884c\u7f16\u7801\uff0c\u7136\u540e\u62fc\u63a5\u7ed3\u679c\uff0c\u8bc4\u4f30SFE\u5bf9RD\u6027\u80fd\u3001\u7f16\u7801\u541e\u5410\u91cf\u3001\u529f\u8017\u548c\u7aef\u5230\u7aef\u5ef6\u8fdf\u7684\u5f71\u54cd\u3002", "result": "SFE\u5728\u5b9e\u65f6\u5e94\u7528\u4e2d\u4f7f\u7f16\u7801\u541e\u5410\u91cf\u8fd1\u4e4e\u7ffb\u500d\uff0cRD\u6027\u80fd\u635f\u5931\u53ef\u5ffd\u7565\uff0c\u652f\u63014K\u4f7f\u7528\u66f4\u9ad8\u8d28\u91cf\u9884\u8bbe\uff0c\u4f7f\u5b9e\u65f68K\u7f16\u7801\u53ef\u884c\uff0c4K\u65e0\u5ef6\u8fdf\u589e\u52a0\uff0c8K\u53ef\u964d\u4f4e\u5ef6\u8fdf\u3002", "conclusion": "SFE\u662f\u5b9e\u73b0\u9ad8\u541e\u5410\u91cf\u3001\u5b9e\u65f6UHD\u8f6c\u7801\u7684\u5173\u952e\u6280\u672f\uff0c\u5728\u541e\u5410\u91cf\u548c\u6548\u7387\u4e4b\u95f4\u63d0\u4f9b\u4e86\u826f\u597d\u7684\u6743\u8861\u3002"}}
{"id": "2511.18688", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.18688", "abs": "https://arxiv.org/abs/2511.18688", "authors": ["Kasidis Arunruangsirilert", "Jiro Katto"], "title": "Evaluation of GPU Video Encoder for Low-Latency Real-Time 4K UHD Encoding", "comment": "2025 IEEE International Conference on Visual Communications and Image Processing (VCIP 2025), 1-4 December 2025, Klagenfurt, Austria", "summary": "The demand for high-quality, real-time video streaming has grown exponentially, with 4K Ultra High Definition (UHD) becoming the new standard for many applications such as live broadcasting, TV services, and interactive cloud gaming. This trend has driven the integration of dedicated hardware encoders into modern Graphics Processing Units (GPUs). Nowadays, these encoders support advanced codecs like HEVC and AV1 and feature specialized Low-Latency and Ultra Low-Latency tuning, targeting end-to-end latencies of < 2 seconds and < 500 ms, respectively. As the demand for such capabilities grows toward the 6G era, a clear understanding of their performance implications is essential. In this work, we evaluate the low-latency encoding modes on GPUs from NVIDIA, Intel, and AMD from both Rate-Distortion (RD) performance and latency perspectives. The results are then compared against both the normal-latency tuning of hardware encoders and leading software encoders. Results show hardware encoders achieve significantly lower E2E latency than software solutions with slightly better RD performance. While standard Low-Latency tuning yields a poor quality-latency trade-off, the Ultra Low-Latency mode reduces E2E latency to 83 ms (5 frames) without additional RD impact. Furthermore, hardware encoder latency is largely insensitive to quality presets, enabling high-quality, low-latency streams without compromise.", "AI": {"tldr": "\u8bc4\u4f30NVIDIA\u3001Intel\u548cAMD GPU\u4e0a\u7684\u4f4e\u5ef6\u8fdf\u7f16\u7801\u6a21\u5f0f\uff0c\u6bd4\u8f83\u786c\u4ef6\u7f16\u7801\u5668\u4e0e\u8f6f\u4ef6\u7f16\u7801\u5668\u7684\u6027\u80fd\u8868\u73b0\uff0c\u53d1\u73b0\u786c\u4ef6\u7f16\u7801\u5668\u5728\u4fdd\u6301\u4f4e\u5ef6\u8fdf\u7684\u540c\u65f6\u63d0\u4f9b\u66f4\u597d\u7684\u7387\u5931\u771f\u6027\u80fd\u3002", "motivation": "\u968f\u77404K\u8d85\u9ad8\u6e05\u89c6\u9891\u6d41\u9700\u6c42\u7684\u589e\u957f\uff0c\u9700\u8981\u4e86\u89e3GPU\u786c\u4ef6\u7f16\u7801\u5668\u5728\u4f4e\u5ef6\u8fdf\u6a21\u5f0f\u4e0b\u7684\u6027\u80fd\u8868\u73b0\uff0c\u4e3a6G\u65f6\u4ee3\u7684\u9ad8\u8d28\u91cf\u5b9e\u65f6\u89c6\u9891\u6d41\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u4ece\u7387\u5931\u771f\u6027\u80fd\u548c\u5ef6\u8fdf\u4e24\u4e2a\u89d2\u5ea6\u8bc4\u4f30NVIDIA\u3001Intel\u548cAMD GPU\u7684\u4f4e\u5ef6\u8fdf\u7f16\u7801\u6a21\u5f0f\uff0c\u5e76\u4e0e\u786c\u4ef6\u7f16\u7801\u5668\u7684\u6b63\u5e38\u5ef6\u8fdf\u6a21\u5f0f\u548c\u9886\u5148\u8f6f\u4ef6\u7f16\u7801\u5668\u8fdb\u884c\u5bf9\u6bd4\u3002", "result": "\u786c\u4ef6\u7f16\u7801\u5668\u76f8\u6bd4\u8f6f\u4ef6\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u4e86\u663e\u8457\u66f4\u4f4e\u7684\u7aef\u5230\u7aef\u5ef6\u8fdf\u548c\u7565\u597d\u7684\u7387\u5931\u771f\u6027\u80fd\u3002\u8d85\u4f4e\u5ef6\u8fdf\u6a21\u5f0f\u53ef\u5c06E2E\u5ef6\u8fdf\u964d\u81f383\u6beb\u79d2\uff085\u5e27\uff09\u4e14\u4e0d\u5f71\u54cd\u7387\u5931\u771f\u6027\u80fd\u3002", "conclusion": "\u786c\u4ef6\u7f16\u7801\u5668\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u7684\u540c\u65f6\u80fd\u591f\u5b9e\u73b0\u6781\u4f4e\u5ef6\u8fdf\uff0c\u4e3a\u5b9e\u65f6\u89c6\u9891\u6d41\u5e94\u7528\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.18755", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.18755", "abs": "https://arxiv.org/abs/2511.18755", "authors": ["Xiaotong Huang", "He Zhu", "Tianrui Ma", "Yuxiang Xiong", "Fangxin Liu", "Zhezhi He", "Yiming Gan", "Zihan Liu", "Jingwen Leng", "Yu Feng", "Minyi Guo"], "title": "Splatonic: Architecture Support for 3D Gaussian Splatting SLAM via Sparse Processing", "comment": null, "summary": "3D Gaussian splatting (3DGS) has emerged as a promising direction for SLAM due to its high-fidelity reconstruction and rapid convergence. However, 3DGS-SLAM algorithms remain impractical for mobile platforms due to their high computational cost, especially for their tracking process.\n  This work introduces Splatonic, a sparse and efficient real-time 3DGS-SLAM algorithm-hardware co-design for resource-constrained devices. Inspired by classical SLAMs, we propose an adaptive sparse pixel sampling algorithm that reduces the number of rendered pixels by up to 256$\\times$ while retaining accuracy. To unlock this performance potential on mobile GPUs, we design a novel pixel-based rendering pipeline that improves hardware utilization via Gaussian-parallel rendering and preemptive $\u03b1$-checking. Together, these optimizations yield up to 121.7$\\times$ speedup on the bottleneck stages and 14.6$\\times$ end-to-end speedup on off-the-shelf GPUs. To further address new bottlenecks introduced by our rendering pipeline, we propose a pipelined architecture that simplifies the overall design while addressing newly emerged bottlenecks in projection and aggregation. Evaluated across four 3DGS-SLAM algorithms, Splatonic achieves up to 274.9$\\times$ speedup and 4738.5$\\times$ energy savings over mobile GPUs and up to 25.2$\\times$ speedup and 241.1$\\times$ energy savings over state-of-the-art accelerators, all with comparable accuracy.", "AI": {"tldr": "Splatonic\u662f\u4e00\u4e2a\u7a00\u758f\u9ad8\u6548\u76843DGS-SLAM\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u7a00\u758f\u50cf\u7d20\u91c7\u6837\u548c\u65b0\u578b\u50cf\u7d20\u6e32\u67d3\u6d41\u6c34\u7ebf\uff0c\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\uff0c\u76f8\u6bd4\u79fb\u52a8GPU\u83b7\u5f97274.9\u500d\u52a0\u901f\u548c4738.5\u500d\u8282\u80fd\u3002", "motivation": "3D\u9ad8\u65af\u6cfc\u6e85(3DGS)\u5728SLAM\u4e2d\u5c55\u73b0\u51fa\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u5feb\u901f\u6536\u655b\u7684\u4f18\u52bf\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u6210\u672c\u4f7f\u5176\u5728\u79fb\u52a8\u5e73\u53f0\u4e0a\u4e0d\u5b9e\u7528\uff0c\u7279\u522b\u662f\u8ddf\u8e2a\u8fc7\u7a0b\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u7a00\u758f\u50cf\u7d20\u91c7\u6837\u7b97\u6cd5\u51cf\u5c11\u6e32\u67d3\u50cf\u7d20\u6570\u91cf\u8fbe256\u500d\uff1b\u8bbe\u8ba1\u65b0\u578b\u57fa\u4e8e\u50cf\u7d20\u7684\u6e32\u67d3\u6d41\u6c34\u7ebf\uff0c\u901a\u8fc7\u9ad8\u65af\u5e76\u884c\u6e32\u67d3\u548c\u62a2\u5360\u5f0f\u03b1\u68c0\u67e5\u63d0\u9ad8\u786c\u4ef6\u5229\u7528\u7387\uff1b\u63d0\u51fa\u6d41\u6c34\u7ebf\u67b6\u6784\u7b80\u5316\u8bbe\u8ba1\u5e76\u89e3\u51b3\u6295\u5f71\u548c\u805a\u5408\u4e2d\u7684\u65b0\u74f6\u9888\u3002", "result": "\u5728\u74f6\u9888\u9636\u6bb5\u5b9e\u73b0121.7\u500d\u52a0\u901f\uff0c\u7aef\u5230\u7aef\u52a0\u901f14.6\u500d\uff1b\u76f8\u6bd4\u79fb\u52a8GPU\u5b9e\u73b0274.9\u500d\u52a0\u901f\u548c4738.5\u500d\u8282\u80fd\uff1b\u76f8\u6bd4\u6700\u5148\u8fdb\u52a0\u901f\u5668\u5b9e\u73b025.2\u500d\u52a0\u901f\u548c241.1\u500d\u8282\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u53ef\u6bd4\u8f83\u7684\u7cbe\u5ea6\u3002", "conclusion": "Splatonic\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6210\u529f\u89e3\u51b3\u4e863DGS-SLAM\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u5b9e\u73b0\u4e86\u5b9e\u65f6\u6027\u80fd\u548c\u9ad8\u80fd\u6548\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u76843D\u91cd\u5efa\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.19366", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.19366", "abs": "https://arxiv.org/abs/2511.19366", "authors": ["Alan Jia Bao Du", "Tarek S. Abdelrahman"], "title": "HeLEx: A Heterogeneous Layout Explorer for Spatial Elastic Coarse-Grained Reconfigurable Arrays", "comment": null, "summary": "We present HeLEx, a framework for determining the functional layout of heterogeneous spatially-configured elastic Coarse-Grained Reconfigurable Arrays (CGRAs). Given a collection of input data flow graphs (DFGs) and a target CGRA, the framework starts with a full layout in which every processing element (PE) supports every operation in the DFGs. It then employs a branch-and-bound (BB) search to eliminate operations out of PEs, ensuring that the input DFGs successfully map onto the resulting CGRAs, eventually returning an optimized heterogeneous CGRA. Experimental evaluation with 12 DFGs and 9 target CGRA sizes reveals that the framework reduces the number of operations by 68.7% on average, resulting in a reduction of CGRA area by almost 70% and of power by over 51%, all compared to the initial full layout. HeLEx generates CGRAs that are on average only within 6.2% of theoretically minimum CGRAs that support exactly the number of operations needed by the input DFGs. A comparison with functional layouts produced by two state-of-the-art frameworks indicates that HeLEx achieves better reduction in the number of operations, by up to 2.6X.", "AI": {"tldr": "HeLEx\u662f\u4e00\u4e2a\u7528\u4e8e\u786e\u5b9a\u5f02\u6784\u7a7a\u95f4\u914d\u7f6e\u5f39\u6027\u7c97\u7c92\u5ea6\u53ef\u91cd\u6784\u9635\u5217(CGRA)\u529f\u80fd\u5e03\u5c40\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u652f\u5b9a\u754c\u641c\u7d22\u4f18\u5316PE\u64cd\u4f5c\u96c6\uff0c\u663e\u8457\u51cf\u5c11CGRA\u9762\u79ef\u548c\u529f\u8017\u3002", "motivation": "\u4f20\u7edfCGRA\u8bbe\u8ba1\u4e2dPE\u652f\u6301\u6240\u6709\u64cd\u4f5c\u5bfc\u81f4\u8d44\u6e90\u6d6a\u8d39\uff0c\u9700\u8981\u4f18\u5316\u529f\u80fd\u5e03\u5c40\u4ee5\u51cf\u5c11\u9762\u79ef\u548c\u529f\u8017\u3002", "method": "\u4f7f\u7528\u5206\u652f\u5b9a\u754c\u641c\u7d22\u7b97\u6cd5\uff0c\u4ece\u5168\u529f\u80fd\u5e03\u5c40\u5f00\u59cb\u9010\u6b65\u6d88\u9664PE\u4e2d\u4e0d\u5fc5\u8981\u7684\u64cd\u4f5c\uff0c\u786e\u4fdd\u8f93\u5165\u6570\u636e\u6d41\u56fe\u4ecd\u80fd\u6210\u529f\u6620\u5c04\u3002", "result": "\u5e73\u5747\u51cf\u5c1168.7%\u7684\u64cd\u4f5c\u6570\u91cf\uff0cCGRA\u9762\u79ef\u51cf\u5c11\u8fd170%\uff0c\u529f\u8017\u964d\u4f4e\u8d85\u8fc751%\uff0c\u4e0e\u7406\u8bba\u6700\u5c0f\u503c\u4ec5\u5dee6.2%\u3002", "conclusion": "HeLEx\u6846\u67b6\u80fd\u6709\u6548\u4f18\u5316\u5f02\u6784CGRA\u529f\u80fd\u5e03\u5c40\uff0c\u5728\u64cd\u4f5c\u51cf\u5c11\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u8fbe2.6\u500d\u3002"}}
