<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Accelerating Post-Quantum Cryptography via LLM-Driven Hardware-Software Co-Design](https://arxiv.org/abs/2602.09410)
*Yuchao Liao,Tosiron Adegbija,Roman Lysecky*

Main category: cs.AR

TL;DR: LLMs加速后量子密码硬件设计：针对FALCON签名方案，LLM驱动的FPGA加速器设计相比传统HLS方法，在关键计算内核上实现最高2.6倍加速，缩短关键路径，但需权衡资源利用和功耗。


<details>
  <summary>Details</summary>
Motivation: 后量子密码算法计算复杂，硬件实现困难。传统硬件-软件协同设计过程耗时且复杂，需要自动化工具来加速PQC算法的FPGA加速器设计，以应对量子计算威胁。

Method: 提出基于LLM的框架，利用大语言模型分析PQC算法、识别性能关键组件、生成FPGA硬件描述候选方案。采用人机协同方式，将LLM生成的加速器与基于HLS的传统方法进行定量比较。

Result: LLM生成的加速器在FALCON低层计算密集型内核上，相比传统HLS方法实现最高2.6倍执行时间加速，关键路径更短。但存在资源利用率和功耗的权衡。LLM能显著减少设计工作和开发时间。

Conclusion: LLM能够自动化PQC算法的FPGA加速器设计迭代，为快速自适应PQC加速器设计提供有前景的新方向，特别是在后量子密码硬件实现领域具有重要应用价值。

Abstract: Post-quantum cryptography (PQC) is crucial for securing data against emerging quantum threats. However, its algorithms are computationally complex and difficult to implement efficiently on hardware. In this paper, we explore the potential of Large Language Models (LLMs) to accelerate the hardware-software co-design process for PQC, with a focus on the FALCON digital signature scheme. We present a novel framework that leverages LLMs to analyze PQC algorithms, identify performance-critical components, and generate candidate hardware descriptions for FPGA implementation. We present the first quantitative comparison between LLM-driven synthesis and conventional HLS-based approaches for low-level compute-intensive kernels in FALCON, showing that human-in-the-loop LLM-generated accelerators can achieve up to 2.6x speedup in kernel execution time with shorter critical paths, while highlighting trade-offs in resource utilization and power consumption. Our results suggest that LLMs can minimize design effort and development time by automating FPGA accelerator design iterations for PQC algorithms, offering a promising new direction for rapid and adaptive PQC accelerator design on FPGAs.

</details>


### [2] [Development of an Energy-Efficient and Real-Time Data Movement Strategy for Next-Generation Heterogeneous Mixed-Criticality Systems](https://arxiv.org/abs/2602.09554)
*Thomas Benz*

Main category: cs.AR

TL;DR: 论文探讨了ACES（自动驾驶、互联、电动化、共享出行）趋势下，工业领域对高性能计算、高能效和异构混合关键性系统的需求，以及内存系统与计算单元协同设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着汽车、机器人、航空航天等工业领域向ACES范式转变，对车载计算性能和高性能通信基础设施的需求急剧增加。同时，摩尔定律和登纳德缩放定律逐渐失效，计算系统需要向更大规模、更高异构性和专业化发展。ACES应用需要大量计算资源，且通常是资源受限的，因此对能效要求极高。

Method: 论文提出需要精心协同设计内存系统与用例、计算单元和加速器，以满足不同工业应用的性能和能效要求。这包括处理异构混合关键性系统（MCSs）中的资源争用问题，确保不同关键级别任务之间的最小干扰。

Result: 分析表明，ACES趋势导致对计算性能、内存带宽和容量的需求同步增长，同时需要处理实时关键任务与通用计算任务在同一物理平台上的共存问题。异构混合关键性系统对互连系统提出了更高的可预测性要求。

Conclusion: 满足ACES应用的性能与能效需求，需要系统性地协同设计内存系统、计算架构和通信基础设施，以应对计算异构化、数据规模增长和混合关键性系统带来的挑战。

Abstract: Industrial domains such as automotive, robotics, and aerospace are rapidly evolving to satisfy the increasing demand for machine-learning-driven Autonomy, Connectivity, Electrification, and Shared mobility (ACES). This paradigm shift inherently and significantly increases the requirement for onboard computing performance and high-performance communication infrastructure. At the same time, Moore's Law and Dennard Scaling are grinding to a halt, in turn, driving computing systems to larger scales and higher levels of heterogeneity and specialization, through application-specific hardware accelerators, instead of relying on technological scaling only. Approaching ACES requires this substantial amount of compute at an increasingly high energy-efficiency, since most use cases are fundamentally resource-bound. This increase in compute performance and heterogeneity goes hand in hand with a growing demand for high memory bandwidth and capacity as the driving applications grow in complexity, operating on huge and progressively irregular data sets and further requiring a steady influx of sensor data, increasing pressure both on on-chip and off-chip interconnect systems. Further, ACES combines real-time time-critical with general compute tasks on the same physical platform, sharing communication, storage, and micro-architectural resources. These heterogeneous mixed-criticality systems (MCSs) place additional pressure on the interconnect, demanding minimal contention between the different criticality levels to sustain a high degree of predictability. Fulfilling the performance and energy-efficiency requirements across a wide range of industrial applications requires a carefully co-designed process of the memory system with the use cases as well as the compute units and accelerators.

</details>
