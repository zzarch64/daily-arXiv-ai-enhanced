<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [M$^{\text{2}}$XFP: A Metadata-Augmented Microscaling Data Format for Efficient Low-bit Quantization](https://arxiv.org/abs/2601.19213)
*Weiming Hu,Zihan Zhang,Haoyan Zhang,Chen Zhang,Cong Guo,Yu Feng,Tianchi Hu,Guanglin Li,Guipeng Hu,Junsong Wang,Jingwen Leng*

Main category: cs.AR

TL;DR: 提出M2XFP方法，通过灵活的元数据和在线量化来改善低比特MX格式的精度损失，在保持高比特效率的同时显著缩小精度差距。


<details>
  <summary>Details</summary>
Motivation: 现有的低比特MX格式（如MXFP4）由于使用共享缩放因子的Power-of-Two格式，导致显著的精度下降。需要在保持高比特效率的同时，通过最小化元数据来恢复量化过程中的精度损失。

Method: 提出基于灵活元数据的算法-硬件协同设计，包括在线量化和简单编码。实现轻量级硬件单元并集成到加速器中，支持所提出的方法。

Result: 在LLM基准测试中，相比MXFP4平均减少70.63%的精度损失，相比最新的NVFP4减少37.30%。设计实现最高1.91倍加速和1.75倍能耗节省。

Conclusion: M2XFP方法通过灵活的元数据和硬件协同设计，在保持高比特效率的同时显著改善了低比特MX格式的精度问题，为大规模语言模型的高效部署提供了有效解决方案。

Abstract: Existing low-bit Microscaling (MX) formats, such as MXFP4, often suffer from substantial accuracy degradation due to the use of a shared scaling factor with the Power-of-Two format. In this work, we explore strategies that introduce minimal metadata to recover accuracy lost during quantization while maintaining high bit efficiency across a wide range of large language models. We propose a complete algorithm-hardware co-design based on flexible metadata, featuring an online quantization with simple encoding. To support the proposed method efficiently, we implement a lightweight hardware unit and integrate it into the accelerator. Evaluation results demonstrate that our method substantially narrows the accuracy gap, achieving on average a 70.63% reduction in accuracy loss compared to MXFP4 and a 37.30% reduction relative to the latest NVFP4 on LLM benchmarks. Furthermore, our design delivers up to 1.91$\times$ speedup and 1.75$\times$ energy savings over state-of-the-art accelerators. Our code is available at https://github.com/SJTU-ReArch-Group/M2XFP_ASPLOS26.

</details>


### [2] [A Reconfigurable Framework for AI-FPGA Agent Integration and Acceleration](https://arxiv.org/abs/2601.19263)
*Aybars Yunusoglu,Talha Coskun,Hiruna Vishwamith,Murat Isik,I. Can Dikmen*

Main category: cs.AR

TL;DR: AI FPGA Agent框架通过软件代理动态分区AI模型、调度硬件卸载，结合参数化加速器核心，在FPGA上实现高效AI推理，相比CPU延迟降低10倍，比GPU能效高2-3倍。


<details>
  <summary>Details</summary>
Motivation: AI在实时和能耗受限环境中的部署需求日益增长，传统CPU/GPU在严格延迟或功耗预算下效率不足。FPGA虽然提供定制化并行和硬件级优化潜力，但AI工作负载映射到FPGA仍面临硬件软件协同设计和数据编排的复杂性挑战。

Method: 提出AI FPGA Agent框架：1) 运行时软件代理动态分区AI模型，调度计算密集型层进行硬件卸载，管理数据传输；2) 硬件组件包括参数化加速器核心，使用量化算术优化高吞吐量推理。

Result: 相比CPU基线延迟降低超过10倍，相比GPU实现能效高2-3倍，同时保持分类精度在完整精度参考的0.2%范围内。

Conclusion: AI-FPGA协同设计具有可扩展、高能效AI部署的潜力，AI FPGA Agent框架简化了深度神经网络在FPGA上的集成和加速。

Abstract: Artificial intelligence (AI) is increasingly deployed in real-time and energy-constrained environments, driving demand for hardware platforms that can deliver high performance and power efficiency. While central processing units (CPUs) and graphics processing units (GPUs) have traditionally served as the primary inference engines, their general-purpose nature often leads to inefficiencies under strict latency or power budgets. Field-Programmable Gate Arrays (FPGAs) offer a promising alternative by enabling custom-tailored parallelism and hardware-level optimizations. However, mapping AI workloads to FPGAs remains challenging due to the complexity of hardware-software co-design and data orchestration. This paper presents AI FPGA Agent, an agent-driven framework that simplifies the integration and acceleration of deep neural network inference on FPGAs. The proposed system employs a runtime software agent that dynamically partitions AI models, schedules compute-intensive layers for hardware offload, and manages data transfers with minimal developer intervention. The hardware component includes a parameterizable accelerator core optimized for high-throughput inference using quantized arithmetic. Experimental results demonstrate that the AI FPGA Agent achieves over 10x latency reduction compared to CPU baselines and 2-3x higher energy efficiency than GPU implementations, all while preserving classification accuracy within 0.2% of full-precision references. These findings underscore the potential of AI-FPGA co-design for scalable, energy-efficient AI deployment.

</details>


### [3] [GenPairX: A Hardware-Algorithm Co-Designed Accelerator for Paired-End Read Mapping](https://arxiv.org/abs/2601.19384)
*Julien Eudine,Chu Li,Zhuo Cheng,Renzo Andri,Can Firtina,Mohammad Sadrosadati,Nika Mansouri Ghiasi,Konstantina Koliogeorgi,Anirban Nag,Arash Tavakkol,Haiyu Mao,Onur Mutlu,Shai Bergman,Ji Zhang*

Main category: cs.AR

TL;DR: GenPairX：一种硬件算法协同设计的加速器，通过联合考虑配对末端读段的新过滤算法和轻量级对齐算法，显著提升配对末端读段映射性能，相比现有方案实现1575倍和1.43倍的每瓦吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 基因组测序中读段映射是主要性能瓶颈，现有过滤算法对配对末端读段效果有限，因为它们独立评估每个读段且过滤率较低，需要更有效的解决方案来减少计算负载并提高内存密集型操作的吞吐量。

Method: 提出GenPairX硬件算法协同设计加速器：1）新颖的过滤算法联合考虑配对中的两个读段以提高过滤效果，用轻量级对齐算法替代大部分计算昂贵的动态规划操作；2）两种专用硬件机制支持所提算法。

Result: GenPairX相比最先进的解决方案实现显著性能提升：与领先的基于CPU和基于加速器的读段映射器相比，分别实现1575倍和1.43倍的每瓦吞吐量提升，且不损失准确性。

Conclusion: GenPairX通过硬件算法协同设计有效解决了配对末端读段映射的计算瓶颈，在保持准确性的同时大幅提升了性能和能效，为基因组分析提供了高效的加速解决方案。

Abstract: Genome sequencing has become a central focus in computational biology. A genome study typically begins with sequencing, which produces millions to billions of short DNA fragments known as reads. Read mapping aligns these reads to a reference genome. Read mapping for short reads comes in two forms: single-end and paired-end, with the latter being more prevalent due to its higher accuracy and support for advanced analysis. Read mapping remains a major performance bottleneck in genome analysis due to expensive dynamic programming. Prior efforts have attempted to mitigate this cost by employing filters to identify and potentially discard computationally expensive matches and leveraging hardware accelerators to speed up the computations. While partially effective, these approaches have limitations. In particular, existing filters are often ineffective for paired-end reads, as they evaluate each read independently and exhibit relatively low filtering ratios. In this work, we propose GenPairX, a hardware-algorithm co-designed accelerator that efficiently minimizes the computational load of paired-end read mapping while enhancing the throughput of memory-intensive operations. GenPairX introduces: (1) a novel filtering algorithm that jointly considers both reads in a pair to improve filtering effectiveness, and a lightweight alignment algorithm to replace most of the computationally expensive dynamic programming operations, and (2) two specialized hardware mechanisms to support the proposed algorithms. Our evaluations show that GenPairX delivers substantial performance improvements over state-of-the-art solutions, achieving 1575x and 1.43x higher throughput per watt compared to leading CPU-based and accelerator-based read mappers, respectively, all without compromising accuracy.

</details>


### [4] [Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation](https://arxiv.org/abs/2601.19747)
*Jiale Liu,Taiyu Zhou,Tianqi Jiang*

Main category: cs.AR

TL;DR: Veri-Sure是一个多智能体框架，通过设计契约对齐智能体意图，使用静态依赖切片指导的补丁机制进行精确修复，结合多分支验证管道确保RTL代码生成的功能正确性，在扩展的VerilogEval-v2-EXT基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前EDA领域使用LLM进行RTL设计面临三个主要瓶颈：1) 基于仿真的评估测试覆盖率和可靠性有限；2) 迭代调试引入的回归和修复幻觉；3) 智能体交接过程中的语义漂移。需要解决这些硅级正确性问题。

Method: 提出Veri-Sure多智能体框架：1) 建立设计契约对齐智能体意图；2) 使用静态依赖切片指导的补丁机制进行精确局部修复；3) 集成多分支验证管道，结合轨迹驱动的时序分析和形式验证（基于断言的检查和布尔等价证明）。

Result: 扩展了VerilogEval-v2-EXT基准，增加53个工业级设计任务和分层难度级别。Veri-Sure在验证正确的RTL代码生成方面超越了独立LLM和先前的智能体系统，达到最先进性能。

Conclusion: Veri-Sure通过设计契约、精确补丁机制和多分支验证管道的集成，解决了RTL设计中的硅级正确性瓶颈，为LLM在EDA领域的可靠应用提供了有效框架。

Abstract: In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents' intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.

</details>
