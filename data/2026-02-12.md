<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 5]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [ACE-RTL: When Agentic Context Evolution Meets RTL-Specialized LLMs](https://arxiv.org/abs/2602.10218)
*Chenhui Deng,Zhongzhi Yu,Guan-Ting Liu,Nathaniel Pinckney,Haoxing Ren*

Main category: cs.AR

TL;DR: ACE-RTL提出了一种结合领域专用LLM和前沿推理LLM的硬件设计自动化方法，通过生成器、反射器和协调器协同迭代优化RTL代码，在CVDP基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前硬件设计自动化中，领域适应的RTL模型和基于模拟反馈的通用LLM代理系统各有优缺点，需要一种统一的方法来结合两者的优势。

Method: 提出ACE-RTL框架，整合了在170万RTL样本上训练的专用LLM和前沿推理LLM，通过生成器、反射器、协调器三个组件迭代优化代码，并引入并行扩展策略减少迭代次数。

Result: 在CVDP基准测试中，ACE-RTL相比14个竞争基线实现了最高44.87%的通过率提升，平均仅需4次迭代即可获得正确解决方案。

Conclusion: ACE-RTL成功统一了硬件设计自动化的两种主要路径，通过智能上下文演化实现了更高效准确的RTL代码生成。

Abstract: Recent advances in large language models (LLMs) have sparked growing interest in applying them to hardware design automation, particularly for accurate RTL code generation. Prior efforts follow two largely independent paths: (i) training domain-adapted RTL models to internalize hardware semantics, (ii) developing agentic systems that leverage frontier generic LLMs guided by simulation feedback. However, these two paths exhibit complementary strengths and weaknesses. In this work, we present ACE-RTL that unifies both directions through Agentic Context Evolution (ACE). ACE-RTL integrates an RTL-specialized LLM, trained on a large-scale dataset of 1.7 million RTL samples, with a frontier reasoning LLM through three synergistic components: the generator, reflector, and coordinator. These components iteratively refine RTL code toward functional correctness. We further introduce a parallel scaling strategy that significantly reduces the number of iterations required to reach correct solutions. On the Comprehensive Verilog Design Problems (CVDP) benchmark, ACE-RTL achieves up to a 44.87% pass rate improvement over 14 competitive baselines while requiring only four iterations on average.

</details>


### [2] [Area-Efficient In-Memory Computing for Mixture-of-Experts via Multiplexing and Caching](https://arxiv.org/abs/2602.10254)
*Hanyuan Gao,Xiaoxuan Yang*

Main category: cs.AR

TL;DR: 提出面向MoE Transformer的面积高效存内计算架构，通过交叉开关复用、专家分组调度和门输出缓存优化，提升面积效率2.2倍，生成性能提升4.2倍。


<details>
  <summary>Details</summary>
Motivation: MoE层通过激活部分专家权重提升模型性能，特别适合存内计算架构部署，但存内计算芯片通常存在较大的外围电路面积开销问题，需要更高效的架构设计。

Method: 1) 提出交叉开关级复用策略，利用MoE稀疏性让多个交叉开关共享外围电路；2) 专家分组和组级调度方法缓解共享带来的负载不平衡和争用开销；3) 门输出缓存存储必要结果，避免生成阶段专家选择路由器访问所有隐藏状态带来的额外计算开销。

Result: MoE部分面积效率相比SOTA架构提升2.2倍；生成阶段缓存使8个token生成的性能和能效分别提升4.2倍和10.1倍；总体性能密度达到15.6 GOPS/W/mm²。

Conclusion: 提出的面积高效存内计算架构有效解决了MoE Transformer在PIM部署中的面积开销问题，通过交叉开关复用、专家分组调度和门输出缓存等创新方法，显著提升了面积效率、性能和能效。

Abstract: Mixture-of-Experts (MoE) layers activate a subset of model weights, dubbed experts, to improve model performance. MoE is particularly promising for deployment on process-in-memory (PIM) architectures, because PIM can naturally fit experts separately and provide great benefits for energy efficiency. However, PIM chips often suffer from large area overhead, especially in the peripheral circuits. In this paper, we propose an area-efficient in-memory computing architecture for MoE transformers. First, to reduce area, we propose a crossbar-level multiplexing strategy that exploits MoE sparsity: experts are deployed on crossbars and multiple crossbars share the same peripheral circuits. Second, we propose expert grouping and group-wise scheduling methods to alleviate the load imbalance and contention overhead caused by sharing. In addition, to address the problem that the expert choice router requires access to all hidden states during generation, we propose a gate-output (GO)cache to store necessary results and bypass expensive additional computation. Experiments show that our approaches improve the area efficiency of the MoE part by up to 2.2x compared to a SOTA architecture. During generation, the cache improves performance and energy efficiency by 4.2x and 10.1x, respectively, compared to the baseline when generating 8 tokens. The total performance density achieves 15.6 GOPS/W/mm2. The code is open source at https://github.com/superstarghy/MoEwithPIM.

</details>


### [3] [DRAMPyML: A Formal Description of DRAM Protocols with Timed Petri Nets](https://arxiv.org/abs/2602.10654)
*Derek Christ,Thomas Zimmermann,Philippe Barbie,Dmitri Saberi,Yao Yin,Matthias Jung*

Main category: cs.AR

TL;DR: 提出基于时间Petri网和Python的DRAM协议建模方法，改进JEDEC标准中简化的状态机模型，提供更准确、可执行的协议表示


<details>
  <summary>Details</summary>
Motivation: JEDEC定义的DRAM标准协议日益复杂，现有简化状态机无法反映内存bank的并行操作，难以理解和验证复杂的设备层次结构

Method: 使用时间Petri网和Python构建演化建模方法，创建更准确的DRAM协议表示模型

Result: 模型使DRAM协议更易理解且可直接执行，支持评估关键指标并验证控制器RTL模型、DRAM逻辑和内存模拟器

Conclusion: 提出的建模方法显著改进DRAM协议的理解和验证能力，为复杂内存系统设计提供有效工具

Abstract: The JEDEC committee defines various domain-specific DRAM standards. These standards feature increasingly complex and evolving protocol specifications, which are detailed in timing diagrams and command tables. Understanding these protocols is becoming progressively challenging as new features and complex device hierarchies are difficult to comprehend without an expressive model. While each JEDEC standard features a simplified state machine, this state machine fails to reflect the parallel operation of memory banks.
  In this paper, we present an evolved modeling approach based on timed Petri nets and Python. This model provides a more accurate representation of DRAM protocols, making them easier to understand and directly executable, which enables the evaluation of interesting metrics and the verification of controller RTL models, DRAM logic and memory simulators.

</details>


### [4] [Fault Tolerant Design of IGZO-based Binary Search ADCs](https://arxiv.org/abs/2602.10790)
*Paula Carolina Lozano Duarte,Sule Ozev,Mehdi Tahoori*

Main category: cs.AR

TL;DR: 提出分层故障注入框架分析单极技术中二进制搜索ADC的缺陷敏感性，通过选择性冗余策略将故障覆盖率从60%提升至92%，面积开销仅4.2%


<details>
  <summary>Details</summary>
Motivation: 柔性电子技术（如IGZO）在可穿戴传感、健康监测等新兴应用中前景广阔，但单极技术相比成熟CMOS技术具有更高的缺陷密度和工艺变化。作为关键传感器接口的ADC对制造缺陷的脆弱性尚未得到充分理解。

Method: 提出分层故障注入框架，结合晶体管级缺陷表征和系统级故障传播分析，在转换层次结构中高效探索单故障和多故障场景，识别关键故障敏感电路组件，并实施选择性冗余策略。

Result: 缺陷容忍设计将单故障注入下的故障覆盖率从60%提升至92%，多故障注入下从34%提升至77.6%，同时仅产生4.2%的面积开销和6%的功耗增加。

Conclusion: 该框架有效识别了二进制搜索ADC中的关键故障敏感组件，通过选择性冗余策略显著提升了缺陷容忍能力，虽然基于IGZO-TFT验证，但适用于所有新兴单极技术。

Abstract: Thin-film technologies such as Indium Gallium Zinc Oxide (IGZO) enable Flexible Electronics (FE) for emerging applications in wearable sensing, personal health monitoring, and large-area systems. Analog-to-digital converters (ADCs) serve as critical sensor interfaces in these systems. Yet, their vulnerability to manufacturing defects remains poorly understood despite unipolar technologies' inherently high defect densities and process variations compared to mature CMOS technologies. We present a hierarchical fault injection framework to characterize defect sensitivity in Binary Search ADCs implemented in n-type only technologies. Our methodology combines transistor-level defect characterization with system-level fault propagation analysis, enabling efficient exploration of both single and multiple fault scenarios across the conversion hierarchy. The framework identifies critical fault-sensitive circuit components and enables selective redundancy strategies targeting only the most sensitive components. The resulting defect-tolerant designs improve fault coverage from 60% to 92% under single-fault injections and from 34% to 77.6% under multi-fault injection, while incurring only 4.2% area overhead and 6% power increase. While validated on IGZO-TFTs, the methodology applies to all emerging unipolar technologies.

</details>


### [5] [From Buffers to Registers: Unlocking Fine-Grained FlashAttention with Hybrid-Bonded 3D NPU Co-Design](https://arxiv.org/abs/2602.11016)
*Jinxin Yu,Yudong Pan,Mengdi Wang,Huawei Li,Yinhe Han,Xiaowei Li,Ying Wang*

Main category: cs.AR

TL;DR: 3D-Flow：一种基于3D堆叠空间加速器的Transformer优化方案，通过垂直分区PE层间的寄存器通信，减少片上SRAM访问，显著降低能耗并提升性能。


<details>
  <summary>Details</summary>
Motivation: Transformer模型存在二次注意力复杂度和内存瓶颈问题。现有加速器虽然减少了片外流量，但片上SRAM访问在长序列任务中占能耗60%以上，成为新的瓶颈。

Method: 提出3D-Flow：混合键合3D堆叠空间加速器，支持垂直分区PE层间的寄存器到寄存器通信；设计3D-FlashAttention细粒度调度方法，实现无气泡垂直数据流，避免片上SRAM往返。

Result: 在Transformer工作负载（OPT和QWEN模型）上评估，相比最先进的2D和3D设计，能耗降低46-93%，速度提升1.4-7.6倍。

Conclusion: 3D-Flow通过3D垂直通信架构和细粒度调度，有效解决了Transformer加速中的片上SRAM访问瓶颈，为未来AI加速器设计提供了新方向。

Abstract: Transformer-based models dominate modern AI workloads but exacerbate memory bottlenecks due to their quadratic attention complexity and ever-growing model sizes. Existing accelerators, such as Groq and Cerebras, mitigate off-chip traffic with large on-chip caches, while algorithmic innovations such as FlashAttention fuse operators to avoid materializing large attention matrices. However, as off-chip traffic decreases, our measurements show that on-chip SRAM accesses account for over 60% of energy in long-sequence workloads, making cache access the new bottleneck. We propose 3D-Flow, a hybrid-bonded, 3D-stacked spatial accelerator that enables register-to-register communication across vertically partitioned PE tiers. Unlike 2D multi-array architectures limited by NoC-based router-to-router transfers, 3D-Flow leverages sub-10 um vertical TSVs to sustain cycle-level operator pipelining with minimal overhead. On top of this architecture, we design 3D-FlashAttention, a fine-grained scheduling method that balances latency across tiers, forming a bubble-free vertical dataflow without on-chip SRAM roundtrips. Evaluations on Transformer workloads (OPT and QWEN models) show that our 3D spatial accelerator reduces 46-93% energy consumption and achieves 1.4x-7.6x speedups compared to state-of-the-art 2D and 3D designs.

</details>
