{"id": "2510.21745", "categories": ["cs.AR", "cs.DC"], "pdf": "https://arxiv.org/pdf/2510.21745", "abs": "https://arxiv.org/abs/2510.21745", "authors": ["Eashan Wadhwa", "Shanker Shreejith"], "title": "Simopt-Power: Leveraging Simulation Metadata for Low-Power Design Synthesis", "comment": null, "summary": "Excessive switching activity is a primary contributor to dynamic power\ndissipation in modern FPGAs, where fine-grained configurability amplifies\nsignal toggling and associated capacitance. Conventional low-power techniques\n-- gating, clock-domain partitioning, and placement-aware netlist rewrites -\neither require intrusive design changes or offer diminishing returns as device\ndensities grow. In this work, we present Simopt-power, a simulator-driven\noptimisation framework that leverages simulation analysis to identify and\nselectively reconfigure high-toggle paths. By feeding activity profiles back\ninto a lightweight transformation pass, Simopt-power judiciously inserts\nduplicate truth table logic using Shannon Decomposition principle and relocates\ncritical nets, thereby attenuating unnecessary transitions without perturbing\nfunctional behaviour. We evaluated this framework on open-source RTLLM\nbenchmark, with Simopt-power achieves an average switching-induced power\nreduction of ~9\\% while incurring only ~9\\% additional LUT-equivalent resources\nfor arithmetic designs. These results demonstrate that coupling simulation\ninsights with targeted optimisations can yield a reduced dynamic power,\noffering a practical path toward using simulation metadata in the FPGA-CAD\nflow.", "AI": {"tldr": "Simopt-power\u662f\u4e00\u4e2a\u57fa\u4e8e\u4eff\u771f\u5206\u6790\u7684FPGA\u4f4e\u529f\u8017\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bc6\u522b\u9ad8\u5207\u6362\u8def\u5f84\u5e76\u9009\u62e9\u6027\u91cd\u914d\u7f6e\uff0c\u5b9e\u73b0\u7ea69%\u7684\u52a8\u6001\u529f\u8017\u964d\u4f4e\uff0c\u4ec5\u589e\u52a0\u7ea69%\u7684LUT\u8d44\u6e90\u5f00\u9500\u3002", "motivation": "\u73b0\u4ee3FPGA\u4e2d\u8fc7\u5ea6\u5207\u6362\u6d3b\u52a8\u662f\u52a8\u6001\u529f\u8017\u7684\u4e3b\u8981\u6765\u6e90\uff0c\u4f20\u7edf\u4f4e\u529f\u8017\u6280\u672f\u9700\u8981\u4fb5\u5165\u6027\u8bbe\u8ba1\u4fee\u6539\u6216\u968f\u7740\u5668\u4ef6\u5bc6\u5ea6\u589e\u52a0\u800c\u6536\u76ca\u9012\u51cf\u3002", "method": "\u5229\u7528\u4eff\u771f\u5206\u6790\u8bc6\u522b\u9ad8\u5207\u6362\u8def\u5f84\uff0c\u901a\u8fc7Shannon\u5206\u89e3\u539f\u7406\u63d2\u5165\u91cd\u590d\u771f\u503c\u8868\u903b\u8f91\u5e76\u91cd\u65b0\u5b9a\u4f4d\u5173\u952e\u7f51\u7edc\uff0c\u5728\u4e0d\u6539\u53d8\u529f\u80fd\u884c\u4e3a\u7684\u60c5\u51b5\u4e0b\u51cf\u5c11\u4e0d\u5fc5\u8981\u7684\u8f6c\u6362\u3002", "result": "\u5728\u5f00\u6e90RTLLM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5e73\u5747\u5b9e\u73b0\u7ea69%\u7684\u5207\u6362\u8bf1\u5bfc\u529f\u8017\u964d\u4f4e\uff0c\u7b97\u672f\u8bbe\u8ba1\u4ec5\u589e\u52a0\u7ea69%\u7684LUT\u7b49\u6548\u8d44\u6e90\u3002", "conclusion": "\u5c06\u4eff\u771f\u6d1e\u5bdf\u4e0e\u9488\u5bf9\u6027\u4f18\u5316\u76f8\u7ed3\u5408\u53ef\u4ee5\u6709\u6548\u964d\u4f4e\u52a8\u6001\u529f\u8017\uff0c\u4e3a\u5728FPGA-CAD\u6d41\u7a0b\u4e2d\u4f7f\u7528\u4eff\u771f\u5143\u6570\u636e\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2510.22087", "categories": ["cs.AR", "cs.AI", "cs.LG", "cs.SE"], "pdf": "https://arxiv.org/pdf/2510.22087", "abs": "https://arxiv.org/abs/2510.22087", "authors": ["Shvetank Prakash", "Andrew Cheng", "Arya Tschand", "Mark Mazumder", "Varun Gohil", "Jeffrey Ma", "Jason Yik", "Zishen Wan", "Jessica Quaye", "Elisavet Lydia Alvanaki", "Avinash Kumar", "Chandrashis Mazumdar", "Tuhin Khare", "Alexander Ingare", "Ikechukwu Uchendu", "Radhika Ghosal", "Abhishek Tyagi", "Chenyu Wang", "Andrea Mattia Garavagno", "Sarah Gu", "Alice Guo", "Grace Hur", "Luca Carloni", "Tushar Krishna", "Ankita Nayak", "Amir Yazdanbakhsh", "Vijay Janapa Reddi"], "title": "QuArch: A Benchmark for Evaluating LLM Reasoning in Computer Architecture", "comment": null, "summary": "The field of computer architecture, which bridges high-level software\nabstractions and low-level hardware implementations, remains absent from\ncurrent large language model (LLM) evaluations. To this end, we present QuArch\n(pronounced 'quark'), the first benchmark designed to facilitate the\ndevelopment and evaluation of LLM knowledge and reasoning capabilities\nspecifically in computer architecture. QuArch provides a comprehensive\ncollection of 2,671 expert-validated question-answer (QA) pairs covering\nvarious aspects of computer architecture, including processor design, memory\nsystems, and interconnection networks. Our evaluation reveals that while\nfrontier models possess domain-specific knowledge, they struggle with skills\nthat require higher-order thinking in computer architecture. Frontier model\naccuracies vary widely (from 34% to 72%) on these advanced questions,\nhighlighting persistent gaps in architectural reasoning across analysis,\ndesign, and implementation QAs. By holistically assessing fundamental skills,\nQuArch provides a foundation for building and measuring LLM capabilities that\ncan accelerate innovation in computing systems. With over 140 contributors from\n40 institutions, this benchmark represents a community effort to set the\nstandard for architectural reasoning in LLM evaluation.", "AI": {"tldr": "QuArch\u662f\u9996\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u67b6\u6784\u9886\u57df\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b2,671\u4e2a\u4e13\u5bb6\u9a8c\u8bc1\u7684\u95ee\u9898-\u7b54\u6848\u5bf9\uff0c\u8986\u76d6\u5904\u7406\u5668\u8bbe\u8ba1\u3001\u5185\u5b58\u7cfb\u7edf\u7b49\u6838\u5fc3\u4e3b\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u8bc4\u4f30\u7f3a\u4e4f\u8ba1\u7b97\u673a\u67b6\u6784\u9886\u57df\u7684\u4e13\u95e8\u6d4b\u8bd5\uff0c\u8be5\u9886\u57df\u8fde\u63a5\u9ad8\u7ea7\u8f6f\u4ef6\u62bd\u8c61\u548c\u4f4e\u7ea7\u786c\u4ef6\u5b9e\u73b0\uff0c\u5bf9\u8ba1\u7b97\u7cfb\u7edf\u521b\u65b0\u81f3\u5173\u91cd\u8981\u3002", "method": "\u5f00\u53d1\u5305\u542b2,671\u4e2a\u4e13\u5bb6\u9a8c\u8bc1QA\u5bf9\u7684\u7efc\u5408\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8986\u76d6\u8ba1\u7b97\u673a\u67b6\u6784\u7684\u591a\u4e2a\u65b9\u9762\uff0c\u5305\u62ec\u5904\u7406\u5668\u8bbe\u8ba1\u3001\u5185\u5b58\u7cfb\u7edf\u548c\u4e92\u8fde\u7f51\u7edc\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5728\u9886\u57df\u77e5\u8bc6\u65b9\u9762\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u9700\u8981\u9ad8\u9636\u601d\u7ef4\u7684\u95ee\u9898\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u51c6\u786e\u7387\u4ece34%\u523072%\u4e0d\u7b49\uff0c\u663e\u793a\u51fa\u5728\u67b6\u6784\u63a8\u7406\u65b9\u9762\u7684\u6301\u7eed\u5dee\u8ddd\u3002", "conclusion": "QuArch\u4e3a\u6784\u5efa\u548c\u8861\u91cfLLM\u5728\u8ba1\u7b97\u673a\u67b6\u6784\u9886\u57df\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u52a0\u901f\u8ba1\u7b97\u7cfb\u7edf\u521b\u65b0\uff0c\u4ee3\u8868\u4e86\u793e\u533a\u5728\u8bbe\u5b9aLLM\u67b6\u6784\u63a8\u7406\u8bc4\u4f30\u6807\u51c6\u65b9\u9762\u7684\u52aa\u529b\u3002"}}
{"id": "2510.22627", "categories": ["cs.AR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.22627", "abs": "https://arxiv.org/abs/2510.22627", "authors": ["Mohd Faisal Khan", "Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "RAMAN: Resource-efficient ApproxiMate Posit Processing for Algorithm-Hardware Co-desigN", "comment": "39th International Conference on VLSI Design and 25th International\n  Conference on Embedded Systems (VLSI-D), Pune, India", "summary": "Edge-AI applications still face considerable challenges in enhancing\ncomputational efficiency in resource-constrained environments. This work\npresents RAMAN, a resource-efficient and approximate posit(8,2)-based\nMultiply-Accumulate (MAC) architecture designed to improve hardware efficiency\nwithin bandwidth limitations. The proposed REAP (Resource-Efficient Approximate\nPosit) MAC engine, which is at the core of RAMAN, uses approximation in the\nposit multiplier to achieve significant area and power reductions with an\nimpact on accuracy. To support diverse AI workloads, this MAC unit is\nincorporated in a scalable Vector Execution Unit (VEU), which permits hardware\nreuse and parallelism among deep neural network layers. Furthermore, we propose\nan algorithm-hardware co-design framework incorporating approximation-aware\ntraining to evaluate the impact of hardware-level approximation on\napplication-level performance. Empirical validation on FPGA and ASIC platforms\nshows that the proposed REAP MAC achieves up to 46% in LUT savings and 35.66%\narea, 31.28% power reduction, respectively, over the baseline Posit Dot-Product\nUnit (PDPU) design, while maintaining high accuracy (98.45%) for handwritten\ndigit recognition. RAMAN demonstrates a promising trade-off between hardware\nefficiency and learning performance, making it suitable for next-generation\nedge intelligence.", "AI": {"tldr": "RAMAN\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8fd1\u4f3cposit(8,2)\u7684MAC\u67b6\u6784\uff0c\u901a\u8fc7\u786c\u4ef6\u8fd1\u4f3c\u548c\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u8fb9\u7f18AI\u5e94\u7528\u4e2d\u5b9e\u73b0\u8d44\u6e90\u6548\u7387\u4e0e\u5b66\u4e60\u6027\u80fd\u7684\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u8fb9\u7f18AI\u5e94\u7528\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684\u8ba1\u7b97\u6548\u7387\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u5e26\u5bbd\u9650\u5236\u4e0b\u63d0\u5347\u786c\u4ef6\u6548\u7387\u3002", "method": "\u63d0\u51faREAP\u8fd1\u4f3cMAC\u5f15\u64ce\uff0c\u5728posit\u4e58\u6cd5\u5668\u4e2d\u91c7\u7528\u8fd1\u4f3c\u8ba1\u7b97\uff1b\u6784\u5efa\u53ef\u6269\u5c55\u7684\u5411\u91cf\u6267\u884c\u5355\u5143(VEU)\u652f\u6301AI\u5de5\u4f5c\u8d1f\u8f7d\uff1b\u91c7\u7528\u8fd1\u4f3c\u611f\u77e5\u8bad\u7ec3\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6846\u67b6\u3002", "result": "\u5728FPGA\u548cASIC\u5e73\u53f0\u4e0a\u9a8c\u8bc1\uff0cREAP MAC\u76f8\u6bd4\u57fa\u51c6\u8bbe\u8ba1\u8282\u770146% LUT\u300135.66%\u9762\u79ef\u548c31.28%\u529f\u8017\uff0c\u624b\u5199\u6570\u5b57\u8bc6\u522b\u51c6\u786e\u7387\u8fbe98.45%\u3002", "conclusion": "RAMAN\u5728\u786c\u4ef6\u6548\u7387\u548c\u5b66\u4e60\u6027\u80fd\u4e4b\u95f4\u5b9e\u73b0\u4e86\u6709\u524d\u666f\u7684\u6743\u8861\uff0c\u9002\u7528\u4e8e\u4e0b\u4e00\u4ee3\u8fb9\u7f18\u667a\u80fd\u5e94\u7528\u3002"}}
{"id": "2510.22674", "categories": ["cs.AR", "cs.IT", "eess.IV", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.22674", "abs": "https://arxiv.org/abs/2510.22674", "authors": ["L. Hemanth Krishna", "Srinivasu Bodapati", "Sreehari Veeramachaneni", "BhaskaraRao Jammu", "Noor Mahammad Sk"], "title": "Approximate Signed Multiplier with Sign-Focused Compressor for Edge Detection Applications", "comment": "15 pages", "summary": "This paper presents an approximate signed multiplier architecture that\nincorporates a sign-focused compressor, specifically designed for edge\ndetection applications in machine learning and signal processing. The\nmultiplier incorporates two types of sign-focused compressors: A + B + C + 1\nand A + B + C + D + 1. Both exact and approximate compressor designs are\nutilized, with a focus on efficiently handling constant value \"1\" and negative\npartial products, which frequently appear in the partial product matrices of\nsigned multipliers. To further enhance efficiency, the lower N - 1 columns of\nthe partial product matrix are truncated, followed by an error compensation\nmechanism. Experimental results show that the proposed 8-bit approximate\nmultiplier achieves a 29.21% reduction in power delay product (PDP) and a\n14.39% reduction in power compared to the best of existing multipliers. The\nproposed multiplier is integrated into a custom convolution layer and performs\nedge detection, demonstrating its practical utility in real-world applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8fb9\u7f18\u68c0\u6d4b\u7684\u8fd1\u4f3c\u6709\u7b26\u53f7\u4e58\u6cd5\u5668\u67b6\u6784\uff0c\u91c7\u7528\u7b26\u53f7\u805a\u7126\u538b\u7f29\u5668\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u529f\u8017\u548c\u5ef6\u8fdf\u3002", "motivation": "\u9488\u5bf9\u673a\u5668\u5b66\u4e60\u548c\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u8fb9\u7f18\u68c0\u6d4b\u5e94\u7528\uff0c\u9700\u8981\u9ad8\u6548\u5904\u7406\u6709\u7b26\u53f7\u4e58\u6cd5\u8fd0\u7b97\uff0c\u7279\u522b\u662f\u5904\u7406\u5e38\u6570\"1\"\u548c\u8d1f\u90e8\u5206\u79ef\u7684\u9891\u7e41\u51fa\u73b0\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u7b26\u53f7\u805a\u7126\u538b\u7f29\u5668(A+B+C+1\u548cA+B+C+D+1)\uff0c\u7ed3\u5408\u7cbe\u786e\u548c\u8fd1\u4f3c\u538b\u7f29\u5668\u8bbe\u8ba1\uff0c\u622a\u65ad\u90e8\u5206\u79ef\u77e9\u9635\u7684\u4e0bN-1\u5217\u5e76\u91c7\u7528\u8bef\u5dee\u8865\u507f\u673a\u5236\u3002", "result": "8\u4f4d\u8fd1\u4f3c\u4e58\u6cd5\u5668\u76f8\u6bd4\u73b0\u6709\u6700\u4f73\u4e58\u6cd5\u5668\uff0c\u529f\u8017\u5ef6\u8fdf\u79ef(PDP)\u964d\u4f4e29.21%\uff0c\u529f\u8017\u964d\u4f4e14.39%\u3002", "conclusion": "\u8be5\u4e58\u6cd5\u5668\u6210\u529f\u96c6\u6210\u5230\u5377\u79ef\u5c42\u4e2d\u5b9e\u73b0\u8fb9\u7f18\u68c0\u6d4b\uff0c\u8bc1\u660e\u4e86\u5176\u5728\u73b0\u5b9e\u5e94\u7528\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002"}}
