<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 3]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [FIFOAdvisor: A DSE Framework for Automated FIFO Sizing of High-Level Synthesis Designs](https://arxiv.org/abs/2510.20981)
*Stefan Abi-Karam,Rishov Sarkar,Suhail Basalama,Jason Cong,Callie Hao*

Main category: cs.AR

TL;DR: FIFOAdvisor是一个自动确定HLS设计中FIFO大小的框架，通过高效的仿真和优化算法，在保证无死锁的同时最小化内存使用和延迟开销。


<details>
  <summary>Details</summary>
Motivation: 在数据流硬件设计中，正确确定FIFO通道缓冲区大小具有挑战性。过小的FIFO会导致停顿和死锁，过大的FIFO会浪费内存。现有方法存在限制性假设、保守过度分配或仿真速度慢的问题。

Method: 利用LightningSim（99.9%周期精确仿真器）进行毫秒级增量仿真，将FIFO大小确定建模为双目标黑盒优化问题，探索启发式和基于搜索的方法来表征延迟-资源权衡。

Result: 在Stream-HLS设计基准测试中，FIFOAdvisor实现了Pareto最优的延迟-内存前沿，相比基线设计显著降低内存使用且延迟开销最小，相比传统HLS/RTL协同仿真大幅提升运行速度。

Conclusion: FIFOAdvisor为快速设计空间探索提供了实用解决方案，能够有效优化具有数据依赖控制流的复杂加速器中的FIFO配置。

Abstract: Dataflow hardware designs enable efficient FPGA implementations via
high-level synthesis (HLS), but correctly sizing first-in-first-out (FIFO)
channel buffers remains challenging. FIFO sizes are user-defined and balance
latency and area-undersized FIFOs cause stalls and potential deadlocks, while
oversized ones waste memory. Determining optimal sizes is non-trivial: existing
methods rely on restrictive assumptions, conservative over-allocation, or slow
RTL simulations. We emphasize that runtime-based analyses (i.e., simulation)
are the only reliable way to ensure deadlock-free FIFO optimization for
data-dependent designs.
  We present FIFOAdvisor, a framework that automatically determines FIFO sizes
in HLS designs. It leverages LightningSim, a 99.9\% cycle-accurate simulator
supporting millisecond-scale incremental runs with new FIFO configurations.
FIFO sizing is formulated as a dual-objective black-box optimization problem,
and we explore heuristic and search-based methods to characterize the
latency-resource trade-off. FIFOAdvisor also integrates with Stream-HLS, a
framework for optimizing affine dataflow designs lowered from C++, MLIR, or
PyTorch, enabling deeper optimization of FIFOs in these workloads.
  We evaluate FIFOAdvisor on Stream-HLS design benchmarks spanning linear
algebra and deep learning workloads. Our results reveal Pareto-optimal
latency-memory frontiers across optimization strategies. Compared to baseline
designs, FIFOAdvisor achieves much lower memory usage with minimal delay
overhead. Additionally, it delivers significant runtime speedups over
traditional HLS/RTL co-simulation, making it practical for rapid design space
exploration. We further demonstrate its capability on a complex accelerator
with data-dependent control flow.
  Code and results: https://github.com/sharc-lab/fifo-advisor

</details>


### [2] [Hardware-Efficient Accurate 4-bit Multiplier for Xilinx 7 Series FPGAs](https://arxiv.org/abs/2510.21533)
*Misaki Kida,Shimpei Sato*

Main category: cs.AR

TL;DR: 提出了一种硬件高效的4位乘法器设计，仅使用11个LUT和2个CARRY4块，相比之前的12-LUT设计减少1个LUT并缩短关键路径。


<details>
  <summary>Details</summary>
Motivation: 随着IoT和边缘推理的普及，需要在查找表(LUT)乘法器中同时优化面积和延迟，这些乘法器并行实现大量低比特位操作。

Method: 通过重新组织映射到LUT的逻辑函数，在AMD Xilinx 7系列FPGA上设计准确的4位乘法器。

Result: 电路实现了最小资源使用和2.750 ns的关键路径延迟。

Conclusion: 该设计在保持准确性的同时，实现了资源使用和延迟的双重优化。

Abstract: As IoT and edge inference proliferate,there is a growing need to
simultaneously optimize area and delay in lookup-table (LUT)-based multipliers
that implement large numbers of low-bitwidth operations in parallel. This paper
proposes a hardwareefficientaccurate 4-bit multiplier design for AMD Xilinx
7-series FPGAs using only 11 LUTs and two CARRY4 blocks. By reorganizing the
logic functions mapped to the LUTs, the proposed method reduces the LUT count
by one compared with the prior 12-LUT design while also shortening the critical
path. Evaluation confirms that the circuit attains minimal resource usage and a
critical-path delay of 2.750 ns.

</details>


### [3] [Accelerating Electrostatics-based Global Placement with Enhanced FFT Computation](https://arxiv.org/abs/2510.21547)
*Hangyu Zhang,Sachin S. Sapatnekar*

Main category: cs.AR

TL;DR: 使用AccFFT加速FFT技术进行电场计算，显著降低了全局布局算法的运行时间，在ePlace-MS和Pplace-MS算法中实现了5.78倍FFT计算加速和32%总运行时间改进。


<details>
  <summary>Details</summary>
Motivation: 现代复杂VLSI设计需要高质量和高效的电路布局，静电分析布局方法虽然改进了可扩展性和解决方案质量，但计算效率仍有提升空间。

Method: 采用加速FFT技术(AccFFT)进行电场计算，并将其集成到ePlace-MS和Pplace-MS布局算法中。

Result: 在标准基准测试中，FFT计算速度提升5.78倍，总运行时间改进32%，详细布局后缩放半周长线长仅减少1.0%。

Conclusion: AccFFT技术能显著提升静电分析布局算法的计算效率，为复杂VLSI设计提供更高效的全局布局解决方案。

Abstract: Global placement is essential for high-quality and efficient circuit
placement for complex modern VLSI designs. Recent advancements, such as
electrostatics-based analytic placement, have improved scalability and solution
quality. This work demonstrates that using an accelerated FFT technique,
AccFFT, for electric field computation significantly reduces runtime.
Experimental results on standard benchmarks show significant improvements when
incorporated into the ePlace-MS and Pplace-MS algorithms, e.g., a 5.78x speedup
in FFT computation and a 32% total runtime improvement against ePlace-MS, with
1.0% reduction of scaled half-perimeter wirelength after detailed placement.

</details>
