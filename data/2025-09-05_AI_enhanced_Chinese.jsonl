{"id": "2509.03846", "categories": ["cs.AR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.03846", "abs": "https://arxiv.org/abs/2509.03846", "authors": ["Md Rownak Hossain Chowdhury", "Mostafizur Rahman"], "title": "Hardware-Aware Data and Instruction Mapping for AI Tasks: Balancing Parallelism, I/O and Memory Tradeoffs", "comment": null, "summary": "We introduce a mapping framework for deep learning inference that takes\nadvantage of predictable neural network behavior to plan both computation and\ncommunication ahead of time. The framework generates a unified stream of\ninstructions and data, enabling the hardware to execute operations and route\ninformation on its own, without frequent involvement from the host and with\nminimal off-chip memory use. This naturally reduces reliance on I/O, off-chip\nmemory, and host control. By leveraging fine-grained message passing on a\nprogrammable, message-based compute architecture, the framework keeps data\nmovement local and coordinates computation across the array using techniques\nsuch as stationary-weight reuse, in-array multicasting, and staged reductions.\nApplied to VGG-19, the framework sustains high utilization (88 to 92 percent),\nwith over 97 percent of messages generated internally and nearly 89 percent of\ntime consumed on-chip transfers. Computation throughput scales beyond 1 TFLOP/s\non larger arrays, while traffic reductions from reuse and local aggregation\nreach up to 100 MB per layer. Overall, the results highlight the effectiveness\nof streaming-based computation and show how our mapper enables this execution\nstyle by tightly coordinating data and instruction flow across the hardware.", "AI": {"tldr": "\u901a\u8fc7\u9884\u5148\u89c4\u5212\u8ba1\u7b97\u548c\u901a\u4fe1\u7684\u6d41\u5f0f\u6267\u884c\u6846\u67b6\uff0c\u5229\u7528\u6d88\u606f\u4f20\u9012\u673a\u5236\u51cf\u5c11I/O\u548c\u4e3b\u673a\u5e72\u9884\uff0c\u5b9e\u73b0\u9ad8\u5229\u7528\u7387\u548c\u9ad8\u901f\u8ba1\u7b97\u901f\u5ea6", "motivation": "\u89e3\u51b3\u6df1\u5ea6\u5b66\u4e60\u63a8\u7406\u4e2d\u5e38\u89c1\u7684I/O\u74f6\u9888\u3001\u4e3b\u673a\u5e72\u9884\u8fc7\u591a\u548c\u79bb\u82af\u5185\u5b58\u5360\u7528\u9ad8\u7684\u95ee\u9898", "method": "\u5f00\u53d1\u7edf\u4e00\u7684\u6307\u4ee4\u548c\u6570\u636e\u6d41\u6846\u67b6\uff0c\u91c7\u7528\u7cbe\u7ec6\u6d88\u606f\u4f20\u9012\u3001\u9759\u6001\u6743\u91cd\u91cd\u7528\u3001\u6570\u7ec4\u5185\u591a\u64ad\u548c\u5206\u6bb5\u7f29\u51cf\u7b49\u6280\u672f", "result": "\u5728VGG-19\u4e0a\u5b9e\u73b088-92%\u5229\u7528\u7387\uff0c97%\u6d88\u606f\u5185\u90e8\u751f\u6210\uff0c89%\u65f6\u95f4\u82af\u5185\u4f20\u8f93\uff0c\u8ba1\u7b97\u901f\u5ea6\u8d851TFLOP/s\uff0c\u6570\u636e\u91cf\u51cf\u5c11100MB/\u5c42", "conclusion": "\u6d41\u5f0f\u8ba1\u7b97\u6a21\u5f0f\u9ad8\u6548\u53ef\u884c\uff0c\u901a\u8fc7\u7d27\u5bc6\u534f\u8c03\u6570\u636e\u548c\u6307\u4ee4\u6d41\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u6027\u80fd\u786c\u4ef6\u6267\u884c"}}
{"id": "2509.04153", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04153", "abs": "https://arxiv.org/abs/2509.04153", "authors": ["Safa Mohammed Sali", "Mahmoud Meribout", "Ashiyana Abdul Majeed"], "title": "Real Time FPGA Based CNNs for Detection, Classification, and Tracking in Autonomous Systems: State of the Art Designs and Optimizations", "comment": null, "summary": "This paper presents a comprehensive review of recent advances in deploying\nconvolutional neural networks (CNNs) for object detection, classification, and\ntracking on Field Programmable Gate Arrays (FPGAs). With the increasing demand\nfor real-time computer vision applications in domains such as autonomous\nvehicles, robotics, and surveillance, FPGAs have emerged as a powerful\nalternative to GPUs and ASICs due to their reconfigurability, low power\nconsumption, and deterministic latency. We critically examine state-of-the-art\nFPGA implementations of CNN-based vision tasks, covering algorithmic\ninnovations, hardware acceleration techniques, and the integration of\noptimization strategies like pruning, quantization, and sparsity-aware methods\nto maximize performance within hardware constraints. This survey also explores\nthe landscape of modern FPGA platforms, including classical LUT-DSP based\narchitectures, System-on-Chip (SoC) FPGAs, and Adaptive Compute Acceleration\nPlatforms (ACAPs), comparing their capabilities in handling deep learning\nworkloads. Furthermore, we review available software development tools such as\nVitis AI, FINN, and Intel FPGA AI Suite, which significantly streamline the\ndesign and deployment of AI models on FPGAs. The paper uniquely discusses\nhybrid architecture that combine GPUs and FPGAs for collaborative acceleration\nof AI inference, addressing challenges related to energy efficiency and\nthroughput. Additionally, we highlight hardware-software co-design practices,\ndataflow optimizations, and pipelined processing techniques essential for\nreal-time inference on resource-constrained devices. Through this survey,\nresearchers and engineers are equipped with insights to develop\nnext-generation, power-efficient, and high-performance vision systems optimized\nfor FPGA deployment in edge and embedded applications.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86FPGA\u4e0aCNN\u76ee\u6807\u68c0\u6d4b\u3001\u5206\u7c7b\u548c\u8ddf\u8e2a\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cd\u70b9\u5206\u6790\u4e86\u786c\u4ef6\u52a0\u901f\u6280\u672f\u3001\u4f18\u5316\u7b56\u7565\u548c\u5f00\u53d1\u5de5\u5177\uff0c\u4e3a\u8fb9\u7f18\u8ba1\u7b97\u63d0\u4f9b\u9ad8\u6548\u89c6\u89c9\u7cfb\u7edf\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u968f\u7740\u81ea\u52a8\u9a7e\u9a76\u3001\u673a\u5668\u4eba\u548c\u76d1\u63a7\u7b49\u5b9e\u65f6\u8ba1\u7b97\u673a\u89c6\u89c9\u5e94\u7528\u9700\u6c42\u7684\u589e\u957f\uff0cFPGA\u56e0\u5176\u53ef\u91cd\u6784\u6027\u3001\u4f4e\u529f\u8017\u548c\u786e\u5b9a\u6027\u5ef6\u8fdf\u800c\u6210\u4e3aGPU\u548cASIC\u7684\u6709\u529b\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6279\u5224\u6027\u5206\u6790\u6700\u5148\u8fdb\u7684FPGA\u5b9e\u73b0\uff0c\u6db5\u76d6\u7b97\u6cd5\u521b\u65b0\u3001\u786c\u4ef6\u52a0\u901f\u6280\u672f\uff0c\u4ee5\u53ca\u526a\u679d\u3001\u91cf\u5316\u548c\u7a00\u758f\u611f\u77e5\u7b49\u4f18\u5316\u7b56\u7565\uff0c\u540c\u65f6\u8003\u5bdf\u73b0\u4ee3FPGA\u5e73\u53f0\u548c\u8f6f\u4ef6\u5f00\u53d1\u5de5\u5177\u3002", "result": "\u63d0\u4f9b\u4e86\u5bf9FPGA\u90e8\u7f72CNN\u7684\u5168\u9762\u6280\u672f\u8bc4\u4f30\uff0c\u5305\u62ec\u6df7\u5408\u67b6\u6784\u3001\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u8df5\u3001\u6570\u636e\u6d41\u4f18\u5316\u548c\u6d41\u6c34\u7ebf\u5904\u7406\u6280\u672f\uff0c\u4e3a\u5b9e\u65f6\u63a8\u7406\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u5f00\u53d1\u4e0b\u4e00\u4ee3\u9ad8\u80fd\u6548\u3001\u9ad8\u6027\u80fd\u89c6\u89c9\u7cfb\u7edf\u7684\u5173\u952e\u89c1\u89e3\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8fb9\u7f18\u548c\u5d4c\u5165\u5f0f\u5e94\u7528\u4e2d\u7684FPGA\u90e8\u7f72\u3002"}}
{"id": "2509.04162", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04162", "abs": "https://arxiv.org/abs/2509.04162", "authors": ["Safa Mohammed Sali", "Mahmoud Meribout", "Ashiyana Abdul Majeed"], "title": "Real Time FPGA Based Transformers & VLMs for Vision Tasks: SOTA Designs and Optimizations", "comment": null, "summary": "Transformers and vision-language models (VLMs) have emerged as dominant\narchitectures in computer vision and multimodal AI, offering state-of-the-art\nperformance in tasks such as image classification, object detection, visual\nquestion answering, and caption generation. However, their high computational\ncomplexity, large memory footprints, and irregular data access patterns present\nsignificant challenges for deployment in latency- and power-constrained\nenvironments. Field-programmable gate arrays (FPGAs) provide an attractive\nhardware platform for such workloads due to their reconfigurability,\nfine-grained parallelism, and potential for energy-efficient acceleration. This\npaper presents a comprehensive review of design trade-offs, optimization\nstrategies, and implementation challenges for FPGA-based inference of\ntransformers and VLMs. We examine critical factors such as device-class\nselection, memory subsystem constraints, dataflow orchestration, quantization\nstrategies, sparsity exploitation, and toolchain choices, alongside\nmodality-specific issues unique to VLMs, including heterogeneous compute\nbalancing and cross-attention memory management. Additionally, we discuss\nemerging trends in hardware-algorithm co-design, highlighting innovations in\nattention mechanisms, compression, and modular overlays to improve efficiency\nand adaptability. Practical issues such as runtime flexibility, verification\noverhead, and the absence of standardized FPGA multimodal benchmarks are also\nconsidered. Finally, we outline future directions toward scalable, portable,\nand reconfigurable FPGA solutions that adapt to evolving model architectures\nwhile sustaining high utilization and predictable performance. This synthesis\noffers both a technical foundation and a forward-looking perspective to help\nbridge the gap between advanced multimodal AI models and efficient FPGA\ndeployment.", "AI": {"tldr": "\u672c\u6587\u5168\u9762\u7efc\u8ff0\u4e86\u57fa\u4e8eFPGA\u7684Transformer\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u7684\u8bbe\u8ba1\u6743\u8861\u3001\u4f18\u5316\u7b56\u7565\u548c\u5b9e\u73b0\u6311\u6218\uff0c\u5305\u62ec\u8bbe\u5907\u9009\u62e9\u3001\u5185\u5b58\u7ea6\u675f\u3001\u6570\u636e\u6d41\u7f16\u6392\u3001\u91cf\u5316\u7b56\u7565\u7b49\u5173\u952e\u6280\u672f\u95ee\u9898\uff0c\u5e76\u8ba8\u8bba\u4e86\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u7684\u65b0\u8d8b\u52bf\u3002", "motivation": "Transformer\u548c\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5728\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u591a\u6a21\u6001AI\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u5927\u5185\u5b58\u5360\u7528\u548c\u4e0d\u89c4\u5219\u6570\u636e\u8bbf\u95ee\u6a21\u5f0f\u5728\u5ef6\u8fdf\u548c\u529f\u8017\u53d7\u9650\u73af\u5883\u4e2d\u90e8\u7f72\u9762\u4e34\u91cd\u5927\u6311\u6218\uff0cFPGA\u56e0\u5176\u53ef\u91cd\u6784\u6027\u3001\u7ec6\u7c92\u5ea6\u5e76\u884c\u6027\u548c\u80fd\u6548\u4f18\u52bf\u6210\u4e3a\u7406\u60f3\u786c\u4ef6\u5e73\u53f0\u3002", "method": "\u901a\u8fc7\u7cfb\u7edf\u6027\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790FPGA\u63a8\u7406\u7684\u5173\u952e\u8bbe\u8ba1\u56e0\u7d20\uff1a\u8bbe\u5907\u7c7b\u522b\u9009\u62e9\u3001\u5185\u5b58\u5b50\u7cfb\u7edf\u7ea6\u675f\u3001\u6570\u636e\u6d41\u7f16\u6392\u3001\u91cf\u5316\u7b56\u7565\u3001\u7a00\u758f\u6027\u5229\u7528\u3001\u5de5\u5177\u94fe\u9009\u62e9\uff0c\u4ee5\u53caVLMs\u7279\u6709\u7684\u6a21\u6001\u7279\u5b9a\u95ee\u9898\uff08\u5f02\u6784\u8ba1\u7b97\u5e73\u8861\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5185\u5b58\u7ba1\u7406\uff09\u3002", "result": "\u63d0\u51fa\u4e86\u9488\u5bf9FPGA\u90e8\u7f72\u7684\u5168\u9762\u6280\u672f\u6846\u67b6\uff0c\u8bc6\u522b\u4e86\u5173\u952e\u6027\u80fd\u74f6\u9888\u548c\u4f18\u5316\u673a\u4f1a\uff0c\u603b\u7ed3\u4e86\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u4e2d\u7684\u521b\u65b0\u65b9\u6cd5\uff08\u6ce8\u610f\u529b\u673a\u5236\u6539\u8fdb\u3001\u538b\u7f29\u6280\u672f\u548c\u6a21\u5757\u5316\u8986\u76d6\uff09\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u8fd0\u884c\u7075\u6d3b\u6027\u3001\u9a8c\u8bc1\u5f00\u9500\u548c\u6807\u51c6\u5316\u57fa\u51c6\u7f3a\u5931\u7b49\u95ee\u9898\u3002", "conclusion": "FPGA\u4e3aTransformer\u548cVLMs\u63d0\u4f9b\u4e86\u9ad8\u6548\u90e8\u7f72\u7684\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u672a\u6765\u9700\u8981\u5411\u53ef\u6269\u5c55\u3001\u53ef\u79fb\u690d\u548c\u53ef\u91cd\u6784\u7684FPGA\u89e3\u51b3\u65b9\u6848\u53d1\u5c55\uff0c\u4ee5\u9002\u914d\u4e0d\u65ad\u6f14\u8fdb\u7684\u6a21\u578b\u67b6\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5229\u7528\u7387\u548c\u53ef\u9884\u6d4b\u6027\u80fd\uff0c\u5f25\u5408\u5148\u8fdb\u591a\u6a21\u6001AI\u6a21\u578b\u4e0e\u9ad8\u6548FPGA\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2509.04173", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2509.04173", "abs": "https://arxiv.org/abs/2509.04173", "authors": ["Safa Sali", "Anis Meribout", "Ashiyana Majeed", "Mahmoud Meribout", "Juan Pablo", "Varun Tiwari", "Asma Baobaid"], "title": "Real-time Object Detection and Associated Hardware Accelerators Targeting Autonomous Vehicles: A Review", "comment": null, "summary": "The efficiency of object detectors depends on factors like detection\naccuracy, processing time, and computational resources. Processing time is\ncrucial for real-time applications, particularly for autonomous vehicles (AVs),\nwhere instantaneous responses are vital for safety. This review paper provides\na concise yet comprehensive survey of real-time object detection (OD)\nalgorithms for autonomous cars delving into their hardware accelerators (HAs).\nNon-neural network-based algorithms, which use statistical image processing,\nhave been entirely substituted by AI algorithms, such as different models of\nconvolutional neural networks (CNNs). Their intrinsically parallel features led\nthem to be deployable into edge-based HAs of various types, where GPUs and, to\na lesser extent, ASIC (application-specific integrated circuit) remain the most\nwidely used. Throughputs of hundreds of frames/s (fps) could be reached;\nhowever, handling object detection for all the cameras available in a typical\nAV requires further hardware and algorithmic improvements. The intensive\ncompetition between AV providers has limited the disclosure of algorithms,\nfirmware, and even hardware platform details. This remains a hurdle for\nresearchers, as commercial systems provide valuable insights while academics\nundergo lengthy training and testing on restricted datasets and road scenarios.\nConsequently, many AV research papers may not be reflected in end products,\nbeing developed under limited conditions. This paper surveys state-of-the-art\nOD algorithms and aims to bridge the gap with technologies in commercial AVs.\nTo our knowledge, this aspect has not been addressed in earlier surveys. Hence,\nthe paper serves as a tangible reference for researchers designing future\ngenerations of vehicles, expected to be fully autonomous for comfort and\nsafety.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u53ca\u5176\u786c\u4ef6\u52a0\u901f\u5668\u7684\u53d1\u5c55\u73b0\u72b6\uff0c\u5206\u6790\u4e86AI\u7b97\u6cd5\u7279\u522b\u662fCNN\u5982\u4f55\u53d6\u4ee3\u4f20\u7edf\u65b9\u6cd5\uff0c\u5e76\u8ba8\u8bba\u4e86\u5546\u4e1aAV\u7cfb\u7edf\u4e0e\u5b66\u672f\u7814\u7a76\u4e4b\u95f4\u7684\u6280\u672f\u5dee\u8ddd\u3002", "motivation": "\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u9700\u8981\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u6765\u786e\u4fdd\u5b89\u5168\uff0c\u4f46\u5546\u4e1aAV\u7cfb\u7edf\u4e0e\u5b66\u672f\u7814\u7a76\u4e4b\u95f4\u5b58\u5728\u6280\u672f\u4fe1\u606f\u4e0d\u900f\u660e\u7684\u9e3f\u6c9f\uff0c\u9700\u8981\u5f25\u5408\u8fd9\u4e00\u5dee\u8ddd\u4e3a\u672a\u6765\u5168\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u8bbe\u8ba1\u63d0\u4f9b\u53c2\u8003\u3002", "method": "\u901a\u8fc7\u5168\u9762\u8c03\u67e5\u6700\u65b0\u7684\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\uff0c\u7279\u522b\u662f\u57fa\u4e8eCNN\u7684AI\u65b9\u6cd5\uff0c\u4ee5\u53caGPU\u548cASIC\u7b49\u786c\u4ef6\u52a0\u901f\u5668\u7684\u5e94\u7528\uff0c\u5206\u6790\u5176\u6027\u80fd\u8868\u73b0\u548c\u6280\u672f\u6311\u6218\u3002", "result": "AI\u7b97\u6cd5\u5df2\u5b8c\u5168\u53d6\u4ee3\u4f20\u7edf\u7edf\u8ba1\u56fe\u50cf\u5904\u7406\u65b9\u6cd5\uff0cCNN\u7684\u5e76\u884c\u7279\u6027\u4f7f\u5176\u80fd\u591f\u5728\u8fb9\u7f18\u786c\u4ef6\u4e0a\u90e8\u7f72\uff0c\u8fbe\u5230\u6570\u767efps\u7684\u5904\u7406\u901f\u5ea6\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u786c\u4ef6\u548c\u7b97\u6cd5\u6539\u8fdb\u6765\u5904\u7406\u591a\u6444\u50cf\u5934\u9700\u6c42\u3002", "conclusion": "\u5546\u4e1aAV\u7cfb\u7edf\u7684\u6280\u672f\u4fdd\u5bc6\u9650\u5236\u4e86\u7814\u7a76\u8fdb\u5c55\uff0c\u672c\u6587\u65e8\u5728\u5f25\u5408\u5b66\u672f\u7814\u7a76\u4e0e\u5546\u4e1a\u5e94\u7528\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u672a\u6765\u5168\u81ea\u52a8\u9a7e\u9a76\u8f66\u8f86\u7684\u8bbe\u8ba1\u63d0\u4f9b\u5b9e\u7528\u53c2\u8003\uff0c\u8fd9\u662f\u6b64\u524d\u7efc\u8ff0\u672a\u6d89\u53ca\u7684\u91cd\u8981\u65b9\u9762\u3002"}}
