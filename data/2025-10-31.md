<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 2]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [CHIPSIM: A Co-Simulation Framework for Deep Learning on Chiplet-Based Systems](https://arxiv.org/abs/2510.25958)
*Lukas Pfromm,Alish Kanani,Harsh Sharma,Janardhan Rao Doppa,Partha Pratim Pande,Umit Y. Ogras*

Main category: cs.AR

TL;DR: CHIPSIM是一个用于小芯片系统上并行DNN执行的协同仿真框架，能准确建模计算和通信，显著提升仿真精度并支持功率/热分析。


<details>
  <summary>Details</summary>
Motivation: 传统单片芯片因制造良率问题无法满足数据密集型应用需求，小芯片架构提供了可扩展解决方案，但现有仿真方法缺乏准确性、速度和灵活性。

Method: 开发CHIPSIM协同仿真框架，同时建模计算和通信，准确捕捉网络争用和流水线效应，并以微秒级粒度分析小芯片和互连网络的功耗。

Result: 在均匀/非均匀小芯片和不同互连网络架构上的广泛评估显示，该框架具有多功能性，精度提升高达340%，并具备功率/热分析能力。

Conclusion: CHIPSIM为小芯片系统提供了快速准确的仿真解决方案，能够有效支持并行DNN执行的性能评估和热管理。

Abstract: Due to reduced manufacturing yields, traditional monolithic chips cannot keep
up with the compute, memory, and communication demands of data-intensive
applications, such as rapidly growing deep neural network (DNN) models.
Chiplet-based architectures offer a cost-effective and scalable solution by
integrating smaller chiplets via a network-on-interposer (NoI). Fast and
accurate simulation approaches are critical to unlocking this potential, but
existing methods lack the required accuracy, speed, and flexibility. To address
this need, this work presents CHIPSIM, a comprehensive co-simulation framework
designed for parallel DNN execution on chiplet-based systems. CHIPSIM
concurrently models computation and communication, accurately capturing network
contention and pipelining effects that conventional simulators overlook.
Furthermore, it profiles the chiplet and NoI power consumptions at microsecond
granularity for precise transient thermal analysis. Extensive evaluations with
homogeneous/heterogeneous chiplets and different NoI architectures demonstrate
the framework's versatility, up to 340% accuracy improvement, and power/thermal
analysis capability.

</details>


### [2] [MIREDO: MIP-Driven Resource-Efficient Dataflow Optimization for Computing-in-Memory Accelerator](https://arxiv.org/abs/2510.26463)
*Xiaolin He,Cenlin Duan,Yingjie Qi,Xiao Ma,Jianlei Yang*

Main category: cs.AR

TL;DR: MIREDO框架通过将存内计算架构的数据流优化建模为混合整数规划问题，显著提升了深度神经网络在CIM加速器上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 存内计算架构虽然能缓解数据移动瓶颈，但由于设计空间庞大和架构约束严格，现有优化方法难以充分利用CIM加速器的潜力，导致理论效率与实际系统效率之间存在明显差距。

Method: 提出MIREDO框架，采用分层硬件抽象和解析延迟模型来准确反映CIM系统中的复杂数据传输行为，将数据流优化建模为混合整数规划问题，联合建模工作负载特性、数据流策略和CIM特定约束。

Result: 评估结果显示MIREDO显著提升了性能，在各种DNN模型和硬件设置下实现了最高3.2倍的性能改进。

Conclusion: MIREDO通过系统化的数据流优化方法，有效解决了CIM架构中的数据流优化挑战，显著提升了系统级效率。

Abstract: Computing-in-Memory (CIM) architectures have emerged as a promising solution
for accelerating Deep Neural Networks (DNNs) by mitigating data movement
bottlenecks. However, realizing the potential of CIM requires specialized
dataflow optimizations, which are challenged by an expansive design space and
strict architectural constraints. Existing optimization approaches often fail
to fully exploit CIM accelerators, leading to noticeable gaps between
theoretical and actual system-level efficiency. To address these limitations,
we propose the MIREDO framework, which formulates dataflow optimization as a
Mixed-Integer Programming (MIP) problem. MIREDO introduces a hierarchical
hardware abstraction coupled with an analytical latency model designed to
accurately reflect the complex data transfer behaviors within CIM systems. By
jointly modeling workload characteristics, dataflow strategies, and
CIM-specific constraints, MIREDO systematically navigates the vast design space
to determine the optimal dataflow configurations. Evaluation results
demonstrate that MIREDO significantly enhances performance, achieving up to
$3.2\times$ improvement across various DNN models and hardware setups.

</details>
