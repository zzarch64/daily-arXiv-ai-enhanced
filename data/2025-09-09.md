<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 6]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Characterizing and Optimizing Realistic Workloads on a Commercial Compute-in-SRAM Device](https://arxiv.org/abs/2509.05451)
*Niansong Zhang,Wenbo Zhu,Courtney Golden,Dan Ilan,Hongzheng Chen,Christopher Batten,Zhiru Zhang*

Main category: cs.AR

TL;DR: 计算在SRAM中的商业设备GSI APU在实际工作负荷下的性能和能消表现，通过优化在RAG应用中实现了比CPU更快4.8-6.6倍的检索速度，且比GPU更节能54.4-117.9倍


<details>
  <summary>Details</summary>
Motivation: 之前对计算在SRAM架构的评估主要依赖仿真器或小型原型，限制了对其真实潜力的理解，需要通过商业设备进行实际性能评估

Method: 使用商业计算在SRAM设备GSI APU，与CPU和GPU进行性能对比；提出分析框架模型性能交换；提出三种优化技术：通信感知的缩减映射、合并DMA和广播友好数据布局

Result: 在10GB-200GB大规模数据集上，优化后的计算在SRAM系统检索速度比优化CPU基准提高4.8-6.6倍，结果生成延迟提高1.1-1.8倍，性能与NVIDIA A6000 GPU相当但能效提高54.4-117.9倍

Conclusion: 计算在SRAM技术在复杂实际应用中具有可行性，通过优化数据管理可充分发挥其细粒度并行优势，为该技术的进一步发展提供了指导

Abstract: Compute-in-SRAM architectures offer a promising approach to achieving higher
performance and energy efficiency across a range of data-intensive
applications. However, prior evaluations have largely relied on simulators or
small prototypes, limiting the understanding of their real-world potential. In
this work, we present a comprehensive performance and energy characterization
of a commercial compute-in-SRAM device, the GSI APU, under realistic workloads.
We compare the GSI APU against established architectures, including CPUs and
GPUs, to quantify its energy efficiency and performance potential. We introduce
an analytical framework for general-purpose compute-in-SRAM devices that
reveals fundamental optimization principles by modeling performance trade-offs,
thereby guiding program optimizations.
  Exploiting the fine-grained parallelism of tightly integrated memory-compute
architectures requires careful data management. We address this by proposing
three optimizations: communication-aware reduction mapping, coalesced DMA, and
broadcast-friendly data layouts. When applied to retrieval-augmented generation
(RAG) over large corpora (10GB--200GB), these optimizations enable our
compute-in-SRAM system to accelerate retrieval by 4.8$\times$--6.6$\times$ over
an optimized CPU baseline, improving end-to-end RAG latency by
1.1$\times$--1.8$\times$. The shared off-chip memory bandwidth is modeled using
a simulated HBM, while all other components are measured on the real
compute-in-SRAM device. Critically, this system matches the performance of an
NVIDIA A6000 GPU for RAG while being significantly more energy-efficient
(54.4$\times$-117.9$\times$ reduction). These findings validate the viability
of compute-in-SRAM for complex, real-world applications and provide guidance
for advancing the technology.

</details>


### [2] [High Utilization Energy-Aware Real-Time Inference Deep Convolutional Neural Network Accelerator](https://arxiv.org/abs/2509.05688)
*Kuan-Ting Lin,Ching-Te Chiu,Jheng-Yi Chang,Shi-Zong Huang,Yu-Ting Li*

Main category: cs.AR

TL;DR: 这篇论文提出了一种高利用率的能消敏计算的深度卷积神经网络加速器，通过数据重用策略和芯片内计算优化，大幅减少数据传输和提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度卷积神经网络在边缘设备上的推理计算复杂度和数据访问量过大，导致延迟过高，无法满足实际应用的实时性要求。

Method: 采用1x1卷积核作为计算单元，设计适合的计算单元；使用重用特征SRAM存储当前层输出作为下一层输入；导入输出重用策略和环形流数据流减少芯片与DRAM的数据交换；使用芯片内直接完成Pooling层计算的模块。

Result: 实现的加速芯片具有极高的硬件利用率，在ECNN模块上减少533倍的数据访问量，能够实时执行VGG16和MobileNet模型，与VWA设计相比速度提升7.52倍，能效提升1.92倍。

Conclusion: 该加速器设计通过数据重用策略和芯片内计算优化，有效解决了边缘设备上深度卷积神经网络推理的性能瓶颈，实现了高效能的实时执行。

Abstract: Deep convolution Neural Network (DCNN) has been widely used in computer
vision tasks. However, for edge devices even inference has too large
computational complexity and data access amount. The inference latency of
state-of-the-art models are impractical for real-world applications. In this
paper, we propose a high utilization energy-aware real-time inference deep
convolutional neural network accelerator, which improves the performance of the
current accelerators. First, we use the 1x1 size convolution kernel as the
smallest unit of the computing unit. Then we design suitable computing unit
based on the requirements of each model. Secondly, we use Reuse Feature SRAM to
store the output of the current layer in the chip and use the value as the
input of the next layer. Moreover, we import Output Reuse Strategy and Ring
Stream Dataflow to reduce the amount of data exchange between chips and DRAM.
Finally, we present On-fly Pooling Module to let the calculation of the Pooling
layer directly complete in the chip. With the aid of the proposed method, the
implemented acceleration chip has an extremely high hardware utilization rate.
We reduce a generous amount of data transfer on the specific module, ECNN.
Compared to the methods without reuse strategy, we can reduce 533 times of data
access amount. At the same time, we have enough computing power to perform
real-time execution of the existing image classification model, VGG16 and
MobileNet. Compared with the design in VWA, we can speed up 7.52 times and have
1.92x energy efficiency

</details>


### [3] [Hardware Acceleration of Kolmogorov-Arnold Network (KAN) in Large-Scale Systems](https://arxiv.org/abs/2509.05937)
*Wei-Hsing Huang,Jianwei Jia,Yuyao Kong,Faaiq Waqar,Tai-Hao Wen,Meng-Fan Chang,Shimeng Yu*

Main category: cs.AR

TL;DR: 本文提出了一种KAN网络的算法-硬件协同设计方法，通过量化、稀疏映射和模拟存内计算等技术，在保持精度的同时显著降低了硬件开销。


<details>
  <summary>Details</summary>
Motivation: Kolmogorov-Arnold Networks (KAN) 虽然参数效率高，但其B样条函数组件在硬件加速方面存在复杂性，需要专门的电路实现，这促使了算法-硬件协同设计的研究。

Method: 采用Alignment-Symmetry和PowerGap量化技术、KAN稀疏映射策略，以及基于模拟存内计算(ACIM)电路的N:1时间调制动态电压输入生成器。

Result: 在TSMC 22nm RRAM-ACIM原型芯片上验证，大规模KAN网络参数增加500K-807K倍时，面积开销仅增加28K-41K倍，功耗增加51-94倍，精度损失仅0.11%-0.23%。

Conclusion: 所提出的协同设计方法展示了KAN架构的良好扩展潜力，在保持高精度的同时实现了显著的硬件效率提升。

Abstract: Recent developments have introduced Kolmogorov-Arnold Networks (KAN), an
innovative architectural paradigm capable of replicating conventional deep
neural network (DNN) capabilities while utilizing significantly reduced
parameter counts through the employment of parameterized B-spline functions
with trainable coefficients. Nevertheless, the B-spline functional components
inherent to KAN architectures introduce distinct hardware acceleration
complexities. While B-spline function evaluation can be accomplished through
look-up table (LUT) implementations that directly encode functional mappings,
thus minimizing computational overhead, such approaches continue to demand
considerable circuit infrastructure, including LUTs, multiplexers, decoders,
and related components. This work presents an algorithm-hardware co-design
approach for KAN acceleration. At the algorithmic level, techniques include
Alignment-Symmetry and PowerGap KAN hardware aware quantization, KAN sparsity
aware mapping strategy, and circuit-level techniques include N:1 Time
Modulation Dynamic Voltage input generator with analog-compute-in-memory (ACIM)
circuits. This work conducts evaluations on large-scale KAN networks to
validate the proposed methodologies. Non-ideality factors, including partial
sum deviations from process variations, have been evaluated with statistics
measured from the TSMC 22nm RRAM-ACIM prototype chips. Utilizing optimally
determined KAN hyperparameters in conjunction with circuit optimizations
fabricated at the 22nm technology node, despite the parameter count for
large-scale tasks in this work increasing by 500Kx to 807Kx compared to
tiny-scale tasks in previous work, the area overhead increases by only 28Kx to
41Kx, with power consumption rising by merely 51x to 94x, while accuracy
degradation remains minimal at 0.11% to 0.23%, demonstrating the scaling
potential of our proposed architecture.

</details>


### [4] [SCREME: A Scalable Framework for Resilient Memory Design](https://arxiv.org/abs/2509.06101)
*Fan Li,Mimi Xie,Yanan Guo,Huize Li,Xin Xin*

Main category: cs.AR

TL;DR: SCREME框架利用低成本、低性能的ECC芯片来提供更多内存空间用于容错设计，通过重新分配带宽和利用未充分利用的I/O资源来实现可扩展的内存可靠性解决方案。


<details>
  <summary>Details</summary>
Motivation: 内存技术的快速发展带来了性能提升，但也加剧了可靠性挑战。传统ECC方案假设分配额外内存空间用于奇偶校验数据总是昂贵的，这种假设限制了可扩展性。

Method: 提出SCREME框架，利用ECC芯片不需要与常规数据芯片相同性能水平的特点：1）将原本为高性能ECC芯片提供的带宽用于容纳多个低成本芯片；2）利用服务器级内存芯片中未充分利用的I/O资源实现灵活的DIMM内部连接。

Result: 通过使用成本较低但速度较慢的芯片（技术演进过程中自然产生的），提供了额外的、经济高效的内存空间用于弹性内存设计。

Conclusion: SCREME提供了一个可扩展的内存框架，能够满足由技术演进驱动的日益增长的内存可靠性需求，打破了传统ECC方案的成本限制假设。

Abstract: The continuing advancement of memory technology has not only fueled a surge
in performance, but also substantially exacerbate reliability challenges.
Traditional solutions have primarily focused on improving the efficiency of
protection schemes, i.e., Error Correction Codes (ECC), under the assumption
that allocating additional memory space for parity data is always expensive and
therefore not a scalable solution.
  We break the stereotype by proposing an orthogonal approach that provides
additional, cost-effective memory space for resilient memory design. In
particular, we recognize that ECC chips (used for parity storage) do not
necessarily require the same performance level as regular data chips. This
offers two-fold benefits: First, the bandwidth originally provisioned for a
regular-performance ECC chip can instead be used to accommodate multiple
low-performance chips. Second, the cost of ECC chips can be effectively
reduced, as lower performance often correlates with lower expense. In addition,
we observe that server-class memory chips are often provisioned with ample, yet
underutilized I/O resources. This further offers the opportunity to repurpose
these resources to enable flexible on-DIMM interconnections. Based on the above
two insights, we finally propose SCREME, a scalable memory framework leverages
cost-effective, albeit slower, chips -- naturally produced during rapid
technology evolution -- to meet the growing reliability demands driven by this
evolution.

</details>


### [5] [Hardware Acceleration in Portable MRIs: State of the Art and Future Prospects](https://arxiv.org/abs/2509.06365)
*Omar Al Habsi,Safa Mohammed Sali,Anis Meribout,Mahmoud Meribout,Saif Almazrouei,Mohamed Seghier*

Main category: cs.AR

TL;DR: 这篇论文评论了硬件加速技术在可穿戰MRI系统中的应用，分析了GPU、FPGA、ASIC等技术在加速图像重建和降低功耗方面的优势，并提出了低场MRI联盟和标准化测试框架的建议。


<details>
  <summary>Details</summary>
Motivation: 可穿戰MRI系统在远程和资源受限环境中有重要作用，但图像重建和机器学习算法的计算复杂性构成了重大挑战。当前研究少有关注硬件加速在解决这些挑战中的作用。

Method: 通过综述最新可穿戰MRI技术发展，重点分析了GPU、FPGA、ASIC等硬件加速技术在加速图像获取和重建中的应用。还讨论了AI驱动的重建技术、开政低场pMRI数据集和边缘硬件解决方案。

Result: 硬件加速技术能够显著提高图像重建速度、降低功耗和增强系统可穿戰性。特别是GPU、FPGA和ASIC在性能和功耗方面表现优异。

Conclusion: 硬件加速技术对下一代可穿戰MRI技术发展至关重要，能够提升图像质量、降低功耗并增强系统可穿戰性。为促进AI在可穿戰MRI中的可复现应用，需要建立低场MRI联盟和标准化测试框架。

Abstract: There is a growing interest in portable MRI (pMRI) systems for point-of-care
imaging, particularly in remote or resource-constrained environments. However,
the computational complexity of pMRI, especially in image reconstruction and
machine learning (ML) algorithms for enhanced imaging, presents significant
challenges. Such challenges can be potentially addressed by harnessing hardware
application solutions, though there is little focus in the current pMRI
literature on hardware acceleration. This paper bridges that gap by reviewing
recent developments in pMRI, emphasizing the role and impact of hardware
acceleration to speed up image acquisition and reconstruction. Key technologies
such as Graphics Processing Units (GPUs), Field-Programmable Gate Arrays
(FPGAs), and Application-Specific Integrated Circuits (ASICs) offer excellent
performance in terms of reconstruction speed and power consumption. This review
also highlights the promise of AI-powered reconstruction, open low-field pMRI
datasets, and innovative edge-based hardware solutions for the future of pMRI
technology. Overall, hardware acceleration can enhance image quality, reduce
power consumption, and increase portability for next-generation pMRI
technology. To accelerate reproducible AI for portable MRI, we propose forming
a Low-Field MRI Consortium and an evidence ladder (analytic/phantom validation,
retrospective multi-center testing, prospective reader and non-inferiority
trials) to provide standardized datasets, benchmarks, and regulator-ready
testbeds.

</details>


### [6] [VCO-CARE: VCO-based Calibration-free Analog Readout for Electrodermal activity sensing](https://arxiv.org/abs/2509.06698)
*Leidy Mabel Alvero-Gonzalez,Matias Miguez,Eric Gutierrez,Juan Sapriza,Susana Patón,David Atienza,José Miranda*

Main category: cs.AR

TL;DR: 提出VCO-CARE系统，一种基于压控振荡器的模拟读出电路，用于连续EDA监测，具有高灵敏度(40pS)、低功耗(2.3μW)和低噪声(0.8μVrms)特性


<details>
  <summary>Details</summary>
Motivation: 解决可穿戴设备中EDA监测对高灵敏度、低功耗和最小校准需求的模拟前端系统的持续挑战

Method: 开发基于压控振荡器的模拟读出电路(VCO-CARE)，专为连续EDA传感设计

Result: 系统在0-20μS范围内达到40pS的平均灵敏度，固定电阻相对误差小于0.0025%，功耗仅2.3μW，噪声贡献仅0.8μVrms

Conclusion: 该研究推动可穿戴传感器向无缝适应不同用户、最小功耗和出色噪声抗扰性的方向发展

Abstract: Continuous monitoring of electrodermal activity (EDA) through wearable
devices has attracted much attention in recent times. However, the persistent
challenge demands analog front-end (AFE) systems with high sensitivity, low
power consumption, and minimal calibration requirements to ensure practical
usability in wearable technologies. In response to this challenge, this
research introduces VCO-CARE, a Voltage-Controlled Oscillator-based Analog
Readout tailored for continuous EDA sensing. The results show that our system
achieves an exceptional average sensitivity of up to 40 pS within a 0-20 uS
range and a negligible relative error of less than 0.0025% for
fixed-resistance. Furthermore, the proposed system consumes only an average of
2.3 uW based on post-layout validations and introduces a low noise
contribution, measuring only 0.8 uVrms across the 0-1.5 Hz EDA signal band.
This research aims to drive the evolution of wearable sensors characterized by
seamless adaptability to diverse users, minimal power consumption, and
outstanding noise resilience.

</details>
