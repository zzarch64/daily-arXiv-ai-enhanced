{"id": "2601.19213", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.19213", "abs": "https://arxiv.org/abs/2601.19213", "authors": ["Weiming Hu", "Zihan Zhang", "Haoyan Zhang", "Chen Zhang", "Cong Guo", "Yu Feng", "Tianchi Hu", "Guanglin Li", "Guipeng Hu", "Junsong Wang", "Jingwen Leng"], "title": "M$^{\\text{2}}$XFP: A Metadata-Augmented Microscaling Data Format for Efficient Low-bit Quantization", "comment": "17 pages, 13 figures, ASPLOS 2026", "summary": "Existing low-bit Microscaling (MX) formats, such as MXFP4, often suffer from substantial accuracy degradation due to the use of a shared scaling factor with the Power-of-Two format. In this work, we explore strategies that introduce minimal metadata to recover accuracy lost during quantization while maintaining high bit efficiency across a wide range of large language models. We propose a complete algorithm-hardware co-design based on flexible metadata, featuring an online quantization with simple encoding. To support the proposed method efficiently, we implement a lightweight hardware unit and integrate it into the accelerator. Evaluation results demonstrate that our method substantially narrows the accuracy gap, achieving on average a 70.63% reduction in accuracy loss compared to MXFP4 and a 37.30% reduction relative to the latest NVFP4 on LLM benchmarks. Furthermore, our design delivers up to 1.91$\\times$ speedup and 1.75$\\times$ energy savings over state-of-the-art accelerators. Our code is available at https://github.com/SJTU-ReArch-Group/M2XFP_ASPLOS26.", "AI": {"tldr": "\u63d0\u51faM2XFP\u65b9\u6cd5\uff0c\u901a\u8fc7\u7075\u6d3b\u7684\u5143\u6570\u636e\u548c\u5728\u7ebf\u91cf\u5316\u6765\u6539\u5584\u4f4e\u6bd4\u7279MX\u683c\u5f0f\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u5728\u4fdd\u6301\u9ad8\u6bd4\u7279\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u7f29\u5c0f\u7cbe\u5ea6\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u7684\u4f4e\u6bd4\u7279MX\u683c\u5f0f\uff08\u5982MXFP4\uff09\u7531\u4e8e\u4f7f\u7528\u5171\u4eab\u7f29\u653e\u56e0\u5b50\u7684Power-of-Two\u683c\u5f0f\uff0c\u5bfc\u81f4\u663e\u8457\u7684\u7cbe\u5ea6\u4e0b\u964d\u3002\u9700\u8981\u5728\u4fdd\u6301\u9ad8\u6bd4\u7279\u6548\u7387\u7684\u540c\u65f6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u5143\u6570\u636e\u6765\u6062\u590d\u91cf\u5316\u8fc7\u7a0b\u4e2d\u7684\u7cbe\u5ea6\u635f\u5931\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7075\u6d3b\u5143\u6570\u636e\u7684\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5305\u62ec\u5728\u7ebf\u91cf\u5316\u548c\u7b80\u5355\u7f16\u7801\u3002\u5b9e\u73b0\u8f7b\u91cf\u7ea7\u786c\u4ef6\u5355\u5143\u5e76\u96c6\u6210\u5230\u52a0\u901f\u5668\u4e2d\uff0c\u652f\u6301\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u3002", "result": "\u5728LLM\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4MXFP4\u5e73\u5747\u51cf\u5c1170.63%\u7684\u7cbe\u5ea6\u635f\u5931\uff0c\u76f8\u6bd4\u6700\u65b0\u7684NVFP4\u51cf\u5c1137.30%\u3002\u8bbe\u8ba1\u5b9e\u73b0\u6700\u9ad81.91\u500d\u52a0\u901f\u548c1.75\u500d\u80fd\u8017\u8282\u7701\u3002", "conclusion": "M2XFP\u65b9\u6cd5\u901a\u8fc7\u7075\u6d3b\u7684\u5143\u6570\u636e\u548c\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u9ad8\u6bd4\u7279\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u6539\u5584\u4e86\u4f4e\u6bd4\u7279MX\u683c\u5f0f\u7684\u7cbe\u5ea6\u95ee\u9898\uff0c\u4e3a\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19263", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2601.19263", "abs": "https://arxiv.org/abs/2601.19263", "authors": ["Aybars Yunusoglu", "Talha Coskun", "Hiruna Vishwamith", "Murat Isik", "I. Can Dikmen"], "title": "A Reconfigurable Framework for AI-FPGA Agent Integration and Acceleration", "comment": "Accepted at 27th International Symposium on Quality Electronic Design (ISQED'26)", "summary": "Artificial intelligence (AI) is increasingly deployed in real-time and energy-constrained environments, driving demand for hardware platforms that can deliver high performance and power efficiency. While central processing units (CPUs) and graphics processing units (GPUs) have traditionally served as the primary inference engines, their general-purpose nature often leads to inefficiencies under strict latency or power budgets. Field-Programmable Gate Arrays (FPGAs) offer a promising alternative by enabling custom-tailored parallelism and hardware-level optimizations. However, mapping AI workloads to FPGAs remains challenging due to the complexity of hardware-software co-design and data orchestration. This paper presents AI FPGA Agent, an agent-driven framework that simplifies the integration and acceleration of deep neural network inference on FPGAs. The proposed system employs a runtime software agent that dynamically partitions AI models, schedules compute-intensive layers for hardware offload, and manages data transfers with minimal developer intervention. The hardware component includes a parameterizable accelerator core optimized for high-throughput inference using quantized arithmetic. Experimental results demonstrate that the AI FPGA Agent achieves over 10x latency reduction compared to CPU baselines and 2-3x higher energy efficiency than GPU implementations, all while preserving classification accuracy within 0.2% of full-precision references. These findings underscore the potential of AI-FPGA co-design for scalable, energy-efficient AI deployment.", "AI": {"tldr": "AI FPGA Agent\u6846\u67b6\u901a\u8fc7\u8f6f\u4ef6\u4ee3\u7406\u52a8\u6001\u5206\u533aAI\u6a21\u578b\u3001\u8c03\u5ea6\u786c\u4ef6\u5378\u8f7d\uff0c\u7ed3\u5408\u53c2\u6570\u5316\u52a0\u901f\u5668\u6838\u5fc3\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0\u9ad8\u6548AI\u63a8\u7406\uff0c\u76f8\u6bd4CPU\u5ef6\u8fdf\u964d\u4f4e10\u500d\uff0c\u6bd4GPU\u80fd\u6548\u9ad82-3\u500d\u3002", "motivation": "AI\u5728\u5b9e\u65f6\u548c\u80fd\u8017\u53d7\u9650\u73af\u5883\u4e2d\u7684\u90e8\u7f72\u9700\u6c42\u65e5\u76ca\u589e\u957f\uff0c\u4f20\u7edfCPU/GPU\u5728\u4e25\u683c\u5ef6\u8fdf\u6216\u529f\u8017\u9884\u7b97\u4e0b\u6548\u7387\u4e0d\u8db3\u3002FPGA\u867d\u7136\u63d0\u4f9b\u5b9a\u5236\u5316\u5e76\u884c\u548c\u786c\u4ef6\u7ea7\u4f18\u5316\u6f5c\u529b\uff0c\u4f46AI\u5de5\u4f5c\u8d1f\u8f7d\u6620\u5c04\u5230FPGA\u4ecd\u9762\u4e34\u786c\u4ef6\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u548c\u6570\u636e\u7f16\u6392\u7684\u590d\u6742\u6027\u6311\u6218\u3002", "method": "\u63d0\u51faAI FPGA Agent\u6846\u67b6\uff1a1) \u8fd0\u884c\u65f6\u8f6f\u4ef6\u4ee3\u7406\u52a8\u6001\u5206\u533aAI\u6a21\u578b\uff0c\u8c03\u5ea6\u8ba1\u7b97\u5bc6\u96c6\u578b\u5c42\u8fdb\u884c\u786c\u4ef6\u5378\u8f7d\uff0c\u7ba1\u7406\u6570\u636e\u4f20\u8f93\uff1b2) \u786c\u4ef6\u7ec4\u4ef6\u5305\u62ec\u53c2\u6570\u5316\u52a0\u901f\u5668\u6838\u5fc3\uff0c\u4f7f\u7528\u91cf\u5316\u7b97\u672f\u4f18\u5316\u9ad8\u541e\u5410\u91cf\u63a8\u7406\u3002", "result": "\u76f8\u6bd4CPU\u57fa\u7ebf\u5ef6\u8fdf\u964d\u4f4e\u8d85\u8fc710\u500d\uff0c\u76f8\u6bd4GPU\u5b9e\u73b0\u80fd\u6548\u9ad82-3\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u5206\u7c7b\u7cbe\u5ea6\u5728\u5b8c\u6574\u7cbe\u5ea6\u53c2\u8003\u76840.2%\u8303\u56f4\u5185\u3002", "conclusion": "AI-FPGA\u534f\u540c\u8bbe\u8ba1\u5177\u6709\u53ef\u6269\u5c55\u3001\u9ad8\u80fd\u6548AI\u90e8\u7f72\u7684\u6f5c\u529b\uff0cAI FPGA Agent\u6846\u67b6\u7b80\u5316\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728FPGA\u4e0a\u7684\u96c6\u6210\u548c\u52a0\u901f\u3002"}}
{"id": "2601.19384", "categories": ["cs.AR", "q-bio.GN"], "pdf": "https://arxiv.org/pdf/2601.19384", "abs": "https://arxiv.org/abs/2601.19384", "authors": ["Julien Eudine", "Chu Li", "Zhuo Cheng", "Renzo Andri", "Can Firtina", "Mohammad Sadrosadati", "Nika Mansouri Ghiasi", "Konstantina Koliogeorgi", "Anirban Nag", "Arash Tavakkol", "Haiyu Mao", "Onur Mutlu", "Shai Bergman", "Ji Zhang"], "title": "GenPairX: A Hardware-Algorithm Co-Designed Accelerator for Paired-End Read Mapping", "comment": null, "summary": "Genome sequencing has become a central focus in computational biology. A genome study typically begins with sequencing, which produces millions to billions of short DNA fragments known as reads. Read mapping aligns these reads to a reference genome. Read mapping for short reads comes in two forms: single-end and paired-end, with the latter being more prevalent due to its higher accuracy and support for advanced analysis. Read mapping remains a major performance bottleneck in genome analysis due to expensive dynamic programming. Prior efforts have attempted to mitigate this cost by employing filters to identify and potentially discard computationally expensive matches and leveraging hardware accelerators to speed up the computations. While partially effective, these approaches have limitations. In particular, existing filters are often ineffective for paired-end reads, as they evaluate each read independently and exhibit relatively low filtering ratios. In this work, we propose GenPairX, a hardware-algorithm co-designed accelerator that efficiently minimizes the computational load of paired-end read mapping while enhancing the throughput of memory-intensive operations. GenPairX introduces: (1) a novel filtering algorithm that jointly considers both reads in a pair to improve filtering effectiveness, and a lightweight alignment algorithm to replace most of the computationally expensive dynamic programming operations, and (2) two specialized hardware mechanisms to support the proposed algorithms. Our evaluations show that GenPairX delivers substantial performance improvements over state-of-the-art solutions, achieving 1575x and 1.43x higher throughput per watt compared to leading CPU-based and accelerator-based read mappers, respectively, all without compromising accuracy.", "AI": {"tldr": "GenPairX\uff1a\u4e00\u79cd\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u7684\u52a0\u901f\u5668\uff0c\u901a\u8fc7\u8054\u5408\u8003\u8651\u914d\u5bf9\u672b\u7aef\u8bfb\u6bb5\u7684\u65b0\u8fc7\u6ee4\u7b97\u6cd5\u548c\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u7b97\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u914d\u5bf9\u672b\u7aef\u8bfb\u6bb5\u6620\u5c04\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6848\u5b9e\u73b01575\u500d\u548c1.43\u500d\u7684\u6bcf\u74e6\u541e\u5410\u91cf\u63d0\u5347\u3002", "motivation": "\u57fa\u56e0\u7ec4\u6d4b\u5e8f\u4e2d\u8bfb\u6bb5\u6620\u5c04\u662f\u4e3b\u8981\u6027\u80fd\u74f6\u9888\uff0c\u73b0\u6709\u8fc7\u6ee4\u7b97\u6cd5\u5bf9\u914d\u5bf9\u672b\u7aef\u8bfb\u6bb5\u6548\u679c\u6709\u9650\uff0c\u56e0\u4e3a\u5b83\u4eec\u72ec\u7acb\u8bc4\u4f30\u6bcf\u4e2a\u8bfb\u6bb5\u4e14\u8fc7\u6ee4\u7387\u8f83\u4f4e\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u6765\u51cf\u5c11\u8ba1\u7b97\u8d1f\u8f7d\u5e76\u63d0\u9ad8\u5185\u5b58\u5bc6\u96c6\u578b\u64cd\u4f5c\u7684\u541e\u5410\u91cf\u3002", "method": "\u63d0\u51faGenPairX\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u52a0\u901f\u5668\uff1a1\uff09\u65b0\u9896\u7684\u8fc7\u6ee4\u7b97\u6cd5\u8054\u5408\u8003\u8651\u914d\u5bf9\u4e2d\u7684\u4e24\u4e2a\u8bfb\u6bb5\u4ee5\u63d0\u9ad8\u8fc7\u6ee4\u6548\u679c\uff0c\u7528\u8f7b\u91cf\u7ea7\u5bf9\u9f50\u7b97\u6cd5\u66ff\u4ee3\u5927\u90e8\u5206\u8ba1\u7b97\u6602\u8d35\u7684\u52a8\u6001\u89c4\u5212\u64cd\u4f5c\uff1b2\uff09\u4e24\u79cd\u4e13\u7528\u786c\u4ef6\u673a\u5236\u652f\u6301\u6240\u63d0\u7b97\u6cd5\u3002", "result": "GenPairX\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u89e3\u51b3\u65b9\u6848\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\uff1a\u4e0e\u9886\u5148\u7684\u57fa\u4e8eCPU\u548c\u57fa\u4e8e\u52a0\u901f\u5668\u7684\u8bfb\u6bb5\u6620\u5c04\u5668\u76f8\u6bd4\uff0c\u5206\u522b\u5b9e\u73b01575\u500d\u548c1.43\u500d\u7684\u6bcf\u74e6\u541e\u5410\u91cf\u63d0\u5347\uff0c\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "conclusion": "GenPairX\u901a\u8fc7\u786c\u4ef6\u7b97\u6cd5\u534f\u540c\u8bbe\u8ba1\u6709\u6548\u89e3\u51b3\u4e86\u914d\u5bf9\u672b\u7aef\u8bfb\u6bb5\u6620\u5c04\u7684\u8ba1\u7b97\u74f6\u9888\uff0c\u5728\u4fdd\u6301\u51c6\u786e\u6027\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u6027\u80fd\u548c\u80fd\u6548\uff0c\u4e3a\u57fa\u56e0\u7ec4\u5206\u6790\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u52a0\u901f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.19747", "categories": ["cs.AR", "cs.AI", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.19747", "abs": "https://arxiv.org/abs/2601.19747", "authors": ["Jiale Liu", "Taiyu Zhou", "Tianqi Jiang"], "title": "Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation", "comment": null, "summary": "In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative debugging, and (iii) semantic drift as intent is reinterpreted across agent handoffs. In this work, we propose Veri-Sure, a multi-agent framework that establishes a design contract to align agents' intent and uses a patching mechanism guided by static dependency slicing to perform precise, localized repairs. By integrating a multi-branch verification pipeline that combines trace-driven temporal analysis with formal verification consisting of assertion-based checking and boolean equivalence proofs, Veri-Sure enables functional correctness beyond pure simulations. We also introduce VerilogEval-v2-EXT, extending the original benchmark with 53 more industrial-grade design tasks and stratified difficulty levels, and show that Veri-Sure achieves state-of-the-art verified-correct RTL code generation performance, surpassing standalone LLMs and prior agentic systems.", "AI": {"tldr": "Veri-Sure\u662f\u4e00\u4e2a\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff0c\u901a\u8fc7\u8bbe\u8ba1\u5951\u7ea6\u5bf9\u9f50\u667a\u80fd\u4f53\u610f\u56fe\uff0c\u4f7f\u7528\u9759\u6001\u4f9d\u8d56\u5207\u7247\u6307\u5bfc\u7684\u8865\u4e01\u673a\u5236\u8fdb\u884c\u7cbe\u786e\u4fee\u590d\uff0c\u7ed3\u5408\u591a\u5206\u652f\u9a8c\u8bc1\u7ba1\u9053\u786e\u4fddRTL\u4ee3\u7801\u751f\u6210\u7684\u529f\u80fd\u6b63\u786e\u6027\uff0c\u5728\u6269\u5c55\u7684VerilogEval-v2-EXT\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u5f53\u524dEDA\u9886\u57df\u4f7f\u7528LLM\u8fdb\u884cRTL\u8bbe\u8ba1\u9762\u4e34\u4e09\u4e2a\u4e3b\u8981\u74f6\u9888\uff1a1) \u57fa\u4e8e\u4eff\u771f\u7684\u8bc4\u4f30\u6d4b\u8bd5\u8986\u76d6\u7387\u548c\u53ef\u9760\u6027\u6709\u9650\uff1b2) \u8fed\u4ee3\u8c03\u8bd5\u5f15\u5165\u7684\u56de\u5f52\u548c\u4fee\u590d\u5e7b\u89c9\uff1b3) \u667a\u80fd\u4f53\u4ea4\u63a5\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u6f02\u79fb\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u7845\u7ea7\u6b63\u786e\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faVeri-Sure\u591a\u667a\u80fd\u4f53\u6846\u67b6\uff1a1) \u5efa\u7acb\u8bbe\u8ba1\u5951\u7ea6\u5bf9\u9f50\u667a\u80fd\u4f53\u610f\u56fe\uff1b2) \u4f7f\u7528\u9759\u6001\u4f9d\u8d56\u5207\u7247\u6307\u5bfc\u7684\u8865\u4e01\u673a\u5236\u8fdb\u884c\u7cbe\u786e\u5c40\u90e8\u4fee\u590d\uff1b3) \u96c6\u6210\u591a\u5206\u652f\u9a8c\u8bc1\u7ba1\u9053\uff0c\u7ed3\u5408\u8f68\u8ff9\u9a71\u52a8\u7684\u65f6\u5e8f\u5206\u6790\u548c\u5f62\u5f0f\u9a8c\u8bc1\uff08\u57fa\u4e8e\u65ad\u8a00\u7684\u68c0\u67e5\u548c\u5e03\u5c14\u7b49\u4ef7\u8bc1\u660e\uff09\u3002", "result": "\u6269\u5c55\u4e86VerilogEval-v2-EXT\u57fa\u51c6\uff0c\u589e\u52a053\u4e2a\u5de5\u4e1a\u7ea7\u8bbe\u8ba1\u4efb\u52a1\u548c\u5206\u5c42\u96be\u5ea6\u7ea7\u522b\u3002Veri-Sure\u5728\u9a8c\u8bc1\u6b63\u786e\u7684RTL\u4ee3\u7801\u751f\u6210\u65b9\u9762\u8d85\u8d8a\u4e86\u72ec\u7acbLLM\u548c\u5148\u524d\u7684\u667a\u80fd\u4f53\u7cfb\u7edf\uff0c\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "conclusion": "Veri-Sure\u901a\u8fc7\u8bbe\u8ba1\u5951\u7ea6\u3001\u7cbe\u786e\u8865\u4e01\u673a\u5236\u548c\u591a\u5206\u652f\u9a8c\u8bc1\u7ba1\u9053\u7684\u96c6\u6210\uff0c\u89e3\u51b3\u4e86RTL\u8bbe\u8ba1\u4e2d\u7684\u7845\u7ea7\u6b63\u786e\u6027\u74f6\u9888\uff0c\u4e3aLLM\u5728EDA\u9886\u57df\u7684\u53ef\u9760\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u6846\u67b6\u3002"}}
