<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 4]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [RulePlanner: All-in-One Reinforcement Learner for Unifying Design Rules in 3D Floorplanning](https://arxiv.org/abs/2601.22476)
*Ruizhe Zhong,Xingbo Du,Junchi Yan*

Main category: cs.AR

TL;DR: 提出基于深度强化学习的统一框架，用于处理3D芯片布局中的复杂设计规则，通过矩阵表示、动作空间约束和奖励信号实现自动化布局优化。


<details>
  <summary>Details</summary>
Motivation: 随着技术节点缩小，3D芯片布局面临复杂设计规则挑战，现有方法只能处理有限规则，其他规则违反需要专家手动调整，导致后处理工作量大且耗时。

Method: 1) 设计新颖的矩阵表示来建模设计规则；2) 在动作空间上施加约束以过滤导致规则违反的无效动作；3) 将约束满足度作为奖励信号进行量化分析。

Result: 在公开基准测试上验证了方法的有效性和正确性，同时在未见电路上展示了良好的可迁移性。

Conclusion: 框架可扩展以容纳新设计规则，为未来芯片设计中的新兴挑战提供了灵活性解决方案。

Abstract: Floorplanning determines the coordinate and shape of each module in Integrated Circuits. With the scaling of technology nodes, in floorplanning stage especially 3D scenarios with multiple stacked layers, it has become increasingly challenging to adhere to complex hardware design rules. Current methods are only capable of handling specific and limited design rules, while violations of other rules require manual and meticulous adjustment. This leads to labor-intensive and time-consuming post-processing for expert engineers. In this paper, we propose an all-in-one deep reinforcement learning-based approach to tackle these challenges, and design novel representations for real-world IC design rules that have not been addressed by previous approaches. Specifically, the processing of various hardware design rules is unified into a single framework with three key components: 1) novel matrix representations to model the design rules, 2) constraints on the action space to filter out invalid actions that cause rule violations, and 3) quantitative analysis of constraint satisfaction as reward signals. Experiments on public benchmarks demonstrate the effectiveness and validity of our approach. Furthermore, transferability is well demonstrated on unseen circuits. Our framework is extensible to accommodate new design rules, thus providing flexibility to address emerging challenges in future chip design. Code will be available at: https://github.com/Thinklab-SJTU/EDA-AI

</details>


### [2] [Design of a GPU with Heterogeneous Cores for Graphics](https://arxiv.org/abs/2601.22862)
*Aurora Tomás,Juan Luis Aragón,Joan Manuel Parcerisa,Antonio González*

Main category: cs.AR

TL;DR: KHEPRI提出了一种异构GPU架构，通过计算专用和内存专用两种核心来适应图形应用中不同区域的多样性需求，配合智能调度器实现性能提升和能耗降低。


<details>
  <summary>Details</summary>
Motivation: 图形应用中的场景具有多样性，不同区域的复杂度和计算需求差异显著。传统同构GPU无法有效适应这种变化，导致资源利用效率低下。异构架构在CPU领域已证明有效，但在GPU领域尚未充分探索。

Method: 1. 设计包含两种核心的异构GPU架构：高ILP优化的计算专用核心和容忍更多缓存未命中的内存专用核心
2. 开发智能工作调度器，动态将帧的不同区域（tile）分配给最合适的核心
3. 利用帧间一致性，基于前一帧对应tile的行为预测当前tile特性

Result: 相比传统同构GPU，KHEPRI实现平均性能提升9.2%，帧率提升7.3%，GPU总能耗降低4.8%，且无需额外硬件开销。

Conclusion: 异构GPU架构能有效适应图形应用的场景多样性，通过专用核心和智能调度实现显著的性能提升和能耗降低，证明了异构设计在GPU领域的可行性。

Abstract: Heterogeneous architectures can deliver higher performance and energy efficiency than symmetric counterparts by using multiple architectures tuned to different types of workloads. While previous works focused on CPUs, this work extends the concept of heterogeneity to GPUs by proposing KHEPRI, a heterogeneous GPU architecture for graphics applications. Scenes in graphics applications showcase diversity, as they consist of many objects with varying levels of complexity. As a result, computational intensity and memory bandwidth requirements differ significantly across different regions of each scene. To address this variability, our proposal includes two types of cores: cores optimized for high ILP (compute-specialized) and cores that tolerate a higher number of simultaneously outstanding cache misses (memory-specialized). A key component of the proposed architecture is a novel work scheduler that dynamically assigns each part of a frame (i.e., a tile) to the most suitable core. Designing this scheduler is particularly challenging, as it must preserve data locality; otherwise, the benefits of heterogeneity may be offset by the penalty of additional cache misses. Additionally, the scheduler requires knowledge of each tile's characteristics before rendering it. For this purpose, KHEPRI leverages frame-to-frame coherence to predict the behavior of each tile based on that of the corresponding tile in the previous frame. Evaluations across a wide range of commercial animated graphics applications show that, compared to a traditional homogeneous GPU, KHEPRI achieves an average performance improvement of 9.2%, a throughput increase (frames per second) of 7.3%, and a total GPU energy reduction of 4.8%. Importantly, these benefits are achieved without any hardware overhead.

</details>


### [3] [Machine Learning for Energy-Performance-aware Scheduling](https://arxiv.org/abs/2601.23134)
*Zheyuan Hu,Yifei Shi*

Main category: cs.AR

TL;DR: 提出基于高斯过程的贝叶斯优化框架，用于自动化搜索异构多核架构上的最优调度配置，平衡能耗与延迟，并通过敏感性分析提供模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 在后邓纳德时代，嵌入式系统优化需要在能耗效率和延迟之间进行复杂权衡。传统启发式调优在高维、非平滑的搜索空间中效率低下。

Method: 使用高斯过程的贝叶斯优化框架，近似能耗与时间的帕累托前沿，结合敏感性分析（fANOVA）比较不同协方差核函数（如Matérn与RBF），为黑盒模型提供物理可解释性。

Result: 框架能够自动化搜索异构多核架构的最优调度配置，揭示驱动系统性能的主导硬件参数，提供模型可解释性。

Conclusion: 提出的贝叶斯优化框架能有效处理嵌入式系统优化中的高维复杂权衡问题，通过敏感性分析增强模型可解释性，优于传统启发式方法。

Abstract: In the post-Dennard era, optimizing embedded systems requires navigating complex trade-offs between energy efficiency and latency. Traditional heuristic tuning is often inefficient in such high-dimensional, non-smooth landscapes. In this work, we propose a Bayesian Optimization framework using Gaussian Processes to automate the search for optimal scheduling configurations on heterogeneous multi-core architectures. We explicitly address the multi-objective nature of the problem by approximating the Pareto Frontier between energy and time. Furthermore, by incorporating Sensitivity Analysis (fANOVA) and comparing different covariance kernels (e.g., Matérn vs. RBF), we provide physical interpretability to the black-box model, revealing the dominant hardware parameters driving system performance.

</details>


### [4] [Toward Digital Twins in 3D IC Packaging: A Critical Review of Physics, Data, and Hybrid Architectures](https://arxiv.org/abs/2601.23226)
*Gourab Datta,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.AR

TL;DR: 本文对3D IC数字孪生技术进行批判性综述，澄清术语混淆，提出混合架构，并制定标准化路线图


<details>
  <summary>Details</summary>
Motivation: 3D IC封装和异构集成面临热斑、翘曲应力、互连老化等多物理场耦合问题，需要超越传统离线计量学的实时监控和控制能力。现有数字孪生文献分散且常混淆静态仿真与动态闭环孪生，需要澄清术语并提供统一架构

Method: 通过三个具体贡献：1) 澄清数字孪生层次结构，区分数字模型、数字阴影和数字孪生；2) 综合三大使能技术：基于物理的建模（从FEA转向实时代理模型）、数据驱动范式（虚拟计量学）、原位传感；3) 提出统一混合数字孪生架构，利用物理信息机器学习（如PINNs）解决数据稀缺与延迟约束

Result: 建立了清晰的数字孪生术语体系，提出了结合物理模型与数据驱动的混合架构，制定了基于IEEE 1451和UCIe协议的标准化路线图，为从被动数字阴影向自主优化数字孪生过渡提供指导

Conclusion: 本文通过澄清术语、综合使能技术和提出统一架构，为3D IC数字孪生技术提供了系统框架，标准化路线图将加速从被动监控向自主优化的数字孪生系统过渡，对3D IC制造和现场运维具有重要意义

Abstract: Three-dimensional integrated circuit (3D IC) pack-aging and heterogeneous integration have emerged as central pillars of contemporary semiconductor scaling. Yet, the multi-physics coupling inherent to stacked architectures manifesting as thermal hot spots, warpage-induced stresses, and interconnect aging demands monitoring and control capabilities that surpass traditional offline metrology. Although Digital Twin (DT) technology provides a principled route to real-time reliability management, the existing literature remains fragmented and frequently blurs the distinction between static multiphysics simulation workflows and truly dynamic, closed-loop twins. This critical review distinguishes itself by addressing these deficiencies through three specific contributions. First, we clarify the Digital Twin hierarchy to resolve terminological ambiguity between digital models, shadows, and twins. Second, we synthesize three foundational enabling technologies: (1) physics-based modeling, emphasizing the shift from computationally intensive finite-element analysis (FEA) to real-time surrogate models; (2) data-driven paradigms, highlighting virtual metrology (VM) for inferring latent metrics; and (3) in-situ sensing, the nervous system coupling the physical stack to its virtual counterpart. Third, beyond a descriptive survey, we propose a unified hybrid DT architecture that leverages physics-informed machine learning (e.g., PINNs) to reconcile data scarcity with latency constraints. Finally, we outline a standards-aligned roadmap incorporating IEEE 1451 and UCIe protocols to accelerate the transition from passive digital shadows to autonomous, self-optimizing Digital Twins for 3D IC manufacturing and field operation.

</details>
