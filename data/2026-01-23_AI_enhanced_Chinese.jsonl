{"id": "2601.15710", "categories": ["cs.AR", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15710", "abs": "https://arxiv.org/abs/2601.15710", "authors": ["Jiahao Zhang", "Zifan He", "Nicholas Fraser", "Michaela Blott", "Yizhou Sun", "Jason Cong"], "title": "FlexLLM: Composable HLS Library for Flexible Hybrid LLM Accelerator Design", "comment": null, "summary": "We present FlexLLM, a composable High-Level Synthesis (HLS) library for rapid development of domain-specific LLM accelerators. FlexLLM exposes key architectural degrees of freedom for stage-customized inference, enabling hybrid designs that tailor temporal reuse and spatial dataflow differently for prefill and decode, and provides a comprehensive quantization suite to support accurate low-bit deployment. Using FlexLLM, we build a complete inference system for the Llama-3.2 1B model in under two months with only 1K lines of code. The system includes: (1) a stage-customized accelerator with hardware-efficient quantization (12.68 WikiText-2 PPL) surpassing SpinQuant baseline, and (2) a Hierarchical Memory Transformer (HMT) plug-in for efficient long-context processing. On the AMD U280 FPGA at 16nm, the accelerator achieves 1.29$\\times$ end-to-end speedup, 1.64$\\times$ higher decode throughput, and 3.14$\\times$ better energy efficiency than an NVIDIA A100 GPU (7nm) running BF16 inference; projected results on the V80 FPGA at 7nm reach 4.71$\\times$, 6.55$\\times$, and 4.13$\\times$, respectively. In long-context scenarios, integrating the HMT plug-in reduces prefill latency by 23.23$\\times$ and extends the context window by 64$\\times$, delivering 1.10$\\times$/4.86$\\times$ lower end-to-end latency and 5.21$\\times$/6.27$\\times$ higher energy efficiency on the U280/V80 compared to the A100 baseline. FlexLLM thus bridges algorithmic innovation in LLM inference and high-performance accelerators with minimal manual effort.", "AI": {"tldr": "FlexLLM\u662f\u4e00\u4e2a\u53ef\u7ec4\u5408\u7684HLS\u5e93\uff0c\u7528\u4e8e\u5feb\u901f\u5f00\u53d1\u9886\u57df\u7279\u5b9a\u7684LLM\u52a0\u901f\u5668\uff0c\u652f\u6301\u9636\u6bb5\u5b9a\u5236\u5316\u63a8\u7406\u548c\u91cf\u5316\u90e8\u7f72\uff0c\u5728FPGA\u4e0a\u5b9e\u73b0\u4e86\u8d85\u8d8aGPU\u7684\u6027\u80fd\u548c\u80fd\u6548", "motivation": "\u5f53\u524dLLM\u63a8\u7406\u9700\u8981\u9ad8\u6027\u80fd\u52a0\u901f\u5668\uff0c\u4f46\u5f00\u53d1\u8fc7\u7a0b\u590d\u6742\u8017\u65f6\u3002FlexLLM\u65e8\u5728\u901a\u8fc7\u53ef\u7ec4\u5408\u7684HLS\u5e93\u7b80\u5316\u9886\u57df\u7279\u5b9aLLM\u52a0\u901f\u5668\u7684\u5f00\u53d1\uff0c\u6865\u63a5\u7b97\u6cd5\u521b\u65b0\u4e0e\u9ad8\u6027\u80fd\u786c\u4ef6\u5b9e\u73b0", "method": "\u63d0\u4f9b\u53ef\u7ec4\u5408\u7684High-Level Synthesis\u5e93\uff0c\u66b4\u9732\u67b6\u6784\u81ea\u7531\u5ea6\u652f\u6301\u9636\u6bb5\u5b9a\u5236\u5316\u63a8\u7406\uff08prefill\u548cdecode\u91c7\u7528\u4e0d\u540c\u8bbe\u8ba1\uff09\uff0c\u5305\u542b\u5168\u9762\u7684\u91cf\u5316\u5957\u4ef6\u652f\u6301\u4f4e\u6bd4\u7279\u90e8\u7f72\uff0c\u5e76\u5f00\u53d1\u4e86Hierarchical Memory Transformer\u63d2\u4ef6\u7528\u4e8e\u957f\u4e0a\u4e0b\u6587\u5904\u7406", "result": "\u5728AMD U280 FPGA\u4e0a\uff0c\u76f8\u6bd4NVIDIA A100 GPU\uff1a\u7aef\u5230\u7aef\u52a0\u901f1.29\u500d\uff0c\u89e3\u7801\u541e\u5410\u91cf\u63d0\u9ad81.64\u500d\uff0c\u80fd\u6548\u63d0\u53473.14\u500d\uff1b\u5728V80 FPGA\u4e0a\u5206\u522b\u8fbe\u52304.71\u500d\u30016.55\u500d\u548c4.13\u500d\u3002HMT\u63d2\u4ef6\u5728\u957f\u4e0a\u4e0b\u6587\u573a\u666f\u4e2d\u51cf\u5c11prefill\u5ef6\u8fdf23.23\u500d\uff0c\u6269\u5c55\u4e0a\u4e0b\u6587\u7a97\u53e364\u500d", "conclusion": "FlexLLM\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u4eba\u5de5\u5de5\u4f5c\u91cf\u6865\u63a5LLM\u63a8\u7406\u7b97\u6cd5\u521b\u65b0\u4e0e\u9ad8\u6027\u80fd\u52a0\u901f\u5668\u5f00\u53d1\uff0c\u663e\u8457\u63d0\u5347FPGA\u4e0aLLM\u63a8\u7406\u7684\u6027\u80fd\u548c\u80fd\u6548\uff0c\u7279\u522b\u662f\u5728\u957f\u4e0a\u4e0b\u6587\u5904\u7406\u65b9\u9762"}}
{"id": "2601.16118", "categories": ["cs.AR", "cs.NE"], "pdf": "https://arxiv.org/pdf/2601.16118", "abs": "https://arxiv.org/abs/2601.16118", "authors": ["Marco Ronzani", "Cristina Silvano"], "title": "A Case for Hypergraphs to Model and Map SNNs on Neuromorphic Hardware", "comment": null, "summary": "Executing Spiking Neural Networks (SNNs) on neuromorphic hardware poses the problem of mapping neurons to cores. SNNs operate by propagating spikes between neurons that form a graph through synapses. Neuromorphic hardware mimics them through a network-on-chip, transmitting spikes, and a mesh of cores, each managing several neurons. Its operational cost is tied to spike movement and active cores. A mapping comprises two tasks: partitioning the SNN's graph to fit inside cores and placement of each partition on the hardware mesh. Both are NP-hard problems, and as SNNs and hardware scale towards billions of neurons, they become increasingly difficult to tackle effectively. In this work, we propose to raise the abstraction of SNNs from graphs to hypergraphs, redesigning mapping techniques accordingly. The resulting model faithfully captures the replication of spikes inside cores by exposing the notion of hyperedge co-membership between neurons. We further show that the overlap and locality of hyperedges strongly correlate with high-quality mappings, making these properties instrumental in devising mapping algorithms. By exploiting them directly, grouping neurons through shared hyperedges, communication traffic and hardware resource usage can be reduced be yond what just contracting individual connections attains. To substantiate this insight, we consider several partitioning and placement algorithms, some newly devised, others adapted from literature, and compare them over progressively larger and bio-plausible SNNs. Our results show that hypergraph based techniques can achieve better mappings than the state-of-the-art at several execution time regimes. Based on these observations, we identify a promising selection of algorithms to achieve effective mappings at any scale.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u5c06\u8109\u51b2\u795e\u7ecf\u7f51\u7edc(SNN)\u4ece\u56fe\u62bd\u8c61\u63d0\u5347\u5230\u8d85\u56fe\u62bd\u8c61\uff0c\u4ee5\u6539\u8fdb\u5728\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u7684\u6620\u5c04\u6280\u672f\uff0c\u901a\u8fc7\u8d85\u8fb9\u5171\u6210\u5458\u5173\u7cfb\u66f4\u597d\u5730\u6355\u6349\u6838\u5fc3\u5185\u8109\u51b2\u590d\u5236\uff0c\u4ece\u800c\u51cf\u5c11\u901a\u4fe1\u6d41\u91cf\u548c\u786c\u4ef6\u8d44\u6e90\u4f7f\u7528\u3002", "motivation": "\u5728\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u6267\u884cSNN\u9762\u4e34\u795e\u7ecf\u5143\u5230\u6838\u5fc3\u7684\u6620\u5c04\u95ee\u9898\u3002\u968f\u7740SNN\u548c\u786c\u4ef6\u89c4\u6a21\u6269\u5c55\u5230\u6570\u5341\u4ebf\u795e\u7ecf\u5143\uff0c\u73b0\u6709\u7684\u56fe\u5206\u533a\u548c\u653e\u7f6e\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\uff0c\u9700\u8981\u66f4\u9ad8\u5c42\u6b21\u7684\u62bd\u8c61\u6765\u6355\u6349\u6838\u5fc3\u5185\u8109\u51b2\u590d\u5236\u7684\u7279\u6027\u3002", "method": "\u5c06SNN\u4ece\u56fe\u6a21\u578b\u63d0\u5347\u5230\u8d85\u56fe\u6a21\u578b\uff0c\u5229\u7528\u8d85\u8fb9\u5171\u6210\u5458\u5173\u7cfb\u6355\u6349\u795e\u7ecf\u5143\u95f4\u7684\u901a\u4fe1\u6a21\u5f0f\u3002\u57fa\u4e8e\u8d85\u8fb9\u7684\u91cd\u53e0\u6027\u548c\u5c40\u90e8\u6027\u8bbe\u8ba1\u6620\u5c04\u7b97\u6cd5\uff0c\u5305\u62ec\u65b0\u8bbe\u8ba1\u7684\u7b97\u6cd5\u548c\u4ece\u6587\u732e\u6539\u7f16\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u8d85\u8fb9\u5171\u4eab\u6765\u5206\u7ec4\u795e\u7ecf\u5143\u3002", "result": "\u8d85\u56fe\u57fa\u6280\u672f\u80fd\u591f\u5728\u591a\u4e2a\u6267\u884c\u65f6\u95f4\u8303\u56f4\u5185\u5b9e\u73b0\u6bd4\u73b0\u6709\u6280\u672f\u66f4\u597d\u7684\u6620\u5c04\u6548\u679c\u3002\u8d85\u8fb9\u7684\u91cd\u53e0\u6027\u548c\u5c40\u90e8\u6027\u4e0e\u9ad8\u8d28\u91cf\u6620\u5c04\u5f3a\u76f8\u5173\uff0c\u5229\u7528\u8fd9\u4e9b\u7279\u6027\u53ef\u4ee5\u663e\u8457\u51cf\u5c11\u901a\u4fe1\u6d41\u91cf\u548c\u786c\u4ef6\u8d44\u6e90\u4f7f\u7528\u3002", "conclusion": "\u8d85\u56fe\u62bd\u8c61\u4e3aSNN\u5728\u795e\u7ecf\u5f62\u6001\u786c\u4ef6\u4e0a\u7684\u6620\u5c04\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684\u6a21\u578b\uff0c\u80fd\u591f\u5904\u7406\u5927\u89c4\u6a21SNN\u7684\u6620\u5c04\u95ee\u9898\u3002\u57fa\u4e8e\u7814\u7a76\u7ed3\u679c\uff0c\u8bc6\u522b\u51fa\u4e86\u4e00\u7ec4\u6709\u524d\u666f\u7684\u7b97\u6cd5\u9009\u62e9\uff0c\u53ef\u5728\u4efb\u4f55\u89c4\u6a21\u4e0b\u5b9e\u73b0\u6709\u6548\u6620\u5c04\u3002"}}
